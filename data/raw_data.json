[
  {
    "subreddit": "learnprogramming",
    "title": "I need help really fast!",
    "text": "For a research project I gotta ask someone some questions about async programming in C#, anyone willing to help? My deadline is tomorrow and I really don't want to fail my year..",
    "created_utc": 1746523951.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kg0ah5/i_need_help_really_fast/",
    "score": 0,
    "num_comments": 2
  },
  {
    "subreddit": "learnprogramming",
    "title": "Tired of screen-sharing on Zoom to code with friends or teammates? I built a real-time collaborative code editor \u2013 Freee!!!!",
    "text": "**Hey devs, students, and 2AM bug-fixers \ud83d\udc4b**\n\n**\ud83c\udfaf Try it here** \u2192 [https://eliteapp.tech/](https://eliteapp.tech/)  \n(No setup \u2013 just sign up with your email and start coding together)\n\nEver struggled with:\n\n* Pair programming over Zoom where only **one person can type**?\n* Helping a friend debug their code and you\u2019re like \u201cshare your screen!\u201d \ud83d\ude29\n* Teaching or learning code online but can\u2019t interact in real-time?\n\nYeah\u2026 same.  \nSo I built **CodeTogether** \u2013 a **real-time collaborative code editor** where multiple people can **code together live**, just like Google Docs \ud83e\udde0\ud83d\udcbb\n\n# \ud83d\udca1 Why it\u2019s useful (especially for you):\n\n* \ud83d\udc68\u200d\ud83c\udf93 **Students** \u2013 work on group projects, labs, or assignments together\n* \ud83d\udc69\u200d\ud83d\udcbc **Working devs** \u2013 do remote pair programming or quick collab\n* \ud83d\udc68\u200d\ud83c\udfeb **Teachers & mentors** \u2013 guide students with live code edits\n* \ud83d\udc68\u200d\ud83d\udcbb **Solo devs** \u2013 use the built-in AI assistant to get coding help\n\n# \ud83d\udd27 Key Features:\n\n* \u270d\ufe0f Real-time code editing (multi-user, multi-file)\n* \ud83d\udd12 Secure room system \u2013 just share a link & code together\n* \ud83d\udcac Built-in chat + see who\u2019s editing what\n* \ud83c\udfa8 Collaborative drawing board for visual explanations\n* \ud83e\udd16 AI helper for code suggestions\n* \ud83d\udcc1 Download full codebase as ZIP anytime\n* \ud83c\udf08 Syntax highlighting, themes, font settings & more\n\n\ud83c\udfaf **Free to use \u2013 Just sign up with your email and start coding together!**  \n\ud83d\udee1\ufe0f Quick & secure login with email OTP \u2013 no passwords, no hassle.  \n\ud83d\udcfa **Live Demo**: [https://eliteapp.tech/](https://eliteapp.tech/)\n\nI made this to **help devs and students** collaborate easily, without headaches or screen-sharing nightmares. It's totally **free forever**, open-source, and privacy-first \ud83d\ude4c\n\nLet me know what you think \u2013 feedback, ideas, bugs, anything!  \nLet\u2019s make coding **together** better \u2764\ufe0f",
    "created_utc": 1746523101.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kg0362/tired_of_screensharing_on_zoom_to_code_with/",
    "score": 1,
    "num_comments": 0
  },
  {
    "subreddit": "learnprogramming",
    "title": "Do i have to copy Debug dlls manually everytime?(sfml via vcpkg via vs code)",
    "text": "So when i want to run \u2014cmake \u2014build build via specifically release mode it works fine no problem\n\n\n    cmake \u2014build build \u2014config Release\n\n\nBut if i use cmake \u2014build build , bydefault it uses debug version but it doesn\u2019t copies debug dlls and i have to go to file to manually copy them\n\n\n    cmake \u2014build build and copying manually \n\n\n( the reason is something like cmake prioritise release dlls?)\n\n\nSo just wanted to know should i use release or debug dlls?? And people disagree but I don\u2019t really know how to write cmake.txt to make it automatically copy dlls of debug so is it alright to use gpt in that case",
    "created_utc": 1746522706.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfzzsg/do_i_have_to_copy_debug_dlls_manually/",
    "score": 1,
    "num_comments": 0
  },
  {
    "subreddit": "learnprogramming",
    "title": "Dependencies Problems",
    "text": "First of all, hello everyone. New member on these subreditt over here!\n\nI'm writing these post because I really need help over something I'm currently working on. \n\nI'm following \"Coding in flow\" video [https://www.youtube.com/watch?v=TyV12oBDsYI&t=1180s&ab\\_channel=CodinginFlow](https://www.youtube.com/watch?v=TyV12oBDsYI&t=1180s&ab_channel=CodinginFlow) to build an app and in the part where he establish all the dependencies is were the troublesome part begin. The video is outdated and new versions of some languages have come out so if I try to follow step-by-step the tutorial my development enviroment cant run the code. Does anyone know how can I fix it?",
    "created_utc": 1746522418.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfzxfo/dependencies_problems/",
    "score": 1,
    "num_comments": 2
  },
  {
    "subreddit": "learnprogramming",
    "title": "PHP memory size exhausted",
    "text": "Hello, I realized my code on server is a ticking bomb cuz on localhost I started getting error from the title and I'm not sure how to improve that code. I use Laravel and this is my:\n\nindex function that passes all the info to view: [https://pastebin.com/bqHSnqza](https://pastebin.com/bqHSnqza)\n\nview: [https://pastebin.com/AqEiCuWV](https://pastebin.com/AqEiCuWV)\n\nI've thought about few solutions:\n\n1. Pagination (then I will have problem with live searching records with JS)\n2. Getting minimal information needed and loading more for specific product with Ajax after clicking edit button\n3. Loading only selling history without option to edit those sellings (right now I don't think I will need to change them, but who knows what will happen in the future)\n4. Similar to one above, but with edit option dedicated site for only that selling\n\nIm shop owner but when I was younger I tried to be web developer so I have some skills, but as you can see, from someone more experienced perspective, my code probably looks terrible. Do you have any propositions how to improve that code so it doesn't exceed memory? Right now it's about 800 records, but with every day it grows about 20-50 records",
    "created_utc": 1746519829.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfzcoh/php_memory_size_exhausted/",
    "score": 2,
    "num_comments": 2
  },
  {
    "subreddit": "learnprogramming",
    "title": "Binary tree",
    "text": "I was solving an exercise that told me to do the following. Randomize 1000 different trees of numbers using different type of randomization and see which randomization gives a better result in a sense which randomization give a more balanced tree.\n\nI got the following results:\n\n**Type A**\n\n    The average max height in 800 iterations: 30.00\n    The highest maximum height: 41\n    The average minimum height: 5.00\n    The lowest minimum height: 2\n    The average difference between minimum and maximum height: 25.00\n    The greatest difference between minimum and maximum height: 35\n    The lowest difference between minimum and maximum height: 19\n\n**Type B**\n\n    The average max height in 800 iterations: 30.00\n    The highest maximum height: 30\n    The average minimum height: 5.00\n    The lowest minimum height: 5\n    The average difference between minimum and maximum height: 25.00\n    The greatest difference between minimum and maximum height: 25\n    The lowest difference between minimum and maximum height: 25\n\nI am not really sure what to make of the results. The highest height is 41 and lowest 2 for A while it is 30 and 5 for B  but this feels like a useless information. I honestly have no clue how I am supposed to conclude anything.\n\nEdit: I don't want an answer, I am interested in understanding the question and how to think about it because I have been stuck on this way to long.",
    "created_utc": 1746510959.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfxbie/binary_tree/",
    "score": 1,
    "num_comments": 4
  },
  {
    "subreddit": "learnprogramming",
    "title": "10 year old game dev",
    "text": "My younger brother is really smart and creative, and he's been wanting to make a FNAF fan game or sth, he has this entire plan and storyline, and I really wanna help him out. \n\nI'm aware it's  definitely not possible for him to make a full blown game, but I want him to start with something so that he doesn't get discouraged. \n\nIs there any programming language or game dev related skill that would be easy enough for him to learn? That he can use to make his passion projects? He's a pretty smart kid and I'm sure he'd be able to figure out stuff even a bit advanced for his age. \n\n\n\n\n",
    "created_utc": 1746509163.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfwvyw/10_year_old_game_dev/",
    "score": 13,
    "num_comments": 8
  },
  {
    "subreddit": "learnprogramming",
    "title": "I need help with a homework",
    "text": "I have to do a binary searching tree , and print it on c#  I have done a way to input the data and print it but I have to do different types of orders and it only prints one , I was wondering if anyone could help or explain to me what I need to modify",
    "created_utc": 1746508950.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfwu1c/i_need_help_with_a_homework/",
    "score": 1,
    "num_comments": 2
  },
  {
    "subreddit": "learnprogramming",
    "title": "I need help from someone experienced in web dev regarding my carreer",
    "text": "Hello everyone. I need help with something, please take the time to read this. I'm 20 years old, I studied development in highschool (school with a focus on web dev and developing in general), so I have some beginner foundation in web development (html, css, javascript, mysql). I'm currently in university, but I really don't like it and the field (security) is boring for me. I want to quit school and give all of my time to learning web development (I like front-end, but it doesn't matter). If you are a person who worked in this field for a few years, can you help me figure out what should I learn? I don't know if I should grind react, angular, node.js or something else, the goal is to land a junior level job within a year. I'm really lost and would appreciate some guidance in this. For those telling me \"don't quit uni\" - i'm already in the process of doing so. Thanks for your help, I really appreciate it.",
    "created_utc": 1746500734.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfujhc/i_need_help_from_someone_experienced_in_web_dev/",
    "score": 0,
    "num_comments": 1
  },
  {
    "subreddit": "learnprogramming",
    "title": "Why is my deployed web app blocked? (Idk what caused this) to access the backend on public wifi.",
    "text": "Hello,\n\nI have recently deployed my backend service on an AWS EC2 instance and my frontend on EAS.\n\nI can successfully manage it to communicate with each other on my home wifi, but I realized that the web app can't make a request when I am on some random grocery store's Wi-Fi. It gave me an error saying \"the certificate chain was issued by an authority that is not trusted\", which sounds like my SSL certificate has a setup issue?\n\nI used Let's encrypt for issueing the certificate.\n\nDoes anyone know why it led to this kind of error and how to prevent it in real real-world deployment situation?\n\nThanks",
    "created_utc": 1746496955.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kftbt0/why_is_my_deployed_web_app_blocked_idk_what/",
    "score": 0,
    "num_comments": 1
  },
  {
    "subreddit": "learnprogramming",
    "title": "Laid off, completed NeetCode 150, now grinding for a high-paying job \u2014 looking for guidance on building a standout profile",
    "text": "I have 1.5 years of experience as a Software Engineer at a mid-sized company, but I got laid off two months ago. Since then, I\u2019ve been grinding LeetCode and have solved 205 problems so far (63 Easy / 121 Medium / 21 Hard). I\u2019ve fully completed NeetCode 150 and am now revisiting it by doing 2 problems a day until I reach mastery.\n\nTo be honest, my previous work experience isn\u2019t something I can highlight strongly on a resume. So now I\u2019m focused on **building my profile**:\n\n* Developing and hosting full-stack projects\n* Actively contributing to open-source (recently made a contribution to a Flask-based issue)\n* Improving my GitHub profile with solid commits, PRs, and documentation\n* Planning to learn AI/ML fundamentals as a long-term goal\n\nMy goal is to **land a high-paying backend or full-stack role**, ideally at a top company. I\u2019m ready to put in 8\u201310 hours of focused work, 6 days a week.\n\nIf you've been in a similar position or have advice on project ideas, profile-building strategies, or job search tips \u2014 I\u2019d really appreciate the help!",
    "created_utc": 1746492154.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfrr2i/laid_off_completed_neetcode_150_now_grinding_for/",
    "score": 10,
    "num_comments": 4
  },
  {
    "subreddit": "learnprogramming",
    "title": "First .NET Dev Job. Grateful, But Worried I\u2019m Alone and Not Growing",
    "text": "Hey everyone,\n\nI\u2019m a .NET web developer. I didn\u2019t study computer science in college, but I went through an intensive 4-month full-stack .NET bootcamp, which gave me a solid foundation.\n\nI just landed my first job (super grateful for that), but there\u2019s something that\u2019s been bugging me. I\u2019m the only one in the company working with .NET. The rest of the team is made up of front-end devs and software testers\u2014no other back-end devs, no senior .NET people, no real mentorship or guidance.\n\nBasically, I\u2019m on my own. And while I\u2019ve done a lot of self-learning to get to this point, I\u2019m honestly tired of doing it all by myself. I\u2019m worried that working solo like this for 1\u20132 years will limit my growth. I won\u2019t have anyone to learn best practices from, no code reviews, no exposure to how real teams handle things.\n\nI\u2019m afraid I\u2019ll waste this time and come out of it stuck, with not much to show for it.\n\nAnyone been in a similar situation? Is there a way to actually grow in a job like this, or should I already be planning my next move?",
    "created_utc": 1746490931.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfrch1/first_net_dev_job_grateful_but_worried_im_alone/",
    "score": 28,
    "num_comments": 13
  },
  {
    "subreddit": "learnprogramming",
    "title": "Questions on how should I start my programming journey",
    "text": "Hey everyone. Just wanna tell you English is my second language so don't mind my broken English. I am very new to coding only know a little bit of HTML and CSS. As far as I know I wanna specialize in both backend and frontend I think it's called full stack. I do wanna know how should I start since I know a little bit of css and html so should I start with front end then go to backend. My other questions is this thing with AI chatgtp can create better websites than me. I know its been a week since I actually lock-in on this but will Ai take over this front end things very confused. And about course I been looking in on the odin project if there is any better course plz do help a newbie.",
    "created_utc": 1746486459.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfprwb/questions_on_how_should_i_start_my_programming/",
    "score": 2,
    "num_comments": 2
  },
  {
    "subreddit": "learnprogramming",
    "title": "I have some problems with my debugger in Eclipse (C++)",
    "text": "First, I don't see any variables in the \"Variables\"-tab. I tried these things: resetting the view, closing the tab and then resetting the view, restarting Eclipse, restarting my PC\n\nSecond problem is that the debugger doesn't stop at the breakpoints I set. I can't see where it is at the moment and when I click \"Resume\" it just immediately ends, no matter how many it should still stop at.\n\nI would be really grateful if someone could help me with this. Thank you!\n\n\nYou can find more information (including the simple program I try it with) [here](https://www.reddit.com/r/eclipse/s/NpMh7hcnTi).",
    "created_utc": 1746482844.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfog6p/i_have_some_problems_with_my_debugger_in_eclipse_c/",
    "score": 1,
    "num_comments": 0
  },
  {
    "subreddit": "learnprogramming",
    "title": "Doing a dev thing in production for the first time.",
    "text": "I recently went to school to get an A.S. degree in Programming and Analysis. When I was a child I stumped my kindergarten teacher by telling her I wanted to be a programmer when I grew up (instead of a firefighter or astronaut) and had to explain to her what it was.\n\nWith no portfolio to speak of and only a two year degree I wasn't going to get into a dev job, so I went back to my old standby, IT.\n\nBeen working in this company for 3 months now. Literally have written hundreds of pages of IT documentation, guides, scripts, etc. Documenting literally everything I do and writing automation to do things easier.\n\nMy CTO said that the head of dev needed my help with something and I was told that she noticed the way that I document and script and needed my cross-functional knowledge for something that our application (that we sell to clients) does with good documentation and validation.\n\nLong story short, she needed a JSON schema so they could make JSON files for something the application does that integrates with IT systems our clients use. Something to define all of the configurations possible and enumerate all the values for each property so that the configuration could be validated by our software's automation. (Most devs know very little about IT infrastructure, so my cross-functional knowledge was know enough of both worlds to be able to make something sensible.)\n\nIt's such a small thing, but she assigned a task in their dev tracker and I did a PR into a live software project for a company that I work for the first time in my life and even though I'm not a dev (yet!) it's still made me feel like in a small part I'm almost reached that thing that I've literally dreamed of doing for 35 years.\n\nI didn't have anyone else to share this with, so I hope you don't mind me sharing the story here.",
    "created_utc": 1746480277.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfnfg1/doing_a_dev_thing_in_production_for_the_first_time/",
    "score": 95,
    "num_comments": 13
  },
  {
    "subreddit": "learnprogramming",
    "title": "Developers, do you use Notion for code documentation or internal wikis?",
    "text": "Hey everyone! \ud83d\udc4b\n\nI'm exploring the idea of using Notion more seriously for documenting code, internal tools, and team workflows. Before I commit to setting things up, I\u2019m really curious how other developers are using Notion for this kind of work.\n\n* Do you currently use Notion for documenting code, internal tools, or workflows?\n* What kind of content do you typically store there (e.g., onboarding steps, CLI commands, architecture overviews)?\n* How well does it work for you in day-to-day development?\n* Do you find yourself switching often between Notion and your IDE or terminal?\n* Are there any tips, tools, or workflows you've found helpful\u2014or any major frustrations?\n\nWould love to hear how others are approaching this and whether Notion has actually been a good fit for dev-oriented documentation.\n\nThanks in advance \ud83d\ude4f",
    "created_utc": 1746479373.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfn25c/developers_do_you_use_notion_for_code/",
    "score": 1,
    "num_comments": 2
  },
  {
    "subreddit": "learnprogramming",
    "title": "Row was updated or deleted by another transaction (or unsaved-value mapping was incorrect)",
    "text": "\n\nHi,\n\nI'm working on a Spring Boot application that connects to a PostgreSQL database. I'm trying to save an \\`Author\\` entity using JPA, and I'm running into this error:\n\n\n\norg.springframework.orm.ObjectOptimisticLockingFailureException: \n\nRow was updated or deleted by another transaction (or unsaved-value mapping was incorrect): \n\n\\[com.example.PostgreDatabase\\_Conn\\_Demo.Domain.Author#7\\]\n\n\n\n Author Entity\n\n\n\n\\`\\`\\`\n\n@ Entity\n\n@ Table(name = \"authors\")\n\n@ Data \n\n@ Builder\n\n@ AllArgsConstructor\n\n@ NoArgsConstructor\n\npublic class Author {\n\n\n\n@ Id\n\n@ GeneratedValue(strategy = GenerationType.SEQUENCE, generator = \"author\\_id\\_seq\")\n\nprivate Long id = null;\n\n\n\nprivate String name;\n\n\n\nprivate Integer age;\n\n}\n\n\\`\\`\\`\n\n\n\n\n\n Integration Test\n\n\\`\\`\\`\n\n@ SpringBootTest\n\n@ ExtendWith(SpringExtension.class)\n\n@ DirtiesContext(classMode = DirtiesContext.ClassMode.AFTER\\_EACH\\_TEST\\_METHOD)\n\npublic class AuthorDAOImplIntegrationTest {\n\n\n\nfinal private AuthorRepository underTest;\n\n\n\n@ Autowired\n\npublic AuthorDAOImplIntegrationTest(AuthorRepository underTest) {\n\nthis.underTest = underTest;\n\n}\n\n\n\n@ Test\n\npublic void testThatAuthorCanBeCreatedAndRecalled() {\n\nAuthor author = TestDataUtil.createTestAuthor();\n\nSystem.out.println(\"Author before save: \" + author);\n\nunderTest.save(author);\n\nOptional<Author> result = underTest.findById(author.getId());\n\nSystem.out.println(\"Retrieved Author: \" + result);\n\nassertThat(result).isPresent();\n\nassertThat(result.get()).isEqualTo(author);\n\n}\n\n}\n\n\\`\\`\\`\n\n\n\n Can you help ?",
    "created_utc": 1746475556.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kflgre/row_was_updated_or_deleted_by_another_transaction/",
    "score": 1,
    "num_comments": 1
  },
  {
    "subreddit": "learnprogramming",
    "title": "Feeling stupid",
    "text": "As the title declares,I feel stupid as an absolute beginner in programming.first forgive my English as am not a native speaker.\nI started learning dart because I have an idea of an app that can make me a good money and it's a real problem solver , when I got in to it ,it felt easy but when I ask AI to give me exercise on the things I learn I couldn't solve it and when it generates the solution I couldn't understand it (the solutions were not in the course)so,am feeling stupid and started to think that am not good enough. I know the expert sometimes feel stupid too,but is there any way that I can adapt this or any other solution to learn effectively?\nAppreciate your help ",
    "created_utc": 1746473575.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfkn39/feeling_stupid/",
    "score": 0,
    "num_comments": 12
  },
  {
    "subreddit": "learnprogramming",
    "title": "Which programming language will help me do this?",
    "text": "Complete beginner to programming and the FAQ said to start with a project I want to create. The task I have come with is this: Every morning I listen to the most recent episodes of three podcasts (for the news) on Spotify. Ideally Spotify would have the option of creating a playlist that updates with just the most recent episodes of specific podcasts (New Episodes kind of does this but it also includes any prior unplayed episodes as well). My current process is unlock my phone, navigate to the Spotify app > Your Library > Podcasts > (Podcast A > add most recent episode to the queue) repeat two more times for the other two podcasts > Play.\n\nI would like to be able to press one button and have all those episodes play in succession. What language would I need to create such a thing? The FAQ suggests Swift for iPhone apps but I am not trying to create a new app- just automate how I use one. Automation/scripting suggests several languages including Python but I am not sure if iOS would be compatible? What are your suggestions?\n\nWhen I say beginner, I mean total beginner. Java means coffee, pythons are snakes, and I don't even know where you physically type the code in. In all honesty I am just curious about finding out if coding would be a way to monetize my \"puzzle itch\" but I can appreciate the importance of learning by doing. If my proposed project is actually more complex than I think it is, let me know!",
    "created_utc": 1746465624.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfh9u5/which_programming_language_will_help_me_do_this/",
    "score": 0,
    "num_comments": 3
  },
  {
    "subreddit": "learnprogramming",
    "title": "I can't even start TMT",
    "text": "so i don't know how to start learning to code. for example, i really wanted to help code this terraria mod so i went on youtube to see how to mod terraria, and in the video it was actually pretty simple, but as soon as i see the required references at the top then needing to even make one modded item i just feel intense anxiety and i loose all motivation, its really weird and annoying. what do i do? should i try to power through or do some trick to get myself to do it or something? ",
    "created_utc": 1746458370.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfe85j/i_cant_even_start_tmt/",
    "score": 0,
    "num_comments": 4
  },
  {
    "subreddit": "learnprogramming",
    "title": "Unsure which profession to pursue \u2014 I enjoy backend development but feel stuck",
    "text": "I've been teaching myself coding through various projects and now I\u2019m trying to figure out the right career direction. So far, I've worked on:\n\nA fitness tracker desktop app in C#\n\nAn e-commerce website in HTML, CSS, and PHP\n\nSeveral Python/Django web projects\n\nA small puzzle game in Java\n\nBriefly explored data analysis using pandas\n\nAll of them are still in development, but I've realized that I really enjoy backend logic \u2014 writing, debugging, and problem-solving \u2014 while I actively avoid front-end design or UI/UX work. I also don\u2019t care much about visual design; I just love seeing my logic work, even if it\u2019s not the most efficient.\n\nI've looked into backend roles, software engineering, and data jobs, but I'm not sure what paths best align with my interests. I\u2019ve searched around Reddit, YouTube, and blogs, but I still feel stuck.\n\nMy question is:\nWhat types of roles or specialties would best suit someone who loves backend problem-solving and doesn\u2019t enjoy UI/design? I'd appreciate advice or personal experience from others who were in a similar position.\n\nThanks in advance!\n",
    "created_utc": 1746457962.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfe20u/unsure_which_profession_to_pursue_i_enjoy_backend/",
    "score": 4,
    "num_comments": 11
  },
  {
    "subreddit": "learnprogramming",
    "title": "Is is worth attaining the CS50x Cert?",
    "text": "Currently taking the free course, but was told thats it wasn\u2019t worth it.\n\nI\u2019m curious to know what you guys think, those  who have it or who never got it, why? Did it help with job applications? Did it make you stand out? ",
    "created_utc": 1746457022.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfdnxo/is_is_worth_attaining_the_cs50x_cert/",
    "score": 0,
    "num_comments": 2
  },
  {
    "subreddit": "learnprogramming",
    "title": "Hackathon Help - Need a Simple but Impactful Idea Based on My Skills",
    "text": "Hey everyone,\n\nI've got a 36-hour hackathon coming up, and we're free to build anything - there's no theme restriction. I'm looking for some practical and achievable project ideas that suit my current skill level.\n\nHere's what I know (being totally honest): Comfortable with Python Familiar with SQL and basic DBMS. Have worked on small projects like Spam Email Detection using ML (with help/tutorials). Recently started learning Streamlit. Not experienced in advanced stuff like frontend frameworks or deep APIs, but I'm open to learning quickly during the hackathon if needed\n\nWhat I'm looking for: A real-world problem I can try solving\n\nin 36 hours. Should be doable solo (or with a small team) without needing expert-level skills Ideally something with social or practical impact not just another to-do app. Would love to use Python, maybe Streamlit or some public APIs if they're beginner-friendly\n\nIf you've seen or worked on any beginner-friendly but interesting ideas (or problems worth solving), please share. I'm okay with simple execution, as long as the idea has a purpose or story behind it.\n\nThanks in advance!",
    "created_utc": 1746449680.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kfawdm/hackathon_help_need_a_simple_but_impactful_idea/",
    "score": 0,
    "num_comments": 1
  },
  {
    "subreddit": "learnprogramming",
    "title": "How to deal with coding burnout?",
    "text": "How do I deal with this. Just finished college a year ago, but I feel like I don't wanna do any type of coding ever again. Is this just a phase that'll pass, do I need help from friends or professionals, do I just keep doing it till it stops hoping I don't go crazy? Or do I need to go outside and touch grass for a while? I tried to stave off the feeling by learning new stuff and applying it but it didn't work.",
    "created_utc": 1746444284.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kf9704/how_to_deal_with_coding_burnout/",
    "score": 17,
    "num_comments": 8
  },
  {
    "subreddit": "learnprogramming",
    "title": "Confused Programmer",
    "text": "I started my programming journey almost four years ago when I was 18, with no background in computers. I began with HTML, basic CSS, and a little bit of JavaScript. Later, I discovered Laravel, a PHP framework, and started working on backend development. Over time, I became skilled in Laravel and really enjoyed building applications.\n\nAs I grew, I realized that I needed a deeper understanding of PHP itself, so I took the time to learn PHP as well. I ended up creating the backend for many mobile applications and worked on complex projects. At that time, I was working at a service-based company, so I had to work on whatever came my way. That\u2019s how I also ended up learning Node.js.\n\nYou could say I\u2019m a backend developer who can work with a variety of frameworks like Laravel, Livewire, CakePHP, and Node.js.\n\nCurrently, I\u2019m working at a fintech, product-based company. But here\u2019s the funny part \u2014 even after four years of experience, I still feel like something is missing. I\u2019m not sure what to learn next to truly grow. I've never done LeetCode problems, but I\u2019m very good at solving real-world, complex problems that arise during application development.\n\nI also have a basic understanding of low-level languages like C++. But now I\u2019m at a crossroads. Sometimes I feel like I should improve my JavaScript skills and learn React. Other times, I feel drawn toward AI and want to explore how to get better at that.\n\nThere\u2019s a lot of confusion in my mind right now.\n\nI\u2019m 22, and I still love learning and building new things. I genuinely enjoy creating. But I\u2019m unsure what to learn next \u2014 something that will help me grow both financially and technically, and truly make me better.\n\nCan you guys please give me some good advice ?",
    "created_utc": 1746438066.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kf7jhg/confused_programmer/",
    "score": 51,
    "num_comments": 19
  },
  {
    "subreddit": "learnprogramming",
    "title": "Built a full-stack project to solve \u201cwhat should I watch next?\u201d \u2014 open to feedback & learning",
    "text": "Hey devs,  \nI\u2019ve been working on a full-stack project to help users find their next movie/show/anime based on their preferences (genre + streaming platform).\n\nIt\u2019s a **non-commercial** tool with a watchlist feature \u2014 and I\u2019m planning to open source it soon for learning and collaboration.\n\nThe idea came from noticing how often people ask *\u201cIs this on Netflix?\u201d*. This aims to make discovery and tracking easier.\n\nWould love feedback on features or code once I drop the repo.  \nLink to the app is in the comments.",
    "created_utc": 1746435964.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kf721r/built_a_fullstack_project_to_solve_what_should_i/",
    "score": 0,
    "num_comments": 1
  },
  {
    "subreddit": "learnprogramming",
    "title": "Be realistic, what's the roadmap to a good high paying job?",
    "text": "Every body says you have to have a good skillset to score a job when it comes to CS and programming. I'm honestly new to this. I'm still 19 and i want to utilize my time to get as good as possible in this field. What should I focus on? What programming languages should I learn? What projects should I make? Help a newbie out. I work better when I have a roadmap in front of me. \n",
    "created_utc": 1746433801.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kf6k8y/be_realistic_whats_the_roadmap_to_a_good_high/",
    "score": 177,
    "num_comments": 79
  },
  {
    "subreddit": "learnprogramming",
    "title": "Anyone know about online programming course without proctored exam for college credit?",
    "text": "Anyone know about online programming course without proctored exam for college credit?\n\nI'm looking for basic of online programming course.\n\n  \nCan you recommend which univ offer this courses for credit? (Accredited)\n\n(I'm international student, so I can't enroll WGU or oakton college)",
    "created_utc": 1746433120.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kf6eus/anyone_know_about_online_programming_course/",
    "score": 0,
    "num_comments": 2
  },
  {
    "subreddit": "learnprogramming",
    "title": "As a frontend developer suck at UI design.",
    "text": "I am learning MERN stack development and have completed frontend development. I can easily write the logic of a website. If I am copying a website, I will figure out how to design its components, or I will be able to create them without assistance.\n\nThe issue arises when I attempt to design everything from scratch in my own head.\n\nI realize that I fail as a UI designer.\n\nIs this normal? ",
    "created_utc": 1746431888.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kf64ly/as_a_frontend_developer_suck_at_ui_design/",
    "score": 42,
    "num_comments": 19
  },
  {
    "subreddit": "learnprogramming",
    "title": "Thinking about picking up coding for a thing to persue in uni/college",
    "text": "18m and finished high school last year august, been working for a bit but that work place closed so now kinda left with not much and started thinking about what to pursue, coding has been something to consider to due i guess parents talking about IT  being a decent career, but i guess i just like games and was curious about game dev,. But i have no real idea were to start or what questions to ask so im kinda stuck and unsure, help and advise would be great.",
    "created_utc": 1746428958.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kf5h56/thinking_about_picking_up_coding_for_a_thing_to/",
    "score": 2,
    "num_comments": 1
  },
  {
    "subreddit": "learnprogramming",
    "title": "learning web dev and OOP combine?",
    "text": "**Hello everyone,**  I'm just stuck managing web dev and OOP (C++)  How can I learn and manage both.  \nneed a best suggestion of you guys.  \nwhich one is more beneficial to learn first?  \nThanks.",
    "created_utc": 1746425937.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kf4rk2/learning_web_dev_and_oop_combine/",
    "score": 18,
    "num_comments": 6
  },
  {
    "subreddit": "learnprogramming",
    "title": "Switching Gears??",
    "text": "Hey!\n\nI have been looking into google certificates, specifically Cyber Security and Data Analytics, and would love some honest opinions on if they are worth the time and money. I currently already have three degrees, that are not tech related, but have not been able to find my place/a solid career path. My though process is to switch gears and step into a new industry, but I am not sure if these courses would teach me enough to land a job. Help please lol ",
    "created_utc": 1746419497.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kf35h8/switching_gears/",
    "score": 1,
    "num_comments": 0
  },
  {
    "subreddit": "learnprogramming",
    "title": "How Can I Start Building a Desktop App?",
    "text": "Hi! So, I\u2019ve been learning to program recently, and I had the idea to make a desktop app specifically for chess training.  \nThe idea is to create a simple but useful tool that helps track and plan chess study sessions.\n\nHere\u2019s what I\u2019m thinking it could include:\n\n* Logging how much time you spend training and breaking it down by category (like tactics, openings, endgames, etc.)\n* Weekly planning (customizable by category or phase)\n* Personal notes for each session\n* Stats over time (weekly/monthly) with charts\n* Daily reminders and puzzles based on what you\u2019ve been training\n* The option to export all your data to CSV or Excel\n\nI\u2019m still pretty new to all this, and I don\u2019t really know everything that goes into building an app like this, and I'm not sure what would be the best language or tools to use\u2014especially for building the UI, storing the data, and maybe even connecting it to platforms like Lichess or [Chess.com](http://Chess.com) in the future.\n\nSo my question is:  \n**What does it actually take to build a desktop app like this? What programming languages, tools, or technologies would you recommend? And where should I start if I want to learn how to build it from scratch?**",
    "created_utc": 1746416510.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kf2b7z/how_can_i_start_building_a_desktop_app/",
    "score": 25,
    "num_comments": 22
  },
  {
    "subreddit": "learnprogramming",
    "title": "Coursera Java autograder failing tests even though output looks correct \u2014 need help",
    "text": "I am taking a java course on Coursera and I'm stuck with 3 failing test cases in the autograder:\n\n\\- testAddExamFunctionality: Expected \"Exam added: 2024-12-12 - Room 122\"\n\n\\- testViewNextExamFunctionality: Expected \"2024-12-12 - Room 122\"\n\n\\- testViewPreviousExamFunctionality: Expected previous exam to be printed\n\n  \nI tested it manually and it prints the expected results, but Coursera's grader still says the test failed. Is there something I'm missing with formatting, newline, or maybe how the output is expected?\n\n  \nAny help would be awesome!\n\nHeres my code:\n\n    1. ExamNode.java\n    \u00a0\u00a0 \u00a0 \u00a0\n    public class ExamNode {\n    \u00a0 \u00a0 String examDetails;\n    \u00a0 \u00a0 ExamNode next;\n    \u00a0 \u00a0 ExamNode prev;\n    \n    \u00a0 \u00a0 public ExamNode(String examDetails) {\n    \u00a0 \u00a0 \u00a0 \u00a0 this.examDetails = examDetails;\n    \u00a0 \u00a0 \u00a0 \u00a0 this.next = null;\n    \u00a0 \u00a0 \u00a0 \u00a0 this.prev = null;\n    \u00a0 \u00a0 }\n    }\n    \u00a0\u00a0 \u00a0\n    \n    2. Student.java\n    \u00a0\u00a0 \u00a0 \u00a0\n    public class Student {\n    \u00a0 \u00a0 private String name;\n    \u00a0 \u00a0 private ExamSchedule examSchedule;\n    \n    \u00a0 \u00a0 public Student(String name) {\n    \u00a0 \u00a0 \u00a0 \u00a0 this.name = name;\n    \u00a0 \u00a0 \u00a0 \u00a0 this.examSchedule = new ExamSchedule();\n    \u00a0 \u00a0 }\n    \n    \u00a0 \u00a0 public String getName() {\n    \u00a0 \u00a0 \u00a0 \u00a0 return name;\n    \u00a0 \u00a0 }\n    \n    \u00a0 \u00a0 public ExamSchedule getExamSchedule() {\n    \u00a0 \u00a0 \u00a0 \u00a0 return examSchedule;\n    \u00a0 \u00a0 }\n    }\n    \n    \n    3. StudentInfoSystem.java\n    \u00a0\u00a0 \u00a0 \u00a0\n    import java.util.ArrayList;\n    \n    public class StudentInfoSystem {\n    \u00a0 \u00a0 private static ArrayList<Student> students = new ArrayList<>();\n    \n    \u00a0 \u00a0 static boolean addStudent(Student student) {\n    \u00a0 \u00a0 \u00a0 \u00a0 if (student != null && student.getName() != null && !student.getName().trim().isEmpty()) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 students.add(student);\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Student added: \" + student.getName());\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return true;\n    \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Failed to add student.\");\n    \u00a0 \u00a0 \u00a0 \u00a0 return false;\n    \u00a0 \u00a0 }\n    \n    \u00a0 \u00a0 static Student findStudentByName(String name) {\n    \u00a0 \u00a0 \u00a0 \u00a0 if (name == null || name.trim().isEmpty()) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return null;\n    \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 for (Student student : students) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 if (student.getName().equalsIgnoreCase(name.trim())) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return student;\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 return null;\n    \u00a0 \u00a0 }\n    }\n    \n    \n    4. ExamSchedule.java\n    \u00a0\u00a0 \u00a0 \u00a0\n    public class ExamSchedule {\n    \u00a0 \u00a0 private ExamNode head;\n    \u00a0 \u00a0 private ExamNode current;\n    \n    \u00a0 \u00a0 public ExamSchedule() {\n    \u00a0 \u00a0 \u00a0 \u00a0 this.head = null;\n    \u00a0 \u00a0 \u00a0 \u00a0 this.current = null;\n    \u00a0 \u00a0 }\n    \n    \u00a0 \u00a0 public void addExam(String examDetails) {\n    \u00a0 \u00a0 \u00a0 \u00a0 ExamNode newNode = new ExamNode(examDetails);\n    \n    \u00a0 \u00a0 \u00a0 \u00a0 if (head == null) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 head = newNode;\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 current = newNode;\n    \u00a0 \u00a0 \u00a0 \u00a0 } else {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ExamNode temp = head;\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 while (temp.next != null) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 temp = temp.next;\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 temp.next = newNode;\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 newNode.prev = temp;\n    \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Exam added: \" + examDetails);\n    \u00a0 \u00a0 }\n    \n    \u00a0 \u00a0 public void viewNextExam() {\n    \u00a0 \u00a0 \u00a0 \u00a0 if (current == null) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 if (head == null) {\n    \u00a0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"No exams scheduled.\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } else {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"No current exam selected or end of schedule reached.\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 } else {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Next Exam: \" + current.examDetails);\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 if (current.next != null) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 current = current.next;\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } else {\n    \u00a0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"You have reached the last exam.\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 }\n    \n    \u00a0 \u00a0 public void viewPreviousExam() {\n    \u00a0\u00a0 \u00a0 \u00a0 \u00a0 if (current == null) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 if (head == null) {\n    \u00a0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"No exams scheduled.\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } else {\n    \u00a0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"No current exam selected or beginning of schedule reached.\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0\u00a0 \u00a0 \u00a0 \u00a0 } else {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Previous Exam: \" + current.examDetails);\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 if (current.prev != null) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 current = current.prev;\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } else {\n    \u00a0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"You have reached the first exam.\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 }\n    \n    \u00a0 \u00a0 public void viewAllExamSchedule() {\n    \u00a0 \u00a0 \u00a0 \u00a0 ExamNode temp = head;\n    \u00a0 \u00a0 \u00a0 \u00a0 if (temp == null) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"No exams scheduled.\");\n    \u00a0 \u00a0 \u00a0 \u00a0 } else {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Exam Schedule:\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 while (temp != null) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(temp.examDetails);\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 temp = temp.next;\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 }\n    }\n    \u00a0\u00a0 \u00a0\n    5. Main.java\n    \u00a0\u00a0 \u00a0 \u00a0\n    import java.util.Scanner;\n    \n    public class Main {\n    \u00a0 \u00a0 public static void main(String[] args) {\n    \u00a0 \u00a0 \u00a0 \u00a0 Scanner scanner = new Scanner(System.in);\n    \n    \u00a0 \u00a0 \u00a0 \u00a0 while (true) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"\\nOptions:\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"1. Add Student\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"2. Add Exam\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"3. View Next Exam\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"4. View Previous Exam\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"5. View Student Schedule\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"6. Exit\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.print(\"Enter your choice: \");\n    \n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 int choice = -1;\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 try {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 choice = scanner.nextInt();\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } catch (java.util.InputMismatchException e) {\n    \u00a0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Invalid input. Please enter a number.\");\n    \u00a0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 scanner.nextLine();\n    \u00a0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 continue;\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 scanner.nextLine();\n    \n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 switch (choice) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 case 1:\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.print(\"Enter student name: \");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 String studentName = scanner.nextLine();\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 if (studentName != null && !studentName.trim().isEmpty()) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Student student = new Student(studentName.trim());\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 StudentInfoSystem.addStudent(student);\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } else {\n    \u00a0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Student name cannot be empty.\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 break;\n    \n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 case 2:\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.print(\"Enter student name: \");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 String nameForExam = scanner.nextLine();\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Student studentForExam = StudentInfoSystem.findStudentByName(nameForExam);\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 if (studentForExam != null) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.print(\"Enter exam date (e.g., 2024-12-12): \");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 String examDate = scanner.nextLine();\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.print(\"Enter exam location (e.g., Room 122): \");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 String examLocation = scanner.nextLine();\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 String examDetails = examDate + \" - \" + examLocation;\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 studentForExam.getExamSchedule().addExam(examDetails);\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } else {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Student not found.\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 break;\n    \n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 case 3:\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.print(\"Enter student name: \");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 String nameForNextExam = scanner.nextLine();\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Student studentForNextExam = StudentInfoSystem.findStudentByName(nameForNextExam);\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 if (studentForNextExam != null) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 studentForNextExam.getExamSchedule().viewNextExam();\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } else {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Student not found.\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 break;\n    \n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 case 4:\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.print(\"Enter student name: \");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 String nameForPreviousExam = scanner.nextLine();\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Student studentForPreviousExam = StudentInfoSystem.findStudentByName(nameForPreviousExam);\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 if (studentForPreviousExam != null) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 studentForPreviousExam.getExamSchedule().viewPreviousExam();\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } else {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Student not found.\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 break;\n    \n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 case 5:\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.print(\"Enter student name: \");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 String nameForSchedule = scanner.nextLine();\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Student studentForSchedule = StudentInfoSystem.findStudentByName(nameForSchedule);\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 if (studentForSchedule != null) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 studentForSchedule.getExamSchedule().viewAllExamSchedule();\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } else {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Student not found.\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 break;\n    \n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 case 6:\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Exiting...\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 scanner.close();\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return;\n    \n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 default:\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Invalid choice. Please try again.\");\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 }\n    }",
    "created_utc": 1746415258.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kf1xwf/coursera_java_autograder_failing_tests_even/",
    "score": 1,
    "num_comments": 0
  },
  {
    "subreddit": "learnprogramming",
    "title": "Good Learning Platforms",
    "text": "I recently finished a graduate level software testing class (they didn\u2019t have a testing class when I was getting my CS degree). So I\u2019m trying to find other resources to help me land a tech job again.\n\nI have some Udemy courses, I\u2019ve tried Codecademy in the past, and my academic advisor suggested Coursera. All I know is I cannot afford another college class.\n*Edit: I also have access to LikedIn Learning.\n\nWhat are your recommendations?",
    "created_utc": 1746406965.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kezef6/good_learning_platforms/",
    "score": 21,
    "num_comments": 5
  },
  {
    "subreddit": "learnprogramming",
    "title": "How to hide API keys when committing to GitHub",
    "text": "I\u2019m working on a frontend-heavy dashboard project involving 5-10 APIs (mostly to showcase that I know how to use them and JSON), but I\u2019m wondering how to hide the API key while keeping it functional when I host the app on GitHub pages. I\u2019ve read it involves creating a new file with the terminal (which I\u2019m not particularly comfortable using). Is there any other way of doing it? Also, what would the consequences of not hiding API keys be and will the rest of the code still be visible to people I share it with?\n\nEdit: thank you for all the comments everyone\u2014they\u2019ve been very helpful and eye opening. As an addendum, here\u2019s my plan to address all the security concerns that have been brought up:\n\n(First, though, I\u2019ve already revoked/made new API keys and haven\u2019t committed them to GitHub, so please don\u2019t worry about that anymore.)\n\n1. I think I\u2019m going to go with GitHub secrets as the most simple way to still have the page functional and secure on pages to share with potential co-ops. Alternatively, I\u2019m going to look into Netlify, which a lot of people have recommended as a simple solution. \n\n2. After that\u2019s done, I\u2019m going to create an alternate version where I use PHPmyAdmin to store the keys and then retrieve them with PHP to showcase doing both (that\u2019s the plan anyways). I\u2019ve avoided PHP since I don\u2019t really understand servers and hosting (haven\u2019t had a class on that yet). Like I don\u2019t know how to make PHP work outside my XAMPP htdocs folder, and it won\u2019t be functional for people I share with (to my knowledge).\n\nAs always, any additional advice would be appreciated, especially if there\u2019s anything wrong with my intended approaches",
    "created_utc": 1746405138.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1keyt4v/how_to_hide_api_keys_when_committing_to_github/",
    "score": 264,
    "num_comments": 67
  },
  {
    "subreddit": "learnprogramming",
    "title": "Choosing a Professional Username & Display Name for Tech Career \u2014 Need Advice!",
    "text": "Hey everyone!\n\nI\u2019m an aspiring web developer and currently setting up my online presence across platforms like GitHub, LinkedIn, and Twitter as I plan to apply for jobs and work on freelance marketplaces soon.\n\nI need advice on choosing a professional yet unique display name and username. The issue is with my full name structure. For example, let\u2019s say my full name is Syed Ahmad Shah, but Ahmad is the name I actually go by. \"Syed\" and \"Shah\" are family-related parts, yet most people (especially in email or formal communication) default to calling me Syed, which doesn\u2019t feel quite right.\n\nHere\u2019s where I need help:\n\n1. Display Name\n\nWould you suggest using Syed Ahmad Shah or just Ahmad Shah to keep things clearer and more direct?\n\nAlso, is it okay to drop \"Syed\" from the display name if it\u2019s not how I prefer to be addressed \u2014 even though it appears on my educational and official documents? Will that cause confusion when applying for jobs or doing official paperwork?\n\n\n2. Username\nHere are some options I\u2019m considering:\n\nsyedahmadshah\n\nsahmadshah\n\nahmadshah\n\nOr should I make it more brand-focused like ahmadshahdev, devahmad, or something similar?\n\n\n3. Consistency Across Platforms\nIs it preferable to have the same username across LinkedIn, GitHub, and Twitter?\nFor example, I might only get ahmadshah on one platform, but I can grab sahmadshah on all three.\nWhich is better \u2014 consistency or ideal name?\n\nFinally \u2014 does this stuff really make a difference when it comes to professional branding or job applications? I'd love to hear your experiences and suggestions!\n\nThanks. ",
    "created_utc": 1746398638.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kewl7x/choosing_a_professional_username_display_name_for/",
    "score": 3,
    "num_comments": 7
  },
  {
    "subreddit": "learnprogramming",
    "title": "Need help on adding photos to my website",
    "text": "Is there someone willing to help me add some photos ty my website im stuck and i cant bother anymore",
    "created_utc": 1746394431.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kev28a/need_help_on_adding_photos_to_my_website/",
    "score": 0,
    "num_comments": 4
  },
  {
    "subreddit": "learnprogramming",
    "title": "Help getting started with Hardware Programming",
    "text": "I recently learned some basic programming on python and with this newly obtained skill I've wanted to create a real device. The device would probably need to include a gyroscope and accelerometer, but I honestly don't even know how I would begin to implement hardware into my code. Are there any resources out there to help me learn the basics? ",
    "created_utc": 1746393786.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1keutdh/help_getting_started_with_hardware_programming/",
    "score": 6,
    "num_comments": 4
  },
  {
    "subreddit": "learnprogramming",
    "title": "Second Bachelor\u2019s in CS or Master\u2019s",
    "text": "Hey everyone!\u00a0\n\nI\u2019ve recently developed a deep passion for Computer Science. Over the past few months, I\u2019ve been working on AI, Machine Learning, and drone technology for agriculture (my current bachelor\u2019s degree), and I\u2019m starting to think about making a shift into Computer Science (CS) as my long-term career.\n\nHere\u2019s where I\u2019m at:\n\nI\u2019ve been accepted into a top 30 CS program abroad, where I\u2019ll be able to take courses in AI, ML, and Computer Vision\u2014super exciting stuff! But I\u2019m unsure about the best path to fully break into the field.\u00a0\n\nI\u2019m debating between two paths:\n\n* **Option 1: Second Bachelor\u2019s in CS** \\--> I\u2019m considering pursuing a second bachelor\u2019s degree, ideally at a top-tier university, followed by a master\u2019s in a specialized field like AI or robotics. One program that caught my eye is the **BSc at ETH Zurich**, which looks incredible. It\u2019s a top-tier university, and from what I\u2019ve read, getting in isn\u2019t impossible. However, I\u2019ve also heard that the program is intense. While I\u2019m confident in my study skills, I\u2019m worried the workload might not leave me with enough time to gain valuable experience like internships, research, or personal projects experiences I see as essential for building a successful career in CS, especially since this would be my second bachelor\u2019s.\n* **Option 2: Conversion Course + Master\u2019s** \\--> Another idea is to take a conversion course in CS and then specialize with a master\u2019s in AI, ML, or robotics. This path is faster and more flexible, but I\u2019m unsure how it would be perceived compared to a full bachelor\u2019s in CS. Would it be seen as less comprehensive by employers or academia?\n\nI\u2019m still unsure whether I want to go into research or dive straight into the industry, which makes this decision even harder.\n\n**So, here\u2019s my question:**  \nIf you were in my position, what would you choose? Is a second bachelor\u2019s degree the best way to go, or would a conversion course and master\u2019s be more effective? I\u2019d really appreciate any insights or advice based on your own experiences.\n\nThanks a lot for your time\u2014I really appreciate any help you can offer!\u00a0\n\n",
    "created_utc": 1746386261.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kerw9b/second_bachelors_in_cs_or_masters/",
    "score": 2,
    "num_comments": 2
  },
  {
    "subreddit": "learnprogramming",
    "title": "Need help: React, Tailwind or Projects as next step?",
    "text": "Hi everyone,\n\nI'm trying to learn Fullstack Webdev on the side (45-50h high-stress work during the week) - I get to invest about 2h/day into that (bit more on the weekend - so probably around 17h/week) and so far I've gotten HTML, CSS and JS down pretty well. I can basically build any interactive website and interact with APIs etc.\n\n  \nI'm at a point however where my next steps - at least the obvious ones - are to learn Tailwind and React before going into the backend. And obviously hammering down the essentials of JS to the point where I can write JS \"blind and with one hand behind my back\". I have three courses from TraversyMedia lined up:\n\nTailwind, React, 20 JS Projects.\n\n  \nIn your opinion (and if possible please add your reasoning) what is the best approach to go forward?\n\nMy fear specifically is that if I now invest the time to nail tailwind I'm going to forget half of my JS knowledge in the meantime.\n\n  \nThank you in advance for your help and I'm sorry if this has been asked before - I just didn't find a question that covers this already.",
    "created_utc": 1746378946.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kep07z/need_help_react_tailwind_or_projects_as_next_step/",
    "score": 2,
    "num_comments": 4
  },
  {
    "subreddit": "learnprogramming",
    "title": "[C++] \"No appropriate default constructor available\" for my MinHeap",
    "text": "I am working on a project to take in data to create tasks and put those task objects onto a templated array MinHeap and sort them by priority. However, I found an issue I have yet to encounter and was hoping for pointers on how to fix.\n\n>\n\nTask: no appropriate default constructor available MinHeap.h(Line 36)\n\npointing to the default constructor of the MinHeap. I have culled down most of my code to what is relevant. Any and all advice is accepted, Thank you!!\n\n\\-main.cpp-\n\n    #include <iostream>\n    #include <fstream>\n    #include <vector>\n    #include <string>\n    #include \"MinHeap.h\"\n    #include \"Task.h\"\n    \n    using namespace std;\n    int main()\n    {\n        string temp = \"\";\n        vector<Task> arr;\n    \n        ifstream infile(\"taskList.csv\");\n    \n        if (!infile.is_open()) { //check if file can be found\n            cout << \"Cant find file... Closing program...\" << endl;\n            exit(0);\n        }\n    \n        getline(infile, temp); //skipping header\n    \n        for (int i = 0; getline(infile, temp); i++) { //create object, add to array, add to MinHeap. After loop, sort MinHeap\n            Task taskObject(temp);\n            arr.push_back(taskObject);\n        }\n    \n        MinHeap<Task> heap(arr.size());\n    \n        for (int i = 0; i < arr.size(); i++) {\n            heap.insert(arr.at(i));\n            cout << \"adding item #\" << i << endl;\n        }\n    \n    }//end main\n\n\\-MinHeap.h-\n\n    #include <iostream>\n    #include <iomanip>\n    \n    using namespace std;\n    \n    template <typename T>\n    class MinHeap {\n    private:\n        T* heap;\n        int capacity;\n        int size;\n    \n        void heapifyUp(int index);\n    \n        void heapifyDown(int index);\n    public:\n    \n        MinHeap(int capacity);\n        ~MinHeap();\n    \n        void insert(const T& item);\n    \n    };\n    \n    //constructor and destructor\n    //@param  capacity   the maximum number of nodes in the heap\n    template <typename T>\n    MinHeap<T>::MinHeap(int capacity) {\n        this->capacity = capacity;\n        heap = new T[capacity];\n        size = 0;\n    }\n    \n    template <typename T>\n    MinHeap<T>::~MinHeap() {\n        cout << \"calling delete on internal heap....\\n\";\n        delete[] heap; \n    }\n    \n    //=================private helper methods===========\n    //heapifyUp() used when inserting into the heap\n    //@param  index   the position to start moving up the tree\n    template <typename T>\n    void MinHeap<T>::heapifyUp(int index) {\n        bool keepGoing = true;\n    \n        while (keepGoing && index > 0) { //maybe dont change\n            int parent = (index - 1) / 2;\n            if (heap[index] < heap[parent]) {\n                swap(heap[index], heap[parent]);\n                index = parent;\n            }\n            else {\n                keepGoing = false;\n            }\n        }\n    }//end heapifyUp()\n    \n    //heapifyDown() used when deleting from the heap\n    //@param   index   position to start moving down the heap\n    template <typename T>\n    void MinHeap<T>::heapifyDown(int index) {\n        bool keepGoing = true;\n    \n        while (keepGoing && 2 * index + 1 > size) {\n            int left = 2 * index + 1;\n            int right = 2 * index + 2;\n            int smallest = index;\n    \n            if (left < size && heap[left] < heap[smallest])\n                smallest = left;\n            if (right < size && heap[right] < heap[smallest])\n                smallest = right;\n    \n            if (smallest != index) {\n                swap(heap[index], heap[smallest]);\n                index = smallest;\n            }\n            else\n                keepGoing = false;\n        }\n    }//end heapifyDown()\n    \n    //insert into the heap - inserts at last available index, calls heapifyUp()\n    //@param  item  the item to insert into the heap\n    template <typename T>\n    void MinHeap<T>::insert(const T& item) {\n        if (size == capacity) {\n            cout << \"Heap is full!\" << endl;\n    \n        }\n        else {\n            cout << \"inserting item\" << endl;\n            heap[size] = item;\n            heapifyUp(size);\n            size++;\n        }\n    }//end insert()\n\n\\-Task.h-\n\n    #pragma once\n    #include <iostream>\n    #include <ostream>\n    \n    using namespace std;\n    \n    class Task {\n    private:\n      string name;\n      int priority;\n      int estimatedTime; //in minutes\n    \n    public:\n      Task(string input); \n      ~Task();\n    \n      //setters\n      void setName(string newName);\n      void setPriority(int newPriority);\n      void setTime(int newTime);\n    \n      //getters\n      string getName();\n      int getPriority();\n      int getTime();\n    \n      //overloaded operators\n      friend ostream& operator<<(ostream& os, Task& task);\n    \n    };\n\n\\-Task.cpp-\n\n    #include \"Task.h\"\n    #include <iostream>\n    #include <string>\n    #include <sstream>\n    using namespace std;\n    \n    Task::Task(string input) {\n      string temp = \"\";\n      istringstream iss(input);\n    \n      for (int i = 0; getline(iss, temp, ','); i++) {\n        if (i == 0)\n          name = temp;\n        if (i == 1)\n          priority = stoi(temp);\n        if (i == 2)\n          estimatedTime = stoi(temp);\n      }\n    \n    } //end Task constructor\n    \n    Task::~Task() {\n    \n    }//end Task deconstructor\n    \n    //setters\n    void Task::setName(string newName) {\n      name = newName;\n    }//end setName()\n    \n    void Task::setPriority(int newPriority) {\n      priority = newPriority;\n    }//end setPriority()\n    \n    void Task::setTime(int newTime) {\n      estimatedTime = newTime;\n    }//end setTime()\n    \n    //getters\n    string Task::getName() {\n      return name;\n    }//end getName()\n    \n    int Task::getPriority() {\n      return priority;\n    }//end getPriority()\n    \n    int Task::getTime() {\n      return estimatedTime;\n    }//end getTime()\n    \n    //overloaded operators\n    ostream& operator<<(ostream& os, Task& task) {\n      os << \"--- << endl;\n      //unfinished\n      return os;\n    }\n\n\\-taskList.csv-\n\n    Title,Priority,EstimatedTime,\n    Complete CTP 250 lab,1,120,\n    Grocery Shopping,3,60,\n    Submit Tax Return,1,90,\n    Walk the Dog,5,30,\n    Prepare BIO 230 Presentation,2,75,\n    Call Doctor,4,20,\n    Read Chapter 5 for ENG 112,3,100,\n    Clean Desk,5,20,\n    Backup Laptop,5,40,\n    Reply to Emails,2,25,\n    Workout,4,60,\n    Plan Weekend Trip,3,90,\n    Water Plants,4,20,\n    Research Internship,2,90,\n    Pay Credit Card Bill,1,5,\n    Update Resume,3,40,\n    Buy Birthday Gift,2,30,\n    Study for BPA 111 Quiz,2,60,\n    Organize Notes for CTS 107,4,45,\n    Refill Prescription,2,20,",
    "created_utc": 1746377630.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1keohka/c_no_appropriate_default_constructor_available/",
    "score": 3,
    "num_comments": 4
  },
  {
    "subreddit": "learnprogramming",
    "title": "Building a Smart Indoor Tracker (with AR + ESP32 + BLE + Unity) \u2014 Need Guidance!",
    "text": "Hey everyone! \n\nI\u2019m working on a unique project \u2014 a **smart object tracker** that helps you find things like wallets, keys, or bags inside your home with **high indoor accuracy**, using components like:\n\n* ESP32-WROOM\n* BLE + ToF + IMU (MPU6050)\n* GPS (Neo M8N, mostly for outdoor fallback)\n* Unity app with **AR directional UI (arrow-based)**\n\nI\u2019ve done **a lot of research**, designed a concept, selected parts, and planned multiple phases (hardware, positioning logic, app UI, AR). I\u2019m using **Unity Visual Scripting** because I don\u2019t know coding. I want to build this step by step and just need a **mentor or someone kind enough to help guide or correct me** when I\u2019m stuck.\n\nIf you\u2019ve worked on **BLE indoor tracking**, **Unity AR apps**, or **ESP32 sensors**, and can just nudge me in the right direction now and then, it would mean the world. I'm not asking for someone to do the work \u2014 I just need a lighthouse \n\nFeel free to comment, DM, or point me to better tutorials/resources. I\u2019ll share my progress and give credit too!\n\nThanks a ton in advance to this amazing community \ud83d\ude4c\n\n\u2014  \n**Tools I\u2019m using:**  \nESP32, MPU6050, VL53L0X, Unity (AR Foundation), GPS module, BLE trilateration",
    "created_utc": 1746371887.0,
    "url": "https://www.reddit.com/r/learnprogramming/comments/1kem8o2/building_a_smart_indoor_tracker_with_ar_esp32_ble/",
    "score": 1,
    "num_comments": 0
  },
  {
    "subreddit": "webdev",
    "title": "Why Data Quality Should Be a Priority for Every Business",
    "text": "In today\u2019s data-driven world, companies rely on data for everything from customer insights to operational optimization. But if the data you base your decisions on is flawed, the outcomes will be too. That\u2019s why a growing number of businesses are focusing not just on having data\u200a\u2014\u200abut on ensuring its quality through measurable [data quality metrics](https://www.promptcloud.com/blog/how-promptcloud-achieves-data-quality-metrics/?utm_source=reddit&utm_medium=social&utm_campaign=socialpost_06may2025).\n\nPoor-quality data can skew business forecasts, misinform strategies, and even damage customer relationships. According to Gartner, the financial impact of poor data quality averages $12.9 million per year for organizations\u200a\u2014\u200amaking a clear case for treating data quality as a first-order concern.\n\n# The Role of Data Quality\u00a0Metrics\n\nMeasuring the health of your data starts with the right metrics. These include accuracy, completeness, consistency, timeliness, validity, and uniqueness. When each of these is monitored consistently, they help teams ensure the [reliability of the data pipelines](https://www.promptcloud.com/blog/assessing-data-quality-how-to/?utm_source=reddit&utm_medium=social&utm_campaign=socialpost_06may2025) feeding into business systems.\n\nFor example, timeliness becomes critical for use cases like price intelligence or competitor tracking, where outdated inputs can mislead decision-makers. Similarly, validating format rules and ensuring uniqueness are especially vital in large-scale [data scraping projects](https://www.promptcloud.com/blog/guide-to-web-scraping-process/?utm_source=reddit&utm_medium=social&utm_campaign=socialpost_06may2025) where duplicate or malformed data can spiral quickly.\n\n# How to Measure and Maintain Data\u00a0Quality\n\nA structured approach to monitoring data quality starts with a baseline assessment. Businesses should begin by evaluating the existing state of their data, identifying missing fields, inconsistencies, and inaccuracies.\n\nFrom there, automation plays a key role. With scalable tools in place, it\u2019s possible to run checks at each stage of the [data extraction process](https://www.promptcloud.com/blog/what-is-data-extraction-and-how-does-it-work/?utm_source=reddit&utm_medium=social&utm_campaign=socialpost_06may2025), helping prevent issues before they impact downstream systems.\n\nFinally, monitoring should be ongoing. As business needs evolve and data sources change, tracking quality over time is essential for maintaining trust in your data infrastructure.\n\n# How [PromptCloud](https://www.promptcloud.com/?utm_source=reddit&utm_medium=social&utm_campaign=socialpost_06may2025) Embeds Quality in Every\u00a0Dataset\n\nAt [PromptCloud](https://www.promptcloud.com/?utm_source=reddit&utm_medium=social&utm_campaign=socialpost_06may2025), we\u2019ve designed our workflows to prioritize quality from the start. Our [web scraping process](https://www.promptcloud.com/blog/guide-to-web-scraping-process/?utm_source=reddit&utm_medium=social&utm_campaign=socialpost_06may2025) includes automated validation, real-time anomaly detection, and configurable deduplication to ensure accuracy and relevance.\n\nWe also focus on standardization\u200a\u2014\u200aensuring that data from different sources aligns with a unified schema. And with compliance built in, our solutions are aligned with [data privacy regulations like GDPR and CCPA](https://www.promptcloud.com/blog/compliant-data-solutions-by-promptcloud/?utm_source=reddit&utm_medium=social&utm_campaign=socialpost_06may2025), helping clients avoid legal risk while scaling their data operations.\n\n# Conclusion\n\nWhen data quality becomes a foundational part of your data strategy, the benefits ripple across every function\u200a\u2014\u200afrom marketing to analytics to executive decision-making. By working with partners who embed quality at every stage, businesses can turn raw data into reliable intelligence.\n\nIf you\u2019re interested in how high-quality data can support better decisions across the board, our post on [how data extraction transforms decision-making](https://www.promptcloud.com/blog/data-extraction-transforming-decision-making/?utm_source=reddit&utm_medium=social&utm_campaign=socialpost_06may2025) offers deeper insight.",
    "created_utc": 1746522594.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kfzytx/why_data_quality_should_be_a_priority_for_every/",
    "score": 0,
    "num_comments": 1
  },
  {
    "subreddit": "webdev",
    "title": "Help: Pull to refresh replication mystery on Chrome",
    "text": "Hi all, I need some help! \nI have a drop-down list that is basically a giant carousel with vertically aligned buttons where you swipe up and down the page to go to the higher/lower button elements. This has been working unchanged for months. Recently a couple of users have reported that by swiping down would trigger the pull to refresh gesture on Chrome, making the drop-down unusable. They are on Android.\nHowever, I cannot replicate this myself. There isn't much to do, is just a dropdown, and i tried on different phone with android/chrome and I can't get the pull to refresh thing to happens.\n\nAny idea why?\nTo see the drop-down I am talking about:\nhttps://theaipeeps.com/chat then click on the magic wand on the top right (on the navbar). Then click on any selector such as \"Country\" and swipe down. That's the drop-down causing trouble.\nWould love some help, I am at loss. ",
    "created_utc": 1746505237.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kfvusg/help_pull_to_refresh_replication_mystery_on_chrome/",
    "score": 1,
    "num_comments": 0
  },
  {
    "subreddit": "webdev",
    "title": "Which Hosting to choose for a website with ~100 pictures uploaded per day by users",
    "text": "The website is mostly of the pictures posted by users. Please advice any good cloud storage that is easily scalable. My dev told me to go with digital ocean. They have so many pricings and I am lil confused. Any help what to choose (droplets or kubernotes)? Also any alternatives? Thank you.",
    "created_utc": 1746504327.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kfvlqx/which_hosting_to_choose_for_a_website_with_100/",
    "score": 5,
    "num_comments": 22
  },
  {
    "subreddit": "webdev",
    "title": "\"Locked\" Inspector Stylesheet",
    "text": "So, I recently was modifying and testing something in CSS via inspector-stylesheet and all of a sudden it got... Locked?? I don't know how else to explain it.\n\nI can create a new inspector-stylesheet and I can modify them in the elements section, but when I go to the source it's not letting me delete or write anything else in there. I can modify other stylesheets, it's only the inspector-stylesheet that is 'locked'. Does anyone know how to solve this issue?\n\nThe issue is happening on Brave Browser, I have tested Firefox and Chrome and the issue is not showing up there, so, it might be a Brave issue??? I have googled it but haven't found an answer. I would appreciate any help and I apologize if this isn't the place to leave this issue.",
    "created_utc": 1746498921.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kftyzk/locked_inspector_stylesheet/",
    "score": 1,
    "num_comments": 0
  },
  {
    "subreddit": "webdev",
    "title": "What questions to ask web developers before signing the contract with them.",
    "text": "I\u2019m talking to few developers to create a non-ecommerce website for me. I need some basic features like live chat, calendar for appts, contact forms, WhatsApp integration. Most of them are including 1 year of hosting then I will be charged from year 2 for $150-200 per year. \n\nI\u2019m new to all this and I understand devil is in details. What specific questions I should ask them to avoid any surprises later on? I\u2019m not sure what to ask them about design, delivery, plugins, hosting, domain email setup etc etc. Please help. ",
    "created_utc": 1746489275.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kfqrrd/what_questions_to_ask_web_developers_before/",
    "score": 0,
    "num_comments": 18
  },
  {
    "subreddit": "webdev",
    "title": "Setup 1099-K Forms for Sellers on Stripe Connect?",
    "text": "Hello! I\u2019ll try to make this short.\n\nI need to find an article/guide on how to generate 1099-K forms for sellers on my online marketplace.\n\nI have seen one or two guides on Stripe, BUT those documents detail how to setup 1099-K generation when the SELLER PAYS THE STRIPE CC PROCESSING FEE, or the PLATFORM PAYS THE PROCESSING FEE.\n\nOn my platform, the CUSTOMER PAYS THE STRIPE CREDIT CARD PROCESSING FEE.\n\nI\u2019m not sure why the professing fees and 1099-K forms are connected\u2026 Can anyone help me find a guide on how to setup 1099-K forms for sellers when customers are paying the Stripe CC processing fee?\n\nThanks!",
    "created_utc": 1746488802.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kfqlx4/setup_1099k_forms_for_sellers_on_stripe_connect/",
    "score": 0,
    "num_comments": 0
  },
  {
    "subreddit": "webdev",
    "title": "How can I view all network requests in Chrome when doing a search?",
    "text": "Hi.\n\nI'm using Maricopa County's GIS to view property information. https://experience.arcgis.com/experience/bd50c51b89054238bfadf69e91b421c9\n\nTheir site allows only one parcel number per query.\n\nWhen performing a search, I have the Network tab open in Chome and I'm looking for possible APIs, to see if there's a way to request info for more than one property at a time.\n\nIn the XHR tab I see 27/479 requests. I can only see the first 27 and I can't scroll down to see more of them. \n\nI've Googled \"chrome view all network requests\" but the answers are over my head. \n\nI've also searched in the Network tab for the URLs I'M interested in seeing but nothing comes back. \n\nHow can I see the other requests? Thanks.",
    "created_utc": 1746482684.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kfodve/how_can_i_view_all_network_requests_in_chrome/",
    "score": 1,
    "num_comments": 7
  },
  {
    "subreddit": "webdev",
    "title": "Discuss SaaS idea - API wrapper",
    "text": "Hello everyone!\n\nI am building a tool that turns *any* API (yours or third-party) into a full SaaS website,. with a UI, user auth, billing, and deploy, in one click. It is a no-code solution, where you just enter an API and get a full website, with the possibility to chose between different UI that suits your needs. However, it will also come with the option of full customizability for developers, where you get access to the source code and are able to build further on the website and customize it to your needs.\n\nSo far I've only managed to build an MVP for showcasing how it should work, but I am working on it until I end up with the final solution.  \nWhy this SaaS you may ask? This helps me, and other devs, to simply create a complete SaaS from just an API, instead of having to create a website from scratch. This tool wraps any REST API into a React frontend, adds login/signup (Clerk/Supabase), Stripe billing, and even deploys to Vercel.\n\nI would love your feedback and ideas!",
    "created_utc": 1746480932.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kfnp0t/discuss_saas_idea_api_wrapper/",
    "score": 1,
    "num_comments": 3
  },
  {
    "subreddit": "webdev",
    "title": "Scalability for a web-based daily word game",
    "text": "Hey fellow devs!\n\nI started my game development journey in 2023 with a daily web-based word game. I learned a great deal from its eventual failure and the issues that essentially held it back. If you are in this space or want to get into daily web games, I've written a piece on the lessons I learned about scalability and database optimization that might help you in your own journey.\n\n",
    "created_utc": 1746472818.0,
    "url": "https://www.wfhgames.com/blog/unzipped-laying-the-foundation",
    "score": 1,
    "num_comments": 0
  },
  {
    "subreddit": "webdev",
    "title": "Routine to get programmatically better",
    "text": "Hey fellow webdevs,\n\nI have an issue. I have no problem working at my current job working with various systems/technologies e.g. Shopify Liquid, NextJS, Twitter, Astro etc. I can build components well but these are mostly not challenging programmatically.\n\nI see my lack there and would like to build a habit to get better. Do you have any daily/weekly routine which helped you? Do you have any other advice?",
    "created_utc": 1746465129.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kfh249/routine_to_get_programmatically_better/",
    "score": 0,
    "num_comments": 10
  },
  {
    "subreddit": "webdev",
    "title": "How to import assets outside Vite root ?",
    "text": "Context:\n\n1. I have a VPS running Coolify (a self-hosted Netlify alternative that deploys apps in docker containers).\n\n2. I have extra storage mounted in /mnt/disk, and in there are images I need to be able to import.\n\n3. My app is an Astro site, and /mnt/disk is mounted to the Docker container in /external.\n\n  \nI need to be able to import or glob the images in /external, so I can use Astro's <Image /> component, which creates an optimized version of the image.\n\n  \nOn my local instance, I succeed in doing this in several ways:  \n  \n1.  Simply using a relative path: ../external  \n2. Bind mounting /external inside /app/src/assets/  \n3. Symlinking /external to /app/src/assets/external\n\nHowever, on production, NOTHING works. I can see the mount with all my images, and with the symlink method I can also see the content in /app/src/assets/external. So the dir is there.\n\nIf I symlink to Astro's /public directory, I can browse to my images in my browser, so there are no permission/ownership issues.\n\nIn my Astro config and tsconfig.json, I've tried many variants of server.fs, and resolve.alias entries. Using absolute paths, relative paths, using path.resolve() etc, I tried so many solutions, but nothing works. I've tried asking in the Astro, Coolify and Vite Discord's but haven't been able to solve it so far.\n\nBeen struggling with this for several days now, so hoping someone here might know the solution.",
    "created_utc": 1746455756.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kfd5yn/how_to_import_assets_outside_vite_root/",
    "score": 1,
    "num_comments": 12
  },
  {
    "subreddit": "webdev",
    "title": "Interview for the same company from 2 recruiters (UK)",
    "text": "Hey, I'm in a bit of an awkward position and could do with some advice.\n\nI had a recruiter reach out to me last week about a role that was coming up. I said they could send my CV over.\n\nOn Friday a different recruitment company called me about the role, I said I'd already been put forward and they said they had exclusivity for the role for 3 weeks so I can't have done. So they got me to sign something saying they will represent me.\n\nThe first recruiter came back to me with an interview at 9am on Wednesday. This isn't the first time this company has used me to get into a company and after the second time I told her if she did it again I would never use them again.\n\nSo now I don't know how to proceed, or even if I want to proceed. If a company gives exclusivity to a recruitment company but then goes against that, then that doesn't fill me with much trust.",
    "created_utc": 1746454033.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kfchvr/interview_for_the_same_company_from_2_recruiters/",
    "score": 6,
    "num_comments": 6
  },
  {
    "subreddit": "webdev",
    "title": "Just build it yourself",
    "text": "I've been super frustrated with bloated projects and dependencies in web development lately. It's like we allowed this huge trash pile of junk to accumulate right under our noses, and haven't bothered to do  anything about it.\n\nSo, I've been trying something different. I've had some success with this at work, and have made it my default mode for side projects:\n\nNext time you're reaching for that npm module, ruby gem, or rust crate, or whatever, consider just building it yourself instead.\n\nWhen I was younger and less confident around other developers I would often build things myself, and get scolded by \"wiser\" developers for re-inventing the wheel, wasting time, and being reckless.\n\nBut, there are benefits we can't ignore:\n\nThe first benefit of building it yourself: Your dependency tree is going to be much smaller and easier to manage. You decide when and where to update your code instead of having it pulled out from under you by some remote update 99 levels deep in the dependency tree.\n\nThe second benefit of building it yourself: Your system will be far more robust, because you'll know most of the code in it and you'll be able to fix it almost immediately. You're far less dependent on other people.\n\nHave you ever pulled in a dependency update to fix a bug, just to discover it breaks a bunch of your existing, perfectly functional code?\n\nThe third benefit of building it yourself: You'll learn how something works, which is going to be insanely valuable in the future. You're investing in yourself, your team, and your product in a very impactful way. Don't underestimate the value of understanding your code and what it does.\n\nDon't be shackled by stupid religious programming edicts like \"Don't repeat yourself\". If someone throws that at you, throw it right back.",
    "created_utc": 1746448701.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kfaks1/just_build_it_yourself/",
    "score": 0,
    "num_comments": 31
  },
  {
    "subreddit": "webdev",
    "title": "I built a VSCode extension that shows array sizes directly in your code\u2014would love feedback from other devs!",
    "text": "Hey everyone!\n\nI\u2019ve been working on a VSCode extension called **Array Size Extension**, and I wanted to share it with you all to get some feedback or maybe help out others who run into the same problem I had.\n\nIf you\u2019re like me, you\u2019ve probably spent too much time manually counting the number of elements in arrays while coding. It\u2019s not the most fun task, especially when you're dealing with complex structures. So, I decided to build something to make that easier.\n\nThis extension shows the **size of arrays directly in your code** as inlay hints, so you don\u2019t have to count manually. Here\u2019s what it does:\n\n* **Real-time size display**: It automatically shows you the size of arrays as you code.\n* **Handles complex arrays**: Works with arrays of strings, objects, and even nested arrays.\n* **JavaScript and TypeScript support**: Fully compatible with both languages.\n* **Lightweight**: I kept performance in mind\u2014doesn\u2019t slow down your editor.\n\nFor example, if you have:\n\n    const myArray = [1, 2, 3, 4, 5]; // It shows: [5]\n    const myComplexArray = ['a,b', { name: 'test' }, [1, 2]]; // It shows: [3]\n\nIt also works for JSON files !!  \n\n\n    \"mixedArray\": [1, \"string\", true, null, 3.14] // // It shows: [5]\n    \"nestedArrays\": [\n        [1, 2],\n        [3, 4, 5],\n        [6, 7, 8, 9]\n      ] // It shows: [3]\n\n  \nI\u2019ve found it pretty useful while coding, and I hope it might be helpful to you too!\n\nHere\u2019s the [link to the extension on the VSCode marketplace](https://marketplace.visualstudio.com/items/?itemName=VincentDevalliere.array-size-extension).\n\nLet me know what you think, and if you have any suggestions or bugs to report, feel free to share. I\u2019m always open to feedback to make it better!",
    "created_utc": 1746448662.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kfakas/i_built_a_vscode_extension_that_shows_array_sizes/",
    "score": 16,
    "num_comments": 19
  },
  {
    "subreddit": "webdev",
    "title": "Found a helpful vscode extension for those watching playoff basketball while web devving!",
    "text": "I'm totally locked into the playoffs rn, but I found alt tabbing while coding super distracting.  \nSo while browsing the VSCode marketplace, I found this extension - NBA Live!  \nIt tracks the **current game**, and **current stats** neatly in the taskbar!\n\n[Stephen Currys Stats during HOU vs GSW game a few days back!](https://preview.redd.it/f43qpx0ojyye1.png?width=640&format=png&auto=webp&s=60ad5925395408a17f7dc4519b8d0692b9c40058)\n\nLink if you are interested: \u00a0[**NBA Live on the VS Code Marketplace**](https://marketplace.visualstudio.com/items/?itemName=fromfuchsia.nbalive)",
    "created_utc": 1746448543.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kfaix8/found_a_helpful_vscode_extension_for_those/",
    "score": 0,
    "num_comments": 0
  },
  {
    "subreddit": "webdev",
    "title": "NextJS page \"crashes\" for 2-3 mins before being able to interact with it.",
    "text": "Hi!  \nI'm using Next for front and laravel/breeze starter kit for backend.  \nEverything worked as intented (Auth, get, ...).  \nBut yesterday it started doing this weird behavior of crashing the front and having to wait literals minutes to be able to interact with it.  \nAnd that's with EACH page.\n\nHas anyone already faced this issue ?  \nHow to handle it ?",
    "created_utc": 1746447124.0,
    "url": "https://i.redd.it/lwlq154mfyye1.gif",
    "score": 0,
    "num_comments": 21
  },
  {
    "subreddit": "webdev",
    "title": "F1 Fantasy tool kind of idea\u2026 is this even possible without zero coding knowledge?",
    "text": "\nHey everyone!\n\nBig F1 fan here, and I get really into F1 Fantasy. I spend a lot of time trying to figure out the best team, looking at stats, guessing who's gonna be good at which track...\n\nI had this idea for a website/tool that could help make those decisions a bit easier\n\nImagine a place where you could see:\n\nHow drivers actually perform on different types of tracks\n\nSome cool historical stats presented nicely.\n\n Maybe even some basic insights into potential points or price changes? (Not sure how feasible this part is!)\n \nMostly to view de performance of a team or a driver on a track.\n\n Quick look at the weather for the race weekend.\n\nBasically, a dashboard.\n\nI have basically zero coding knowledge. Like, nada. I wouldn't know where to start writing actual code\n\nBUT... I've been doing some digging!\n\n I actually found this cool API called HypRace on RapidAPI that seems to have tons of historical F1 data (results, drivers, tracks, standings - back to the dinosaurs, almost!). So getting the raw F1 data might be possible without scraping tons of tables myself. \n\n\nThis got me thinking about No-Code / Low-Code tools. I've heard names like Bubble, Softr, etc. Could these actually let someone like me build something like this visually?\n\nMy Big Questions :\n\n Is this idea even doable with No-Code tools?\n\nThe API has race results, but not the actual prices from the official F1 Fantasy game. How could I possibly get those updated prices onto my site without coding/scraping (which sounds super hard)? Has anyone managed something like this?\n\nHow would No-Code handle things like calculating potential points or suggesting optimized teams? Can you even build that kind of logic visually, or does it get crazy complicated?\n\nAny tool recommendations? If you've used No-Code for data-heavy sites or API stuff, which platforms felt intuitive for a beginner but were still powerful?\n\nJust looking for a reality check, any advice, tips, or maybe just to hear if anyone else has going down a similar path!",
    "created_utc": 1746445080.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kf9fjc/f1_fantasy_tool_kind_of_idea_is_this_even/",
    "score": 0,
    "num_comments": 4
  },
  {
    "subreddit": "webdev",
    "title": "Need Advice: 3x Salary Offer for Fullstack Role, But It\u2019s a One-Man Show. Go for it?",
    "text": "  Hi. Everyone. \n\nPlease bear with me, I hope this is the right place to ask. \n\nI\u2019m currently a jr web developer and have been working in my first proper dev job for almost a year. The pay is on the lower end, but I\u2019m gaining experience. Before this, I was a research assistant at a university doing Python and data-related work.\n\nNow I\u2019ve been offered a new role\u2014by a university again\u2014that would pay me 3x my current salary. The catch? I\u2019d be the only tech person on the project. They\u2019re launching a community transformation program to help modernize local businesses, and they want to build an eCommerce platform for one of the businesses involved.\n\nIf I take the role, I\u2019ll have to be, the business analyst, the designer, the fullstack developer, DevOps, basically everything\n\nIt feels like a huge undertaking, but the pay bump is very tempting. Plus, eCommerce isn\u2019t exactly uncharted territory\u2014I know there are tons of resources and templates out there. I\u2019d just need to stitch it all together.\n\nAlso, it's not a like a freelance contract as the liability lies on the University, not on me, the worst case is I fail to deliver and they fire me. \n\nAt my current job, I\u2019m the de facto backend guy anyway. No one else really knows backend, and my senior is a UI/UX dev. I was basically hired to replace the last backend dev. I\u2019d rate myself as an average developer\u2014I can build APIs, do basic backend stuff, and frontend isn\u2019t a problem for me either.\n\nI\u2019m torn because my current job is decent albeit the low pay, and we are very close to deadline,  so if I bail, i will definitely burning bridges here. If possible I would like to get 1 year of experience to make my resume look nice, but if I don't take the university gig, I'll miss out on a huge pay bump. \n\n\nWould love to hear your thoughts\u2014should I take it? What should I consider before saying yes?\n\nWhat would you do? \n\n",
    "created_utc": 1746443556.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kf8zij/need_advice_3x_salary_offer_for_fullstack_role/",
    "score": 50,
    "num_comments": 63
  },
  {
    "subreddit": "webdev",
    "title": "Should I purchase multiple domain TLDs for my brand? What\u2019s your opinion?",
    "text": "Hey everyone  I own the main .com for my brand, but I\u2019m wondering if it\u2019s smart (or necessary) to purchase other TLDs too  like .net, .co, .io, and so on.\n\nSome people say it helps with branding, trust, SEO, and protecting your name from copycats or squatters. Others say it\u2019s a waste of money unless you\u2019re a big company with legal teams and deep pockets.\n\nI\u2019m especially curious if buying multiple TLDs early actually *saves money* in the long run, before someone else grabs them  or if it just ends up being a bunch of unused domains sitting around.\n\nWhat\u2019s your honest opinion? Have you done this for your own brand or project? Did it actually help? Would love to hear how you approached it.\n\nAlso if you *do* buy in bulk, where\u2019s the best place to do that?",
    "created_utc": 1746438807.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kf7pwu/should_i_purchase_multiple_domain_tlds_for_my/",
    "score": 10,
    "num_comments": 12
  },
  {
    "subreddit": "webdev",
    "title": "Just bought 2 websites and want help pulling a (harmless) prank on someone",
    "text": "So I'm familiar with the concept of 400 / 500 pages since I work in Tech.  I have a family member who is studying web development.\n\nIs there a funny prank I can pull on them with by having them go to my website.  I have no coding experience with HTML.  open to all ideas but again has to be harmless but funny\n\n  \nThanks",
    "created_utc": 1746417905.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kf2pxt/just_bought_2_websites_and_want_help_pulling_a/",
    "score": 0,
    "num_comments": 11
  },
  {
    "subreddit": "webdev",
    "title": "Bootstrap Tooltips mess up datatable sorting",
    "text": "Recently ran into this issue. I have a Datatable with links in the form of dates. I tried to add Bootstrap tooltips to the date links to show more info like location of the event. However, when adding the tooltips, the data in these take precedence over the actual cell data.\n\nSo if I have the following example rows:\n\n>Name / First Event  \nName 1 / 2025-05-04 (tooltip: Philadelphia)  \nName 2 / 2024-10-22 (tooltip: Chicago)  \nName 3 / 2023-07-15 (tooltip: New York)\n\nIf I try and sort by the \"first event\" row in decending order (most recent first). Rather than sorting like the above, it would instead sort by the text in the Tooltip (so: Philadelphia > NY > Chicago). Without the tooltips, the sorting works as intended.\n\nHere is the code for both the tooltips and the Datatable JS initialization. I'm doing this in Django so the bracketed text are just replacements for the template variables.\n\n `<td> <a data-bs-toggle=\"tooltip\" data-bs-placement=\"top\" data-bs-html=\"true\" data-bs-custom-class=\"custom-tooltip\" data-bs-title=\"[DATE]<br>[LOCATION]\" href=\"\">[DATE]</a></td>`\n\n    $(document).ready(function () {\n    \u00a0 \u00a0 \u00a0 new DataTable('#table', {\n    \u00a0 \u00a0 \u00a0 \u00a0 layout: layout,\n    \u00a0 \u00a0 \u00a0 \u00a0 order: [[1, 'desc']],\n    \u00a0 \u00a0 \u00a0 });\n    \u00a0 \u00a0 });\n\nHas anyone else been able to use both Bootstrap tooltips and Datatables without them getting messed up like this? I'm sure it's possible, probably something I'm overlooking.\n\nThanks in advance for any help.",
    "created_utc": 1746417500.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kf2lfl/bootstrap_tooltips_mess_up_datatable_sorting/",
    "score": 1,
    "num_comments": 4
  },
  {
    "subreddit": "webdev",
    "title": "HELP? FAVICON",
    "text": "hello, no idea if this is the right sub to ask this and if it isn\u2019t please lead me to it but :\n\nHOW DO I change my website\u2019s (shopify) favicon so it shows on google ?\n\nplease?\n\nIt shows when you click on it but not on google search if that makes sense\u2026 \ud83e\udd72\n\nExplain like I\u2019m 5 please\u2026\ud83e\udee3",
    "created_utc": 1746416092.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kf26w5/help_favicon/",
    "score": 2,
    "num_comments": 13
  },
  {
    "subreddit": "webdev",
    "title": "A P2P multiplayer library (WebRTC-based) that behaves like WebSockets (client / server)",
    "text": "Hey!\n\nI'm developing multiplayer games such as OpenGuessr and AutoGuessr, and worked on something interesting for that: A peer-2-peer library that abstracts away all the annoying stuff and allows for **writing code once, not twice**. It is based on **WebRTC data channels** and works around a ton of WebRTC's shortcomings.\n\nIn a traditional peer-2-peer scenario, you'd need **separate host peer and client peer logic**. For example:\n\n* Host peer runs a chat room\n* Client peer joins and sends a message\n* Host adds the message to the \"chat\" array and sends the updated array to all peers\n\nWhat this means in practice is that you'll have to **write the majority of your code twice** \u2013\u00a0once from the host peer's perspective, and once from the client peer's perspective. This is annoying and makes the code hard to read and maintain.\n\nMy library, [PlayPeerJS](https://github.com/therealPaulPlay/PlayPeerJS), works differently:\n\n\\- It provides an API for **updating storage keys of a synced storage**, for getting the current storage, event hooks and so on\n\n\\-  The **\"host\" is a dynamic concept** \u2013\u00a0under the hood, the host role is assigned at random and \"migrated\" if the current host disconnects. All peers then move on to a new host that they agreed upon prior. The host's task is to actually perform the storage syncing, passing on events and so on.\n\nWhat's more, the library does:\n\n* Heartbeat checks\n* Optimistic updates to work around high TURN latency\n* Ordering of messages\n* Safe array transformations (adding / removing etc. without overwriting changes)\n* Timeouts for all sorts of things to recognize hanging connections or connection attempts\n* Room size limits\n\nI've been using this for a couple of months now and wanted to **share the upsides and downsides** that I noticed:\n\n\\+ Latency, without TURN, is good.\n\n\\+ It's cheap / free (depending on the setup) to host.\n\n\\- Hard to debug as you have no insight into sessions.\n\n\\- Phones like to kill WebRTC connections quickly, most VPNs or Proxies don't support them and certain wlan routers don't either. What's more, TURN adds a ton of latency.\n\n\\- Establishing a connection can take up to \\~5 seconds\n\n\\- No \"source of truth\" > E.g. if you are in a room with another person and they appear to have disconnected, you can't know whether the connection issue is on their side or on your end.\n\nNonetheless, I'll continue to use it for AutoGuessr. But the interesting thing about PlayPeerJS is that you don't have to choose! I recently developed [PlaySocketJS](https://github.com/therealPaulPlay/PlaySocketJS) which **shares the same API** (apart from a few event & the constructor, which needs a WS connection) and allows you to \"just swap out the library\" and move from WebRTC to **WebSockets**.\n\nThis makes trying out WebRTC really painless and low-risk :-) Please let me know what you think of this, and if you'd use it in your own application! I'd also be interested in hearing **your take on WebRTC** data channels.",
    "created_utc": 1746404413.0,
    "url": "https://www.reddit.com/r/webdev/comments/1keykmg/a_p2p_multiplayer_library_webrtcbased_that/",
    "score": 8,
    "num_comments": 0
  },
  {
    "subreddit": "webdev",
    "title": "Need help and guidance on working with a full stack dev for my first e-commerce website.",
    "text": "I am in the very early stages of my startup and about to hire a full stack web dev from Upwork to begin work on our e-commerce website.\n\nI need help with best practice guidelines for all things from working with a remote developer, how to handle code security, handover process, what a workflow profess might look like, how to handle logins or account creations, basically everything.\n\nI would appreciate any help or guidance in this area.\n\nThanks.",
    "created_utc": 1746399731.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kewzae/need_help_and_guidance_on_working_with_a_full/",
    "score": 5,
    "num_comments": 13
  },
  {
    "subreddit": "webdev",
    "title": "Help e get customer feedback",
    "text": "As a startup founder, I struggled to get actionable feedback from early website visitors. So, I built a simple feedback bubble that sits at the bottom of the site and lets users send thoughts directly to the founder. I\u2019d love to hear how others are collecting feedback or if you think this approach could work for small teams. Any suggestions or feedback?",
    "created_utc": 1746398431.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kewinr/help_e_get_customer_feedback/",
    "score": 0,
    "num_comments": 1
  },
  {
    "subreddit": "webdev",
    "title": "Best OS for Laptops and Mobiles",
    "text": "Hello, everybody. I recently discovered a laptop from my own. It's a HP model, 14-bs003la. I'm planning to format my laptop, and install a new OS. I don't programm, I just want to be able to web surface and play Steam, and absolutly keep my privacy. Wich OS do you recommend me?\n\n  \nAlso I have a Redmi 9A, also planning to format and install a new OS. Any ideas of what OS will be good?\n\n  \nThanks for the help.",
    "created_utc": 1746389847.0,
    "url": "https://www.reddit.com/r/webdev/comments/1ketawu/best_os_for_laptops_and_mobiles/",
    "score": 0,
    "num_comments": 10
  },
  {
    "subreddit": "webdev",
    "title": "Migrating/rewrite APIs from flask",
    "text": "So I started building the backend for a basic social media platform with flask since I am highly familiar with python and it was so easy to get started with. But I feel like it's not the most extendable without gluing extensions together and that I might run into issues with it sooner rather than later.\n\nOther than python I'm familiar with java and golang. I have also heard tools like laravel/symfony and rails are pretty feature-rich out of the box. I didnt have a great experience with django, and i would prefer API-first development. I guess something like DRF is an option for that though. Not sure if anything in particular stands out in 2025. Thanks!\n\nJust want to pick the right tool for the job.",
    "created_utc": 1746385610.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kern0s/migratingrewrite_apis_from_flask/",
    "score": 10,
    "num_comments": 5
  },
  {
    "subreddit": "webdev",
    "title": "OAuth and Redirects: Next steps?",
    "text": "Hi Everyone,\n\nI have just made a web app in vanilla JS, which is hosted with Vite. The intent is to host this app locally so that other devices on the network (most likely only one) can access it. I don't intend to make it available to the internet. I am looking to understand how I take my app and make it functional within my home network.\n\nI have containerised it and have the application running and accessible locally. The app itself is also accessible by other devices on the network. However, the app using Spotify API which requires OAuth2 and a redirect URI. I am familar with [127.0.0.1/callback](http://127.0.0.1/callback) being a development callback URI, however I haven't found any advice on how to transition to the 'proper way'.\n\nWhen I accesss my app on other devices, it works until the authentication process where I am redirected to the [127.0.0.1](http://127.0.0.1) callback address and get an error. \n\n  \nCould anyone please explain the process for self hosting a website and managing callback outside of the [127.0.0.1](http://127.0.0.1) method. I believe the issue stems from spotify does not allow the use of a home network IP address (192.168.x.x) as it returns an invalid. Does this mean I must create a domain of sorts and direct traffic that way? What is the general steps for this, is that a reverse proxy?\n\n  \nThanks for all your help\n\n  \n",
    "created_utc": 1746383962.0,
    "url": "https://www.reddit.com/r/webdev/comments/1ker02q/oauth_and_redirects_next_steps/",
    "score": 2,
    "num_comments": 0
  },
  {
    "subreddit": "webdev",
    "title": "AI FastAPI-MCP Monitoring Project - u can now talk with your devices - Alpha Version",
    "text": "# Introduction\n\nThe first alpha version of the MCP Monitoring project has been completed, offering basic monitoring capabilities for various device types.\n\n\n\n\n\nhttps://preview.redd.it/rfdtmoqbrqye1.png?width=2547&format=png&auto=webp&s=5f115cbe59ac8e30ffc52ec5e99baca054b208db\n\n# Supported Device Types\n\n# Standard Devices (Windows, Linux, Mac)\n\n* Requires running Glances (custom agent coming later)\n* All statistics are transferred to the MCP server\n* Any data can be queried with the help of LLM\n\n  \n\n\nhttps://preview.redd.it/q3m2yjqgrqye1.png?width=1305&format=png&auto=webp&s=f0fdfdb8407ce58ddb9fb7b24191edefa0ad595c\n\n# Custom Devices\n\n* Any device with network connectivity can be integrated by writing a custom plugin\n* Successfully tested devices: ESXi, TV, lab machines, Synology NAS, Proxmox, Fritz!Box router\n* Not only querying but also control is possible\n* The LLM is capable of interpreting and using the operations defined in plugins\n\n# Current Features\n\n**Creating Sensors**: RAM and CPU monitoring (currently only on standard devices)\n\n* **LLM Integration**: Currently works only with OpenAI API key, Ollama support is not yet stable\n* **Device Communication**: Chat interface with devices on the Devices page\n* **Dashboard**: Network summaries can be requested by clicking on the moving \"soul\" icon\n* Notifications for sensors\n\n\n\nhttps://preview.redd.it/sezmc3yhrqye1.png?width=2542&format=png&auto=webp&s=54d4254ac41ec39a3c39f3756d89d5633f9a67bf\n\nhttps://preview.redd.it/gtbq32yhrqye1.png?width=1559&format=png&auto=webp&s=2cadd69363753c0594c80eb384613387547e7e55\n\nhttps://preview.redd.it/ieoek2yhrqye1.png?width=1576&format=png&auto=webp&s=8e026b26f0fda1f79b0e922bf6c5a179b3af1565\n\n# Known Issues\n\nAfter adding a new device, 30-50 seconds are needed to check its availability\n\nAuto-refresh doesn't work optimally, manual refresh is often required\n\nPlugins can only be added in JSON format\n\nNo filtering option in the device list\n\n# Planned Developments\n\n* More sensor types (processes, etc.)\n* Sensor support for custom devices\n* Development of a custom agent for standard devices\n* More advanced, dynamic interface for plugin-based devices\n* And much, much, much more.\n\n# Try It Out\n\nThe project is available on GitHub:  [https://github.com/n1kozor/AINFRA](https://github.com/n1kozor/AINFRA)\n\n",
    "created_utc": 1746354171.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kegmep/ai_fastapimcp_monitoring_project_u_can_now_talk/",
    "score": 0,
    "num_comments": 0
  },
  {
    "subreddit": "webdev",
    "title": "Help with my website",
    "text": "Hello friends,\n\nI could really use some help with my website. I provide content localization services, but my website does not rank well. I barely get any impressions, and even less clicks.\n\n[https://www.topblog.agency](https://www.topblog.agency)\n\nPlease check it out and let me know what could be done better.\n\nThank you!",
    "created_utc": 1746348764.0,
    "url": "https://www.reddit.com/r/webdev/comments/1kefc2i/help_with_my_website/",
    "score": 2,
    "num_comments": 3
  },
  {
    "subreddit": "webdev",
    "title": "New Project I am working on - Authentra, Social Media Designed to Remove Fake AI Generated Content",
    "text": "Hey everyone! I have started working on a new side project for fun called\u00a0**Authentra** and I would love to know if you guys like my ideas.\n\nIt's a social media platform similar to Facebook or Instagram, but I'm trying to make it much more positive and authentic than the others:\n\n* **AI Content Filter:**\u00a0Every uploaded image is automatically scanned and blocked if it's AI-generated. I am hoping to restore authenticity and reduce click and rage bate content.\n* **User-Controlled Algorithm:**\u00a0Next, I'm working on an algorithm that gives control over the feed back to users. Instead of pushing divisive or misleading content purely for engagement, it lets you customize your feed preferences with simple sliders:\n   * Want more factual content? Just slide right.\n   * Prefer memes and lighter content? You\u2019ve got control.\n\nMy big picture goal is to reduce the negative impacts of current social media platforms\u2014especially mental health issues, misinformation, and societal division as these are things I have struggled with and dislike from current social media options.\n\n**I'd appreciate your thoughts:**\n\n* Would you use something like this?\n* Any feature suggestions or concerns you can think of?\n* Does the idea of a user-controlled algorithm appeal to you?",
    "created_utc": 1746344509.0,
    "url": "https://www.reddit.com/r/webdev/comments/1keecsf/new_project_i_am_working_on_authentra_social/",
    "score": 3,
    "num_comments": 13
  },
  {
    "subreddit": "webdev",
    "title": "I built a tool to tackle my biggest pain points as a Japanese learner: Japanese numbers and grammar, and now my girlfriend and I use it everyday",
    "text": "Hey everyone! I wanted to share something I\u2019ve been working on that came out of a personal frustration while studying Japanese.\n\nOne of the first pain points I hit was with anything related to **numbers (times, dates, counters, durations...)**. Google Translate often doesn\u2019t give the right pronunciation (or any at all), and the audio can be different from what\u2019s written. Most websites only show **static lists**, which means if you're trying to figure out something like \"9:13 PM\" or \"2 months from now\" or how to say specific numbers like \"183746\", it's either a long scroll or just not there at all.\n\nSo I built a tool to let me **quickly look up number-related stuff** \u2014 time, counters, dates \u2014 and get **instant readings in kana, romaji, kanji**, with context and notes, and example sentences. I wanted it to be smooth, fast, and something I could use either for a quick lookup or to test my knowledge.\n\nAnother big pain point is Japanese and what sounds natural and what doesn't. I\u2019d often see sentences that made sense to native speakers, but I couldn\u2019t understand why. I added a **grammar analyzer** that breaks sentences down into parts, color-codes them, and explains how they work and connect with each other. Now when I see a sentence I don\u2019t understand (which happens often), I drop it in it's been a big help for both my girlfriend and I to understand some more complicated sentences. We were reading a Japanese children's book the other day and were stuck on a page because we didn't understand the way two verbs connected to each other and what they mean when used together so we used it and cleared it up perfectly.\n\nIt's called **Kazu Navi \u304b\u305a\u30ca\u30d3** (number navigator) and I'm honestly just really proud that I built something that's been very useful to me.\n\nLink: [kazunavi.com](https://kazunavi.com/)\n\nThe **number converters are all free** to use without an account. You can use the **grammar analyzer** 6 times with an account and there's also a **natural translation** module that you can use unlimited times with an account.\n\n\ud83d\udcbb Built with Next.js, PostgreSQL, Tailwind, and a lot of time in the Japanese Stack Exchange\n\nWould love any feedback \u2014 especially if you\u2019ve studied Japanese or have ideas to improve the UI/UX since I'm taking a big mobile-first approach so it even emulates mobile UI which I'm not sure if it comes across as \"lazy\" or if it's good practice, let me know what you think!",
    "created_utc": 1746336242.0,
    "url": "https://www.reddit.com/gallery/1keccqb",
    "score": 32,
    "num_comments": 13
  },
  {
    "subreddit": "webdev",
    "title": "Page Speed Insights says INVALID URL after updating name servers",
    "text": "Hello developers, I deleted [Quic.cloud](http://Quic.cloud) CDN and updated name servers. After that, Google Page Speed Insights returns this error: \"Unable to resolve https://counselit.com/. Try checking the URL for validity\".\n\nI purged all the LiteSpeed cache and deleted the server-side cache. Also cleared browser cache. Even edited the ./public\\_html/wp-content/litespeed/robots.txt to \"User-agent: \\*\n\nDisallow: Allow:/wp-admin/\n\n/wp-admin/admin-ajax.php\n\nSitemap: https://counselit.com/sitemap\\_index.xml\"\n\nNothing helped though.\n\nHow do you think I could fix this?\n\nI really appreciate any help you can provide.",
    "created_utc": 1746324430.0,
    "url": "https://www.reddit.com/r/webdev/comments/1ke92we/page_speed_insights_says_invalid_url_after/",
    "score": 2,
    "num_comments": 1
  },
  {
    "subreddit": "webdev",
    "title": "BookMatchup > GoodReads? Looking for honest feedback on design and UX.",
    "text": "BookMatchup is a MERN stack project to help readers connect through shared books. I've heard a lot of frustration with Goodreads, clunky UI, limited social features. So, this is my take on something better.\n\n**Core features:**\n\n* Add books to your wishlist or completed list\n* Get matched with other users based on shared titles\n* Leave ratings, reviews, and reactions\n* Customize your profile with avatars, color themes, and a short bio\n* Community feedback forum (link in the footer)\n\n**Login options:**\n\n* Sign up with Google or email\n* Or try the test account:\u00a0**Username:**\u00a0`test`\u00a0**Password:**\u00a0`test`\n\n**Tech stack:**\n\n* Frontend: React (deployed on Netlify)\n* Backend: Node/Express (deployed on Render)\n* Auth: Firebase\n* Book data: Open Library API\n* Database: MongoDB\n\nCheck it out here:\u00a0[https://bookmatchup.com](https://bookmatchup.com/)\n\nI'm an English teacher with some coding skills, building out my portfolio \u2014 but this feels like it could grow into something more than just a resume piece. Would really appreciate your feedback on design, layout, UX flow, or features you'd want as a reader.  \n  \nThanks for reading.",
    "created_utc": 1746323688.0,
    "url": "https://i.redd.it/5m1u7ntt8oye1.png",
    "score": 3,
    "num_comments": 2
  },
  {
    "subreddit": "webdev",
    "title": "Best practices for enriching DTOs with bucket files (S3, GCS, etc.) across backends?",
    "text": "Hey everyone \ud83d\udc4b\n\nI'm currently working with Spring Boot, and I have DTOs that need to include images or files stored in a bucket (S3, GCS, MinIO, etc.).\n\nRight now, I generate file URLs (signed or public) before returning the DTOs to the frontend. But I\u2019m wondering if there\u2019s a common pattern or architectural concept \u2014 not just in Java \u2014 that developers use to cleanly handle this kind of DTO enrichment.\n\nHere are some things I\u2019m trying to figure out:\n\nWhere should the logic to generate file URLs live? In the mapper, a DTO enricher class, or a service layer?\n\nWhat\u2019s the cleanest way to ensure this logic stays reusable across multiple models (not just one specific DTO)?\n\nWhat do you usually do when the frontend gets a pre-signed upload URL but never completes the upload?\n\nHow do you keep your database and bucket in sync?\n\nIs there a naming convention or common interface-based approach that helps keep things clean?\n\nWould love to hear your thoughts or see examples of how you structured this!\n\nThanks in advance \ud83d\ude4f",
    "created_utc": 1746323276.0,
    "url": "https://www.reddit.com/r/webdev/comments/1ke8qhj/best_practices_for_enriching_dtos_with_bucket/",
    "score": 5,
    "num_comments": 2
  },
  {
    "subreddit": "webdev",
    "title": "Resume Review - 6 Years as \"Do it All\" guy at a startup, 6mo unemployed, only 1 technical interview",
    "text": "Hi all,\n\nAny recommendations for improvements to the resume, or better places to look for jobs would be massively appreciated. I unfortunately live in a pretty rural area, so local options are basically non-existent. I've been applying for in-person & remote jobs basically anywhere in the US, and I've had 6 or 7 \"interviews\" with recruiters, but only 1 technical interview which didn't proceed after that.\n\nI've certainly got more frontend experience than backend, but with the work on the startup's web app & AWS and other DevOps responsibilities I've been considering myself \"full-stack\" enough to learn anything I don't know as needed. I've been applying to anything relevant I can find on LinkedIn, Indeed, Dice, and a few other job boards, from entry-level to senior.\n\n**Details about my experience:**\n\nMy only tech job was after college at a startup for the last 6 years before being laid off when the startup was bought out. I learned the vast majority of my programming/web dev knowledge on the job as needed, with a few C/C++/Java/SQL classes at the end of college that made me realize I preferred programming to the criminal justice major.\n\nI went from basic HTML/CSS work on Wordpress sites to learning vanilla JS & many JS frameworks whenever we had work on client sites using those tech stacks, eventually becoming responsible for fixing any high-priority issues on client sites, with lower-priority fixes eventually being left for our 3rd-party (over-sea) dev team. Additionally, I was responsible for all work on the startup's own websites as well as being the PM/QA for most of the 3rd-party dev team's work, acting as a middleman between them & our clients to make sure everything met quality standards. I eventually gained ownership of our in-house React/Node.js/MongoDB web-crawler app when the original dev (smartly) left for a higher-paying position elsewhere with better growth.\n\nI was the only person at the startup who knew more than very basic HTML/CSS (after the CTO retired after about 2 years), and I was much more technical than anyone else remaining, so I was also the in-house & client-facing tech support, as well as providing tech expertise on sales calls, being responsible for Hosting/DNS/Email/etc with AWS, Cloudflare, Godaddy/Kinsta, etc. I learned WCAG 2.1/2.2 accessibility pretty quickly & became the in-house subject matter expert, eventually training clients (& my co-workers when 2.1 updated to 2.2). No certifications since the startup wouldn't pay for those, but planning on getting IAAP's \"Web Accessibility Specialist\" cert when exams open in a couple weeks.\n\nIf I can answer any questions or provide any more info just let me know. Thanks",
    "created_utc": 1746322349.0,
    "url": "https://i.redd.it/2962vvda4oye1.png",
    "score": 82,
    "num_comments": 35
  },
  {
    "subreddit": "webdev",
    "title": "divs are not buttons and they certainly aren't links",
    "text": "I'm going to go on a bit of a rant, because this is something I've been encountering more and more lately: I go to browse a website. The sort of website that has index/list pages that are meant to link to a bunch of other pages, like an online store's product page or a site that hosts videos/images/games/etc. I see something I'm interested in on the index page so I go to middle-click and open it in a new tab so I can continue browsing the index before checking it out in detail... but instead of a new tab, the autoscroll activates. I try right-clicking, but there's no \"Open in new tab/window\" option. I left-click, and it takes me to a new url. I go back, I inspect the source: What I'm clicking on is not a link. It's not even a button. It is a div, with a button attribute, being used in place of a link. \n\nWhy. Why does anyone program a website this way?? *Especially* a website whose whole purpose is for people to browse lots of products/content. It is absolutely infuriating in this day and age to have to navigate a website entirely in a single tab, going forward and back between the index page and \"linked\" pages.\n\nAnd that's just me finding it *annoying*. The most recent example I encountered was this [tea store](https://www.adagio.com/list/best_sellers.html), where the divs aren't even *fully implemented as the buttons they say they are* (that are being used as links). The div-buttons are only coded to respond to a mouse-click, which means their website *legitimately cannot be navigated* by someone using a keyboard as an input device, like, oh, y'know blind people??\n\nRant aside... legitimately, why do people build websites this way? I only know HTML/CSS on a hobbyist level, so I can't tell if poorly implementing a less-accessible knock-off button instead of a link is easier to code and a form of laziness/negligence, or if this is actively taking an unnecessarily complicated route to come up with a worse solution than what's natively available and a form of straight-up incompetence.",
    "created_utc": 1746314069.0,
    "url": "https://www.reddit.com/r/webdev/comments/1ke5uta/divs_are_not_buttons_and_they_certainly_arent/",
    "score": 668,
    "num_comments": 175
  },
  {
    "subreddit": "webdev",
    "title": "Automated Client Onboarding System Using Free Tools & No-Code \u2013 A Step-by-Step Guide",
    "text": "Built a fully automated client onboarding system \u2014 using only free tools + no-code \u2014 and I'm open to helping others do the same\n\nAs someone who loves building smart systems, I recently designed an end-to-end client onboarding automation that now runs on autopilot.\n\nHere\u2019s the flow I built:\n\nGoogle Forms to capture client details\n\nNotion as the backend CRM/database\n\nGmail sends a personalized welcome email instantly\n\nTelegram notifies me in real-time with the lead details\n\nAll tied together using Zapier (free plan)\n\n\nThis setup:\n\nRemoves manual effort\n\nSpeeds up response time\n\nKeeps everything organized in one place\n\nImpresses clients with instant communication\n\n\nI\u2019m sharing this not just as a win, but because I genuinely enjoy building automations like this \u2014 whether it's for onboarding, internal workflows, or marketing funnels.\n\nIf you're trying to automate a part of your business and don\u2019t know where to start, feel free to drop a comment or DM me. Would love to help or collaborate!",
    "created_utc": 1746307197.0,
    "url": "https://www.reddit.com/gallery/1ke3h6s",
    "score": 0,
    "num_comments": 5
  },
  {
    "subreddit": "webdev",
    "title": "I built an app that analyzes food items and scores them based on how processed they are.",
    "text": "There have been many scientific studies suggesting a strong link between high consumption of ultra-processed foods (UPFs) and a range of negative health outcomes, including increased risk of heart disease, type 2 diabetes, and cancer.\n\nMany people like myself are trying to eat healthier by cutting back on their consumption of ultra-processed foods.\n\nBut it turns out to be pretty difficult to know exactly what foods are ultra-processed, and it ends up taking a lot of time and effort trying to figure that out for each food item.\n\nMy app (NovaScanner: Detect UPF Foods) solves this issue by allowing you to snap a pic of any food item and instantly receive a 0-100 score and NOVA classification for that food item based on its level of processing.\n\nIt saves people like myself (who are trying to cut back on UPFs) a ton of time and mental energy, as well as reduces decision fatigue.\n\nWhat makes NovaScanner better than the existing UPF scanner apps on the App Store? NovaScanner is the only app able to scan ANY food item directly, whereas all the other apps only work for food items that have a label or barcode. The vast majority of food items don't have a label or barcode.\n\nUnlike all the other scanner apps, NovaScanner is able to scan prepared food, restaurant meals, and home-cooked dishes, in addition to packaged food items.\n\nIf you'd like to check or try it out, it's available for free on the[ App Store](https://apps.apple.com/us/app/novascanner-detect-upf-foods/id6742974239).",
    "created_utc": 1746305111.0,
    "url": "https://www.reddit.com/gallery/1ke2pz8",
    "score": 0,
    "num_comments": 5
  },
  {
    "subreddit": "webdev",
    "title": "Which looks better?",
    "text": "This is the dashboard to a customer management system I am working one, I can't decide which one looks better\nI am using tailwind css and chart js\nThis is made in laravel using alpine js\n\n(ps : sorry for the empty/missing graphs on the first one) ",
    "created_utc": 1746304564.0,
    "url": "https://www.reddit.com/gallery/1ke2isu",
    "score": 13,
    "num_comments": 26
  },
  {
    "subreddit": "webdev",
    "title": "How to convert Replit WebApp to True TWA (To upload on play store)",
    "text": "I have created this web application (Link in my Profile) named Public Speaking Gym. \n\nNow I want to convert this into Standalone TWA and then upload on Play Store.\n\nKey Features of TWA:-\n\u2022 Uses Browser under the hood, but hides all browser UI\n\u2022 Fully Full-Screen, launch from Play Store like any other Android App\n\u2022 It feels and looks 100% like a native Android app, but content is still served from web server.\n\nAnyone who have solved this issue, Please guide how to do this and what applications are best for this thing. A quick guide is enough, I would use chatgpt for detailed things.\n\nThanks.",
    "created_utc": 1746304539.0,
    "url": "https://www.reddit.com/r/webdev/comments/1ke2ihy/how_to_convert_replit_webapp_to_true_twa_to/",
    "score": 0,
    "num_comments": 6
  },
  {
    "subreddit": "webdev",
    "title": "I built a web app that turns images, 3D models, and even real-world locations into Minecraft builds",
    "text": "This is a hobby project I\u2019ve been working on for a little while now. It's a web-based tool that helps you bring your ideas to life in Minecraft. You can:\n\n* Import images, 3D models, .mcstructure, .schem, or .litematic files and transform them to voxels\n* Enter real-world coordinates to voxelize cities and landmarks using OpenStreetMap data\n* Export your builds in Minecraft-compatible formats\n* View layer-by-layer instructions for large, complex creations\n* Use AI to generate images or 3D models from text prompts\n* (Pro users can even upload entire Minecraft worlds to get a build from their world and transform it to a bloxelizer creation or upload a bloxelizer creation to their world)\n\nCheck it out:\n\n\ud83d\udd17 Live:[ https://bloxelizer.com](https://bloxelizer.com)\n\nIf you find any bugs or have any feature suggestions, feel free to open up an issue / discussion here[ https://github.com/bloxelizer/app](https://github.com/bloxelizer/app)\n\nWould love your feedback or ideas. hope you find it fun to explore!",
    "created_utc": 1746302461.0,
    "url": "https://www.reddit.com/gallery/1ke1reu",
    "score": 9,
    "num_comments": 7
  },
  {
    "subreddit": "reactjs",
    "title": "React + Redux Toolkit + React Refresh - RSPack setup issue",
    "text": "Not sure if this subreddit is the best place to ask this question, but I am pretty hopeless at this moment.\n\nI am using RSPack bundler in my React application, the setup is pretty basic and straightforward - I use React, Redux Toolkit, TypeScript and CSS Modules. When running a dev server I want to have a fast refresh so I use `@rspack/plugin-react-refresh`.\n\nThe problem is that when I make changes to my component files (`.tsx` extension) everything works fine, but if I make any changes to my redux files, then redux state gets lost and page is stuck on initial request load. I understand that React Refresh was meant to persist components local state, not global state, and I am okay with that. What I want to achieve is when I make changes to `.ts` files, I want my app to fully reload and when I make changes to `.tsx` files, I want React Refresh do its thing. Is that possible?\n\nBy the way, if I make changes to `.ts` file which contain non-redux code, then React Refresh works just fine.\n\nHere is my config:\n\n```ts\nimport \"dotenv/config\";\n\nimport { defineConfig } from \"@rspack/cli\";\nimport { rspack } from \"@rspack/core\";\nimport ReactRefreshPlugin from \"@rspack/plugin-react-refresh\";\nimport path from \"node:path\";\nimport { TsCheckerRspackPlugin } from \"ts-checker-rspack-plugin\";\nimport { z } from \"zod\";\n\nconst {\n  CircularDependencyRspackPlugin,\n  CopyRspackPlugin,\n  DefinePlugin,\n  HtmlRspackPlugin,\n  LightningCssMinimizerRspackPlugin,\n} = rspack;\n\nconst mode = z.enum([\"development\", \"production\"]).parse(process.env.NODE_ENV);\n\nexport default defineConfig({\n  devServer: {\n    hot: mode === \"development\",\n    port: 3000,\n  },\n  devtool: mode === \"production\" ? false : \"source-map\",\n  entry: {\n    main: \"./src/index.tsx\",\n  },\n  experiments: {\n    css: true,\n  },\n  mode,\n  module: {\n    parser: {\n      \"css/auto\": {\n        namedExports: false,\n      },\n    },\n    rules: [\n      {\n        test: /\\.(ts|tsx)$/,\n        use: {\n          loader: \"builtin:swc-loader\",\n          options: {\n            jsc: {\n              parser: { syntax: \"typescript\", tsx: true },\n              transform: {\n                react: { development: mode === \"development\", refresh: mode === \"development\", runtime: \"automatic\" },\n              },\n            },\n          },\n        },\n      },\n    ],\n  },\n  optimization: {\n    minimizer: [\"...\", new LightningCssMinimizerRspackPlugin()],\n    runtimeChunk: {\n      name: \"runtime\",\n    },\n  },\n  output: {\n    path: path.resolve(process.cwd(), \"build\"),\n  },\n  performance: {\n    maxAssetSize: 512000,\n    maxEntrypointSize: 512000,\n  },\n  plugins: [\n    new CircularDependencyRspackPlugin({ failOnError: true }),\n    new CopyRspackPlugin({ patterns: [{ from: \"./public\" }] }),\n    new DefinePlugin({\n      \"process.env.API_URL\": z\n        .string()\n        .url()\n        .transform((apiUrl) => JSON.stringify(apiUrl))\n        .parse(process.env.API_URL),\n    }),\n    new HtmlRspackPlugin({ template: \"./src/index.html\" }),\n    new TsCheckerRspackPlugin({\n      typescript: { configOverwrite: { compilerOptions: { types: [\"./src/types.d.ts\"] } } },\n    }),\n    mode === \"development\" ? new ReactRefreshPlugin() : null,\n  ].filter(Boolean),\n  resolve: {\n    alias: {\n      \"~\": path.resolve(process.cwd(), \"src\"),\n    },\n    extensions: [\"...\", \".ts\", \".tsx\"],\n  },\n  watchOptions: {\n    ignored: /node_modules/,\n  },\n});\n```",
    "created_utc": 1746524516.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kg0f62/react_redux_toolkit_react_refresh_rspack_setup/",
    "score": 1,
    "num_comments": 0
  },
  {
    "subreddit": "reactjs",
    "title": "Help me understand why my page won't rank",
    "text": "I have recently bought a domain previously used by others, and I'm remaking it.\n\nI'm using React with Mantine, but the page won't show up on search results.\n\nI suspect it's because it's a SPA and it can't be crawled properly? Any help would be appreciated!",
    "created_utc": 1746522835.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kg00uq/help_me_understand_why_my_page_wont_rank/",
    "score": 0,
    "num_comments": 1
  },
  {
    "subreddit": "reactjs",
    "title": "TMiR 2025-04: React 19.1 helps debug owner stacks",
    "text": "",
    "created_utc": 1746488302.0,
    "url": "https://www.reactiflux.com/transcripts/tmir-2025-04",
    "score": 4,
    "num_comments": 1
  },
  {
    "subreddit": "reactjs",
    "title": "ReactFlow Nodes Not Rendering",
    "text": "Has anyone else had this issue when using ReactFlow? \n\nAbout 75% of the time my nodes render just fine but the other 25% the ReactFlow diagram is blank. No errors in console, no warnings either and a simple refresh ( or 2 ??? ) will have the nodes rendered.  \n\n\nThis almost never happens on local and only ever happens on prod \n\n  \nI'm kind of at my wits end with this. I have the node types defined outside the component, the nodes and edges are defined like this \n\n    const [selectedWorkflow, setSelectedWorkflow] = useState('earnings-call');\n\n    const nodes = [selectorNode, ...getWorkflowNodes()];\n\n    const nodes = [selectorNode, ...getWorkflowNodes()];\n        const edges = getWorkflowEdges().map(edge => ({\n            ...edge,\n            style: edgeStyle,\n        }));\n\n\n\ngetWorkflowNodes/Edges is just a switch statement returning different static lists of nodes.\n\nVideo Example: [https://youtu.be/FfxWF1vFrYQ](https://youtu.be/FfxWF1vFrYQ)\n\n  \nMuch appreciation to any help given",
    "created_utc": 1746483712.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kfortt/reactflow_nodes_not_rendering/",
    "score": 3,
    "num_comments": 2
  },
  {
    "subreddit": "reactjs",
    "title": "I don't get the point of shadcn resisting against the idea of component library",
    "text": "the source code of the component is visible and editable in your src. Yes. It does allow you to be more flexible, expandable with a readable format.\n\nHow is this different than a component library with good styling/editing support?\n\nYou are still using pre defined <CoolBlock.Code/>.\n\nIn my eyes shadcn is just a normal component library that focuses on modularity.\n\nI don't get the constant rejection of \"well actually this is not a component library so no you can't access cool looking base components with a simple `import Button from \"shadcn\"`. You have to install them individually and they need to take up space in your src and you also need to do more job even if your goal styling is not far from the default simple version of the components\".\n\nIt could just be shipped like a component library. \n\nWhere am I wrong? I accept I'm not the wisest here.\n\nEdit: fix autocomplete mistakes",
    "created_utc": 1746481661.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kfnz9x/i_dont_get_the_point_of_shadcn_resisting_against/",
    "score": 34,
    "num_comments": 37
  },
  {
    "subreddit": "reactjs",
    "title": "Next.js App Router: Auth state in MainNav (Context) doesn't update after login/logout without refresh",
    "text": "I'm working on a Next.js 14 project using the App Router and running into a state update issue with authentication.\n\n**Tech Stack:**\n\n* Next.js 14 (App Router)\n* React Context API for global auth state\n* Supabase for Authentication (using `onAuthStateChange` listener)\n* TypeScript\n\nI have a `MainNav` component in my header that should display the user's email and a logout button when logged in, or login/signup buttons when logged out. It gets the user state via `useUser()` from my `UserContext`.\n\nHowever, the `MainNav` component doesn't visually update immediately after a successful login or logout action. The user info/buttons only change to the correct state after I manually refresh the page.\n\nThis is the MaiNav component:\n\n    // components/main-nav.tsx\n    \"use client\";\n    \n    import Logout from \"@/components/logout\"; // Assumes this handles the Supabase signout action\n    import { Button } from \"@/components/ui/button\";\n    import { cn } from \"@/lib/utils\";\n    import { useUser } from \"@/state/user-context\"; // Consumes context\n    import { Moon, Sun } from \"lucide-react\";\n    import { useTheme } from \"next-themes\";\n    import Link from \"next/link\";\n    import { usePathname } from \"next/navigation\";\n    import React from \"react\";\n    \n    const MainNav = () => {\n      const pathname = usePathname();\n      const { theme, setTheme } = useTheme();\n      const { user, loading } = useUser();\n    \n      // Simplified routes array...\n      const routes = [{ label: \"Home\", href: \"/\", active: pathname === \"/\" }];\n    \n      // The part that doesn't update immediately:\n      return (\n        <div className=\"flex items-center justify-between w-full\">\n          <nav>{/* Nav Links */}</nav>\n          <div className=\"flex items-center space-x-4\">\n            {loading ? (\n              <span>Loading...</span>\n            ) : user ? (\n              <>\n                <p className=\"text-sm text-muted-foreground\">{user.email}</p>\n                <Logout />\n              </>\n            ) : (\n              <Button asChild>\n                <Link href=\"/signup\">Register</Link>\n              </Button>\n            )}\n          </div>\n        </div>\n      );\n    };\n    \n    export default MainNav;\n\nAnd this is the ContextProvider that is used for the state:\n\n    // state/user-context.tsx\n    \"use client\";\n    \n    import React, { createContext, ReactNode, useContext, useEffect, useState } from \"react\";\n    import { Session, User } from \"@supabase/supabase-js\";\n    import { createClient } from \"@/utils/supabase/client\";\n    \n    interface UserProviderProps { children: ReactNode; }\n    interface UserContextType { user: User | null; loading: boolean; }\n    \n    const UserContext = createContext<UserContextType>({ user: null, loading: true });\n    const supabase = createClient();\n    \n    export const UserProvider = ({ children }: UserProviderProps) => {\n      const [user, setUser] = useState<User | null>(null);\n      const [loading, setLoading] = useState<boolean>(true);\n    \n      useEffect(() => {\n        let initialCheckCompleted = false;\n        const { data: { subscription } } = supabase.auth.onAuthStateChange((event, session) => {\n          console.log(`Supabase auth event: ${event}`, session); // DEBUG\n          setUser(session?.user ?? null);\n    \n          if (!initialCheckCompleted) {\n            setLoading(false);\n            initialCheckCompleted = true;\n          }\n        });\n    \n        const getInitialSession = async () => {\n          const { data: { session } } = await supabase.auth.getSession();\n          if (!initialCheckCompleted) {\n             setUser(session?.user ?? null);\n             setLoading(false);\n             initialCheckCompleted = true;\n          }\n        }\n        getInitialSession();\n    \n    \n        return () => { subscription?.unsubscribe(); };\n      }, []);\n    \n      return (\n        <UserContext.Provider value={{ user, loading }}>\n          {children}\n        </UserContext.Provider>\n      );\n    };\n    \n    export const useUser = () => useContext(UserContext);\n\nIn the main layout I am wrapping the children, MainNav included, with UserProvider.\n\nThe \\`onAuthStateChange\\` function fires correctly on refresh, but does not fire on logout/login. \n\nI am pretty sure this is something simple that I am just not seeing. ",
    "created_utc": 1746473643.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kfko40/nextjs_app_router_auth_state_in_mainnav_context/",
    "score": 1,
    "num_comments": 1
  },
  {
    "subreddit": "reactjs",
    "title": "Mantine 8.0 is out \u2013 170+ hooks and components",
    "text": "Hi everyone! I\u2019m very excited to share the latest major 8.0 release of Mantine with you.\n\n[https://mantine.dev/](https://mantine.dev/)\n\nHere are the most important changes (compared to 7.0 release):\n\n* Fully featured charts library (based on recharts). It includes 12 components: [AreaChart](https://mantine.dev/charts/area-chart/), [BarChart](https://mantine.dev/charts/bar-chart/), [Sparkline](https://mantine.dev/charts/sparkline/), [Heatmap](https://mantine.dev/charts/heatmap/) and more.\n* 20+ new components and hooks in the core library: [Tree](https://mantine.dev/core/tree/), [FloatingIndicator](https://mantine.dev/core/floating-indicator/), [CheckboxCard](https://mantine.dev/core/checkbox/#checkboxcard-component), [SemicircleProgress](https://mantine.dev/core/semi-circle-progress/), [TableOfContents](https://mantine.dev/core/table-of-contents/), and more.\n* Improved dates handling and new components for time picking (new [TimePicker](https://mantine.dev/dates/time-picker/) and [TimeGrid](https://mantine.dev/dates/time-grid/) components)\n* [Community extensions](https://mantine.dev/x/extensions/) allow other developers to share their libraries. There are already 8 extensions available that implement various features: context menu, data table, onboarding / tour, block-based rich text editor, etc.\n* Improved [code highlight package](https://mantine.dev/x/code-highlight/), which now supports syntax highlighting with shiki.\n\nThanks for stopping by! Please let us know what you think. We appreciate all feedback and critique, as it helps us move forward.",
    "created_utc": 1746443208.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kf8vwj/mantine_80_is_out_170_hooks_and_components/",
    "score": 323,
    "num_comments": 38
  },
  {
    "subreddit": "reactjs",
    "title": "Reactylon: An open-source framework for building cross-platform WebXR apps with React + Babylon.js",
    "text": "I\u2019ve been diving deep into XR (VR/AR/MR) development lately and wanted to share something I'm working on:\u00a0[Reactylon](https://www.reactylon.com/docs)\u00a0\\- a new open-source framework that lets you build immersive WebXR experiences using React and Babylon.js.\n\n\ud83d\udee0 What is Reactylon?\n\n* A React-based abstraction layer over Babylon.js for building 3D/XR apps.\n* Write JSX to create your scene.\n* It automatically handles Babylon object creation, parenting, disposal, scene management, etc.\n* Works on\u00a0web, mobile, VR/AR/MR\u00a0-\u00a0write once, run anywhere.\n\n\ud83d\ude80 Why use it?\n\n* Familiar React syntax for managing 3D scenes.\n* Built-in WebXR support for VR/AR headsets.\n* Progressive Web App (PWA) and native device support (via Babylon Native + React Native).\n* Simple model loading, physics integration (Havok), 2D/3D audio, animations and GUI overlays - all declarative.\n* 100+ interactive code examples to try in-browser.\n\n\ud83d\udd17 If you want to check it out:\n\nGitHub repo:\u00a0[https://github.com/simonedevit/reactylon](https://github.com/simonedevit/reactylon)\n\nDocumentation:\u00a0[https://www.reactylon.com/docs](https://www.reactylon.com/docs)\n\nWould love to hear your thoughts on the code, the docs and the overall idea... anything you think could help make it even better. Cheers and thanks for reading!",
    "created_utc": 1746441263.0,
    "url": "https://www.reactylon.com/docs",
    "score": 4,
    "num_comments": 0
  },
  {
    "subreddit": "reactjs",
    "title": "Need opinions from a file based routing I created using vite/reactjs/react-router-dom",
    "text": "I've created a `react-router-dom` wrapper to create full file-based-routing for SPA apps, its inspired from nextjs app-router.\n\nWhy? I love NextJS, but creating full SPA with it needs a lot of workarounds, even tho you use `\"use client\"` and dynamically import components, there still not full SPA, components get rendered on build time.\n\nSo, for SPA I decided to explore Vite + reactjs + react-router but I missed the file based routing from nextjs. I took a look at the file based routing from remix/react-router but I personally didn't liked it, I want something that doesn't have too much rules on naming conventions or having to create the routing obj manually, that's why I created this PoC, basically it reads all your files inside the `src/pages` folder, create the routing objects and pass them to `createBrowserRouter` fn\n\nAt this moment this PoC only supports index.tsx, layout.tsx, loading.tsx, error.tsx and data.ts\n\nFor pages we can use `index.tsx` or any other page name we want, example: `about.tsx`, `contact.tsx`, etc. This is just a simple react component without any special rules.\n\nFor loading states we use `loading.tsx`, this react component shows up when the page chunk is loading or `data.ts` is loading.\n\nFor error boundaries we use `error.tsx` which is another regular react component we display when there is an error in the react dom.\n\nTo load data before the page renders we can use `data.ts`. this is a simple ts file that should return an async fn as default and injects the data to our view  via `initialData` prop. while its loading it displays `loading.tsx` and if it catches an error it displays `error.tsx`.\n\nFor layouts we use `layout.tsx`, its a simple react component that renders a children\n\nI know that for layouts we use Outlet in react-router but this layout we use children, I did it this way so it feels more \"natural\" instead of remembering which component we should use/return.\n\nAnyways, feel free to explore the github PoC and let me know your thoughts.\n\nShould I continue its development? Which other features it would be nice to implement? Should I create a npm package for it?\n\ngithub repo: https://github.com/eralvarez/react-file-based-routing\n\n",
    "created_utc": 1746408951.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kf00xg/need_opinions_from_a_file_based_routing_i_created/",
    "score": 4,
    "num_comments": 8
  },
  {
    "subreddit": "reactjs",
    "title": "General state mgmt question (simple beginner app)",
    "text": "I am building a simple app that simply uses useEffect to call json data from a REST endpoint. Simple enough, you've all done this a million times. From there the json data is used to render sets of cards (basically a online store showing products, but this is not for ecommerce, its for showing a catalog of open data sets where each card represents one dataset, like Census population estimates or something). We have probably about 100 cards max, so not a heavy load really, and for the time being the cards and json data are read only, but editing may be introduced in the future. \n\nIf I have a ui element, like a panel with filtering options, what is the best way to manage filter state? There might be 5 or 6 different filters (e.g. filter by source agency, or data type, or year published). Basically we need to share state between probably 3 to 4 components, with maybe 2 layers of nesting max. In the past I have just used prop drilling and useState, and that could probably work here, but in this case, what would you say is the next logical step up? Do i need something like Zustand? would Context be more logical? Should I just stick with useState? \n\nSoooo many options in the React ecosystem... it gets overwhelming fast, thanks for your help! ",
    "created_utc": 1746377927.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1keoln0/general_state_mgmt_question_simple_beginner_app/",
    "score": 2,
    "num_comments": 10
  },
  {
    "subreddit": "reactjs",
    "title": "Tanstack Form (Form.Subscibe) not working as expected on react native",
    "text": "  \nI am currently using Tanstack From for testing on my react-native project  , but I am having trouble on Reactivity , My form.Subscibe method is not working as expected , I have read the documentation on reactivity but was not able to find any good working solution on it, can anyone assist me ?\n\n\\`\\`\\`tsx  \nimport { Button, ButtonText } from \"@/components/ui/button\";\n\nimport { FormControl, FormControlError, FormControlErrorText, FormControlErrorIcon, FormControlLabel, FormControlLabelText, FormControlHelper, FormControlHelperText } from \"@/components/ui/form-control\";\n\nimport { Input, InputField } from \"@/components/ui/input\";\n\nimport { VStack } from \"@/components/ui/vstack\";\n\nimport { AlertCircleIcon } from \"@/components/ui/icon\";\n\nimport {useForm} from '@tanstack/react-form'\n\nimport {View,Text, ActivityIndicator} from 'react-native'\n\nimport { validateUsername } from \"@/api/user\";\n\nimport { z } from 'zod'\n\n\n\nconst userSchema = z.object({\n\n  username: z.string().min(3, 'Username must be at least 3 characters please'),\n\n  password: z.string().min(6, 'Password must be at least 6 characters'),\n\n})\n\n\t\n\nexport default function App () {\n\nconst form=useForm({\n\ndefaultValues:{\n\nusername:\"\",\n\npassword:\"\",\n\nconfirmPassword:\"\"\n\n},\n\nvalidators:{\n\nonSubmit:({value})=>{\n\nif(!value.username || !value.password){\n\nreturn \"All fields are mandotry and required here\"\n\n}\n\n}\n\n},\n\nonSubmit:({value})=>{\n\nconsole.log(value)\n\n}\n\n})\n\n\n\nreturn (\n\n<View className=\"flex-1 justify-center items-center\">\n\n<VStack className=\"w-full max-w-\\[300px\\] rounded-md border border-background-200 p-4\">\n\n<FormControl \n\nsize=\"md\" \n\nisDisabled={false} \n\nisReadOnly={false} \n\nisRequired={false} >\n\n<form.Field\n\nname=\"username\"\n\nvalidators={{\n\nonChangeAsyncDebounceMs:50, //Here use concept of debounce since this is heavy operation\n\nonChangeAsync: ({ value }) => validateUsername(value),\n\nonChange: ({ value }) => {\n\nconst result = userSchema.shape.username.safeParse(value)\n\nreturn result.success ? undefined : result.error.errors\\[0\\].message\n\n},\n\n}}\n\nchildren={(field) => (\n\n<>\n\n<FormControlLabel>\n\n<FormControlLabelText>Username</FormControlLabelText>\n\n</FormControlLabel>\n\n<View className=\"relative\">\n\n<Input className=\"my-1\" size=\"md\">\n\n<InputField\n\ntype=\"text\"\n\nplaceholder=\"Username\"\n\nvalue={field.state.value}\n\nonChangeText={(text) => field.handleChange(text)}\n\n/>\n\n{field.getMeta().isValidating &&\n\n<View className=\"absolute right-2 top-1/2 transform -translate-y-1/2\">\n\n<ActivityIndicator/>\n\n</View>\n\n}\n\n</Input>\n\n</View>\n\n{field.state.meta.errors &&\n\n<FormControlHelper>\n\n<FormControlHelperText className=\"text-red-500\">\n\n{field.state.meta.errors}\n\n</FormControlHelperText>\n\n</FormControlHelper>\n\n}\n\n</>\n\n)}\n\n/>\n\n\n\n<form.Field\n\nname=\"password\"\n\nvalidators={{\n\nonChangeAsyncDebounceMs:50, //Here use concept of debounce since this is heavy operation\n\nonChangeAsync: ({ value }) => {\n\nif (value.length < 6) {\n\nreturn \"Password must be at least 6 characters long\";\n\n}\n\n\n\nif (!/\\[A-Z\\]/.test(value)) {\n\nreturn \"Password must contain at least one uppercase letter\";\n\n}\n\n\n\nif (!/\\[a-z\\]/.test(value)) {\n\nreturn \"Password must contain at least one lowercase letter\";\n\n}\n\n\n\nif (!/\\[0-9\\]/.test(value)) {\n\nreturn \"Password must contain at least one number\";\n\n}\n\n},\n\n}}\n\nchildren={(field)=>(\n\n<>\n\n<FormControlLabel className=\"mt-2\">\n\n<FormControlLabelText>Password</FormControlLabelText>\n\n</FormControlLabel>\n\n<Input className=\"my-1\" size=\"md\">\n\n<InputField\n\ntype=\"password\"\n\nplaceholder=\"password\"\n\nvalue={field.state.value}\n\nonChangeText={(text) => field.handleChange(text)}\n\n/>\n\n</Input>\n\n{field.state.meta.errors &&\n\n<FormControlHelper>\n\n<FormControlHelperText className=\"text-red-500\">\n\n{field.state.meta.errors}\n\n</FormControlHelperText>\n\n</FormControlHelper>\n\n}\n\n</>\n\n)}\n\n/>\n\n\n\n<form.Field\n\nname=\"confirmPassword\"\n\nvalidators={{\n\nonChangeListenTo:\\['password'\\],\n\nonChange:({value,fieldApi})=>{\n\nif(value!==fieldApi.form.getFieldValue(\"password\")){\n\nreturn \"Passwords do not match\"\n\n}\n\n}                \n\n}}\n\nchildren={(field)=>(\n\n<>\n\n<FormControlLabel className=\"mt-2\">\n\n<FormControlLabelText>Confirm Password</FormControlLabelText>\n\n</FormControlLabel>\n\n<Input className=\"my-1\" size=\"md\">\n\n<InputField\n\ntype=\"password\"\n\nplaceholder=\"Confirm Password\"\n\nvalue={field.state.value}\n\nonChangeText={(text) => field.handleChange(text)}\n\n/>\n\n</Input>\n\n{field.state.meta.errors &&\n\n<FormControlHelper>\n\n<FormControlHelperText className=\"text-red-500\">\n\n{field.state.meta.errors}\n\n</FormControlHelperText>\n\n</FormControlHelper>\n\n}\n\n</>\n\n)}\n\n/>\n\n\n\n<form.Subscribe\n\nselector={state=>state.errors}\n\nchildren={(errors) => \n\nerrors.length > 0 && (\n\n<FormControlError>\n\n<FormControlErrorIcon\n\nas={AlertCircleIcon}\n\n/>\n\n<FormControlErrorText>\n\n\"Submit all things\"\n\n</FormControlErrorText>\n\n</FormControlError>\n\n) \n\n}\n\n/>       \n\n</FormControl>\n\n<View className=\"flex-row justify-between\">\n\n<Button className=\"w-fit mt-4 bg-blue-500\" size=\"sm\" \n\nonPress={()=>{\n\nform.reset()\n\n}}>\n\n<ButtonText>Reset</ButtonText>\n\n</Button>\n\n\n\n<Button className=\"w-fit mt-4\" size=\"sm\" \n\nonPress={()=>{\n\nform.handleSubmit()\n\n}}>\n\n<ButtonText>Submit</ButtonText>\n\n</Button>\n\n</View>\n\n</VStack>\n\n</View>\n\n);\n\n};\n\n\\`\\`\\`",
    "created_utc": 1746298187.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1ke065g/tanstack_form_formsubscibe_not_working_as/",
    "score": 0,
    "num_comments": 0
  },
  {
    "subreddit": "reactjs",
    "title": "[Show & Tell] jotai-composer \u2013 Modular State Composition in Jotai Using \u201cEnhancers\u201d (Feedback Welcome)",
    "text": ">Hi everyone! \ud83d\udc4b\n\n>I\u2019ve just released **jotai-composer**, a minimal helper built on top of Jotai that allows you to compose state in a **modular, functional, and fully typed** manner using what I call *enhancers*.\n\n# Why might this be useful?\n\n* **Isolated slices** \u2192 Each enhancer manages its own piece of state and/or actions.\n* **Simple pipeline** \u2192 Chain enhancers using pipe(enhanceWith(...)) without boilerplate.\n* **End-to-end TypeScript** \u2192 Types are inferred for state, actions, and payloads.\n* **Interop** \u2192 Works with atomWithStorage, atomWithObservable, etc.\n* If you\u2019re interested, feel free to check it out. I\u2019d appreciate any feedback you have! \ud83d\ude4f\n\n>\n\n>**GitHub:** [**https://github.com/diegodhh/jotai-compose**](https://github.com/diegodhh/jotai-compose)  \n**npm :**  [https://www.npmjs.com/package/jotai-composer](https://www.npmjs.com/package/jotai-composer)\n\n>**Live Demo:** [https://github.com/diegodhh/jotai-compose-example](https://github.com/diegodhh/jotai-compose-example)\n\n>\n\n>Thanks for reading!\n\n`import { atom } from 'jotai';`\n\n`import { pipe } from 'remeda';`\n\n`import { enhanceWith } from 'jotai-composer';`\n\n`const countAtom = atom(0);`\n\n`const counterEnhancer = {`\n\n\u00a0 `read: () => atom(get => ({ count: get(countAtom) })),`\n\n\u00a0 `write: ({ stateHelper: { get, set }, update }) =>`\n\n`update.type === 'ADD' &&`\n\n`(set(countAtom, get(countAtom) + 1), { shouldAbortNextSetter: true }),`\n\n`};`\n\n`const plusOneEnhancer = {`\n\n\u00a0 `read: ({ last }) => ({ countPlusOne: last.count + 1 }),`\n\n`};`\n\n`export const composedAtom = pipe(`\n\n\u00a0 `enhanceWith(counterEnhancer)(),`\n\n\u00a0 `enhanceWith(plusOneEnhancer),`\n\n`);`\n\n`/* In a component:`\n\n`const [state, dispatch] = useAtom(composedAtom);`\n\n`dispatch({ type: 'ADD' });`\n\n`*/`\n\n>",
    "created_utc": 1746288372.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kdwfo4/show_tell_jotaicomposer_modular_state_composition/",
    "score": 0,
    "num_comments": 3
  },
  {
    "subreddit": "reactjs",
    "title": "How I Integrated React into Our Legacy MVC App \u2014 Without a Rewrite",
    "text": "Hey guys,\n\nJust published my first Medium article and wanted to share it on here for feedback.\n\nI explain how I gradually modernised a legacy PHP MVC app by integrating React - without a full rewrite.\n\nThis was a real-world challenge at work, and I\u2019m hoping the write-up might help others in similar situations - or at least spark some discussion.\n\nWould love to hear your opinions:\n\n* Does this approach make sense?\n* Anything you\u2019d do differently?\n\nCheers!",
    "created_utc": 1746286086.0,
    "url": "https://medium.com/@johncummins1997/how-i-integrated-react-into-our-legacy-mvc-app-without-a-rewrite-3846e2f46490",
    "score": 49,
    "num_comments": 13
  },
  {
    "subreddit": "reactjs",
    "title": "Trying to proxy fresh React + Vite project to ExpressJS server using https",
    "text": "So I have new react project created with vite running on localhost:3000. I'm trying to send https request to an expressjs backend running on localhost:3001. When looking up how to send https requests in react/vite a popular option seemed to be to use vite-plugin-mkcert. This library generated two cert files:\n\n    /home/\"username\"/.vite-plugin-mkcert/dev.pem\n    /home/\"username\"/.vite-plugin-mkcert/cert.pem\n\nNow when I try to send requests I the following error:\n\n`Error: unsuitable certificate purpose`\n\n  \nMy vite.config.ts (in react) looks like this:\n\n    export default defineConfig({\n    \u00a0 plugins: [react(), tsconfigPaths(), mkcert()],\n    \u00a0 server: {\n    \u00a0 \u00a0 port: 3000,\n    \u00a0 \u00a0 proxy: {\n    \u00a0 \u00a0 \u00a0 '/api': {\n    \u00a0 \u00a0 \u00a0 \u00a0 target: 'https://localhost:3001',\n    \u00a0 \u00a0 \u00a0 \u00a0 changeOrigin: true,\n    \u00a0 \u00a0 \u00a0 },\n    \u00a0 \u00a0 },\n    \u00a0 },\n      define: {\n    \u00a0 \u00a0 'process.env': {}\n    \u00a0 }\n    });\n\n  \nAnd in express I load the cert files like this:\n\n    import https from 'https';\n    import server from './server'; // where I configure expressjs\n    \n    https.createServer({\n    \u00a0 \u00a0 key: fs.readFileSync('/home/\"username\"/.vite-plugin-mkcert/dev.pem'),\n    \u00a0 \u00a0 cert: fs.readFileSync('/home/\"username\"/.vite-plugin-mkcert/cert.pem'),\n    \u00a0 }, server).listen(Env.Port, () => console.log('server running'));\n\nI've also tried using the rootCA.pem and rootCA-key.pem files too\n\nP.S. Everything was working before when I used created-react-app and was using some cert files I made with openssl. I need express to be running https too cause it that's required by some third party stuff.",
    "created_utc": 1746235754.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kdhe5r/trying_to_proxy_fresh_react_vite_project_to/",
    "score": 2,
    "num_comments": 0
  },
  {
    "subreddit": "reactjs",
    "title": "Built a free Next.js SaaS boilerplate to save devs time (no lock-in, no fluff)",
    "text": "Hey folks \ud83d\udc4b\n\nAfter building a few SaaS products ourselves, we were tired of starter kits that stop at login or force you into paid APIs. So we created [**SaaSLaunchpad**](https://github.com/Excelorithm/SaaSLaunchpad)  a free, open-source Next.js SaaS boilerplate that\u2019s actually *ready to launch* with:\n\n* Full auth + role-based access\n* Stripe Checkout + Customer Portal\n* Team dashboard\n* Email templates (Nodemailer)\n* Firebase + OneSignal push notifications\n\nWe use open tech (Next.js, PostgreSQL, Drizzle, NextAuth, etc.) and avoided vendor lock-in.\n\nIt\u2019s hosted on GitHub for anyone to use or contribute. Hope it helps someone here build faster \ud83d\ude4c  \nOpen to feedback or suggestions!\n\n\ud83d\udd17 GitHub: [https://github.com/Excelorithm/SaaSLaunchpad](https://github.com/Excelorithm/SaaSLaunchpad)",
    "created_utc": 1746183745.0,
    "url": "https://github.com/Excelorithm/SaaSLaunchpad",
    "score": 0,
    "num_comments": 3
  },
  {
    "subreddit": "reactjs",
    "title": "\ud83d\ude80 upup \u2013 drop-in React uploader for S3, DigitalOcean, Backblaze, GCP & Azure w/ GDrive and OneDrive user integration!",
    "text": "Upup snaps into any React project and just works.\n\n* `npm i upup-react-file-uploader` add `<UpupUploader/>` \u2013 done. Easy to start, tons of customization options!.\n* Multi-cloud out of the box: S3, DigitalOcean Spaces, Backblaze B2, Google Drive, Azure Blob (Dropbox next).\n* Full stack, zero friction: Polished UI + presigned-URL helpers for Node/Next/Express.\n* Complete flexibility with styling. Allowing you to change the style of nearly all classnames of the component.\n\nBattle-tested in production already:  \n\ud83d\udcda uNotes \u2013 AI doc uploads for past exams \u2192 [https://unotes.net](https://unotes.net/)  \n\ud83c\udf99 Shorty \u2013 media uploads for transcripts \u2192 [https://aishorty.com](https://aishorty.com/)\n\n\ud83d\udc49 Try out the live demo: [https://useupup.com#demo](https://useupup.com#demo)\n\nYou can even play with the code without any setup: [https://stackblitz.com/edit/stackblitz-starters-flxnhixb](https://stackblitz.com/edit/stackblitz-starters-flxnhixb)\n\nPlease join our Discord if you need any support: [https://discord.com/invite/ny5WUE9ayc](https://discord.com/invite/ny5WUE9ayc)   \n  \nWe would be happy to support any developers of any skills to get this uploader up and running FAST!",
    "created_utc": 1746162204.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kcszw7/upup_dropin_react_uploader_for_s3_digitalocean/",
    "score": 3,
    "num_comments": 0
  },
  {
    "subreddit": "reactjs",
    "title": "Need help exporting a React resume to PDF (Tailwind + Vite)",
    "text": "Now I want to add a feature to **export the resume preview as a PDF**, and I'm running into issues.\n\nI\u2019d ideally like to:\n\n1. Keep the **layout and Tailwind styles** intact\n2. Support **A4 page size**\n3. Allow **one-click download** of the resume as a PDF\n4. The pdf should not be a screenshot. (like html2pdf etc. does)\n\nIf anyone has figured this out before or has suggestions on the best approach or libraries to use \u2014 I\u2019d *really* appreciate your help!\n\nThanks in advance \ud83d\ude4f",
    "created_utc": 1746157854.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kcrtkt/need_help_exporting_a_react_resume_to_pdf/",
    "score": 0,
    "num_comments": 5
  },
  {
    "subreddit": "reactjs",
    "title": "Introducing css-ctrl \u2014 a new, zero-runtime way to write CSS faster and more flexibly.",
    "text": "I\u2019ve been building this project on and off for a few years, exploring different ideas to make writing CSS a bit smoother and more enjoyable in my own workflow.\n\nI took ideas from various frameworks and combined the parts I liked into something simple. and that became **css-ctrl**.\n\nIt\u2019s a **zero-runtime CSS + TypeScript** solution, built for fast styling, dynamic styling with a type-safe API and seamless design system integration.\n\nSo today, I\u2019m sharing it with you, would love to hear what you think \ud83d\ude4c\n\n**\ud83d\udca1 What is css-ctrl?**\n\nIt\u2019s a **zero-runtime CSS-in-JS** solution. It isn\u2019t built on traditional\u00a0CSS-in-JS\u00a0concepts it\u2019s a\u00a0**new approach**\u00a0to writing CSS in TS and compiling\u00a0real CSS file while you\u2019re developing. so it feels like using Tailwind, CSS-Modules, and styled-components together. because it keeps your HTML clean, speeds up styling, and supports dynamic styling just like styled-components.\n\n**\ud83c\udf87 Features**\n\n\\- \ud83e\udde9 VSCode Extension it helps generate CSS, enhances the workflow, and delivers an awesome DX.\n\n\\- \u26a1 No config just install and start styling right away\n\n\\- \u2728 Use shorter, cleaner syntax like `bg[blue]`\n\n\\- \u2699\ufe0f Full **type-safety** dynamic styling\n\n\\- \ud83e\udde0 Designed for seamless **design system** integration\n\n\\- \ud83d\udca8 Super lightweight, the core library is only 3 KB, and the VSCode extension is just 700 KB.\n\n\\- and more...\n\n**\u26a0\ufe0f Important:** You\u2019ll need to install both the VSCode extension and the library.  \nThe library can\u2019t compile CSS; it\u2019s only there to support dynamic styling at runtime.\n\n**\ud83c\udf10 Docs**  \n[https://css-ctrl.dev/](https://css-ctrl.dev/)\n\n**\ud83d\udc49 Github**  \n[https://github.com/punlx/css-ctrl](https://github.com/punlx/css-ctrl)\n\nI put this together in my spare time, so the documentation might not look polished yet, but I focused on making it easy to understand and get started.\n\n\\---\n\n**\ud83d\ude4f Feedback welcome!**\n\nIf you're into CSS-in-JS, developer experience, or experimenting with new styling paradigms, I\u2019d love your feedback.\n\nTry it out and let me know what you think!\n\nHere are a few quick examples of what using `css-ctrl` looks like:\n\nStyling\n\n[https://i.imgur.com/LEOEit6.gif](https://i.imgur.com/LEOEit6.gif)\n\n**Dynamic Variables** (also supports dynamic properties - see docs)  \n[https://i.imgur.com/XpKWIBK.gif](https://i.imgur.com/XpKWIBK.gif)\n\nNested styling like SCSS\n\n[https://i.imgur.com/wGj6KDN.gif](https://i.imgur.com/wGj6KDN.gif)\n\nUsing palette from design system\n\n[https://i.imgur.com/0RvQduQ.png](https://i.imgur.com/0RvQduQ.png)\n\nUsing typo from design system\n\n[https://i.imgur.com/exCOsVM.gif](https://i.imgur.com/exCOsVM.gif)\n\nUsing variables from design system\n\n[https://i.imgur.com/cyAzKkQ.gif](https://i.imgur.com/cyAzKkQ.gif)\n\nResponsive\n\n[https://i.imgur.com/IkxVgbc.png](https://i.imgur.com/IkxVgbc.png)\n\nUsing Breakpoints\n\n[https://i.imgur.com/g8H1dkl.gif](https://i.imgur.com/g8H1dkl.gif)\n\nPseudo\n\n[https://imgur.com/a/qItiqET](https://imgur.com/a/qItiqET)\n\nAnd more feature.. in docs",
    "created_utc": 1746120906.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kcemcr/introducing_cssctrl_a_new_zeroruntime_way_to/",
    "score": 31,
    "num_comments": 52
  },
  {
    "subreddit": "reactjs",
    "title": "I need a offline map component",
    "text": "We're using Google maps to show and draw mission waypoints of a drone. But when there's no internet connection we can't even show the circles, polylines etc. We need an offline map component to show waypoints like rendering circles, polygons, polylines according to latitude and longitude data. Background can be gray or white or smth.\n\nI found some on the npm but they written with class components. And class components' lifecycles does not work quite right with functional components.\n\nDo you know a better packet or do I have to write my own?",
    "created_utc": 1746103096.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kc7otw/i_need_a_offline_map_component/",
    "score": 8,
    "num_comments": 24
  },
  {
    "subreddit": "reactjs",
    "title": "How to deal with a horrible react codebase as an inexperienced developer?",
    "text": "Recently, I was assigned a project to finish some adjustments, and this code is a disaster. It was almost entirely written by AI with no review. Someone was vibe coding hard.\n\nTo paint a picture, there's a file with 3k lines of code, 22 conditions, nearly a dozen try-catch blocks, all just to handle database errors. On the frontend.\n\nUnfortunately, I, with my impressive one year of career experience, was selected to fix this.\n\nThe problem is, I don't feel competent enough. So far, I've only worked on projects I've created. I read a lot about coding, and I\u2019m busting my ass working 60-hour weeks, but this is giving me some serious anxiety.\n\nAt first, I thought it was just the unfamiliarity with the code, but after days of documenting and trying to understand what was done, I feel completely hopeless.",
    "created_utc": 1746023770.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kbi2c5/how_to_deal_with_a_horrible_react_codebase_as_an/",
    "score": 115,
    "num_comments": 100
  },
  {
    "subreddit": "reactjs",
    "title": "ReactJS website freezing up",
    "text": "Hello dear React-Community!\n\nI worked on a reactjs website and need your help. I created it while learning reactjs with udemy tutorials, so my knowledge was not perfect and now the site has problems.\n\nThats the link to the website: [https://my-sreal.at/de](https://my-sreal.at/de)\n\n  \nMain problem: after about 10-15minutes of inactivity - simple letting the tab stay open and not clicking anything - the site freezes up. In Chrome I get the alert popup \"site doesn't respond anymore\". And then you can't click away or do anything.\n\nThere are no error messages in the console.  \nOn the homepage or other basic pages in the menu (there is a whole other menu when you're logged in. But the freezing-up happens anywhere) there are no calls to api endpoints, so that can't be it either.\n\n  \nI used Redux as a state management tool and already cleared a lot of unnecessary data from it. \n\n  \nResearch says I may have some useEffect in place that fires again and again and again and creates an infinity loop, but I can't find it.\n\n  \nI am lost and don't know how to improve the website or what the cause of this freeze-up is. Nothing happens on these pages!\n\n  \nCan you tell me what to look for or give some pointers HOW to at least find out what the cause of the problem is? I would be very grateful.\n\nAre there any tools I can install to help? I already use reacts why-did-you-render but it also does not show me anything problematic.\n\n",
    "created_utc": 1746015303.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kbeyer/reactjs_website_freezing_up/",
    "score": 2,
    "num_comments": 8
  },
  {
    "subreddit": "reactjs",
    "title": "Microfrontends Dynamic Remotes (React+Vite)",
    "text": "I'm working with Microfrontends (MFEs) using React + Vite + [vite-federation-plugin](https://github.com/originjs/vite-plugin-federation/discussions/701).\n\nI have:\n\n* A container (host) application\n* Multiple MFEs, each bundled as a standalone Vite app and deployed as a Docker image.\n\nEach MFE is built once and deployed to multiple environments (DEV, STAGE, PROD). The\u00a0**remoteEntry.js**\u00a0files are hosted at different base URLs depending on the environment.\n\n\u2753 **Challenge**  \nIn the container app, I need to define the remote MFE URLs like this:\n\n    remotes: {\n        'fe-mfe-abc': `${env.VITE_ABC_BASE_URL}/assets/remoteEntry.js`,\n        'fe-mfe-xyz': `${env.VITE_XYZ_BASE_URL}/assets/remoteEntry.js`,\n    }\n\nBut since\u00a0`VITE_ABC_BASE_URL`\u00a0changes per environment, I don't want to create separate builds of the container app for each environment.\n\n\ud83e\udde0 **Goal**  \nHow can I manage these dynamic base URLs efficiently without\u00a0**rebuilding**\u00a0the container app for every environment?\n\nAny help will be really appreciated  \nThanks",
    "created_utc": 1745963208.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kazy14/microfrontends_dynamic_remotes_reactvite/",
    "score": 9,
    "num_comments": 5
  },
  {
    "subreddit": "reactjs",
    "title": "How do you deal with `watch` from `react-hook-form` being broken with the React Compiler?",
    "text": "Now that the React Compiler has been released as an RC, I decided to try enabling it on our project at work. A lot of things worked fine out of the box, but I quickly realized that our usage of `react-hook-form` was... less fine.\n\nThe main issue seems to be that things like `watch` and `formState` apparently break the rules of React and ends up being memoized by the compiler.\n\n**If you've run into the same issues, how are you dealing with it?**\n\nIt seems neither the compiler team nor the `react-hook-form` team plan to do anything about this and instead advice us to move over to things like `useWatch` instead, but I'm unsure how to do this without our forms becoming much less readable.\n\nHere's a simplified (and kind of dumb) example of something that could be in one of our forms:\n\n    <Form.Field label=\"How many hours are you currently working per week?\">\n      <Form.Input.Number control={control} name=\"hoursFull\" />\n    </Form.Field>\n\n    <Form.Fieldset label=\"Do you want to work part-time?\">\n      <Form.Input.Boolean control={control} name=\"parttime\" />\n    </Form.Fieldset>\n\n    {watch('parttime') === true && (\n      <Form.Field label=\"How many hours would you like to work per week?\">\n        <Form.Input.Number\n          control={control}\n          name=\"hoursParttime\"\n          max={watch('hoursFull')}\n          />\n        {watch('hoursFull') != null && watch('hoursParttime') != null && (\n          <p>This would be {\n            formatPercent(watch('hoursParttime') / watch('hoursFull')\n          } of your current workload.</p>\n        )}\n      </Form.Field>\n    )}\n  \nThe input components use `useController` and are working fine, but our use of `watch` to add/remove fields, limit a numeric input based on the value of another, and to show calculated values becomes memoized by the compiler and no longer updates when the values change.\n\nThe recommendation is to switch to `useWatch`, but for that you need to move things into a child component (since it requires the `react-hook-form` context), which would make our forms much less readable, and for the `max` prop I'm not even sure it would be possible.\n\nI'm considering trying to make reusable components like `<When control={control} name=\"foo\" is={someValue}>` and `<Value control={control} name=\"bar\" format={asNumber}>`, but... still less readable, and quickly becomes difficult to maintain, especially type-wise.\n\nSo... any advice on how to migrate these types of `watch` usage? How would you solve this?",
    "created_utc": 1745924924.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kal9he/how_do_you_deal_with_watch_from_reacthookform/",
    "score": 29,
    "num_comments": 37
  },
  {
    "subreddit": "reactjs",
    "title": "Where can I import route for Error Boundaries from",
    "text": "I'm trying to create a custom element to display errors in my React project and I'm using React router in Data mode. I read the documentation and I found this Error Boundaries example but it use an import and it's path  `\"./+types/root\"` is wrong I don't know where can I import it from:\n\n    import { Route } from \"./+types/root\";\n\nI need that import to set the annotation for the error object param that contains the error data and I'm using react-ts so I need to annotate all.\n\nThis is the doc reference [https://reactrouter.com/how-to/error-boundary#error-boundaries](https://reactrouter.com/how-to/error-boundary#error-boundaries)",
    "created_utc": 1745894996.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1kadrjs/where_can_i_import_route_for_error_boundaries_from/",
    "score": 3,
    "num_comments": 3
  },
  {
    "subreddit": "reactjs",
    "title": "Adding Arpeggios to a React CAGED Guitar Theory App",
    "text": "Hi everyone, I\u2019m building a React guitar theory app to help visualize scales and chords on a fretboard. In this fifth video of my series, I walk through implementing arpeggios alongside the existing CAGED chords using TypeScript and Next.js dynamic routes. I\u2019d love your feedback on the approach and any improvements you\u2019d suggest!\n\nVideo: https://youtu.be/MZejUV0iSKg  \nSource code: https://github.com/radzionc/guitar\n",
    "created_utc": 1745811522.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1k9ma82/adding_arpeggios_to_a_react_caged_guitar_theory/",
    "score": 5,
    "num_comments": 0
  },
  {
    "subreddit": "reactjs",
    "title": "\ud83d\ude80 Feedback Wanted: Is this Zustand setup production-ready? Any improvements?",
    "text": "Hey everyone! \ud83d\udc4b\ud83c\udffc\n\nI'm building a project and using Zustand for state management.\nI modularized the slices like themeSlice, userSlice, and blogSlice and combined them like this:\n\nZustand + immer for immutable updates\n\nZustand + persist for localStorage persistence\n\nZustand + devtools for easier debugging\n\nSlices for modular separation of concerns\n\nHere\u2019s a quick overview of how I structured it:\n\nuseStore combines multiple slices.\n\nEach slice (Theme/User/Blog) is cleanly separated.\n\nUsing useShallow in components to prevent unnecessary re-renders.\n\n\u2705 Questions:\n\n\ud83d\udc49 Is this considered a best practice / production-ready setup for Zustand?\n\n\ud83d\udc49 Are there better patterns or improvements I should know about (especially for large apps)?\n\n``` \nimport { create } from \"zustand\";\nimport { immer } from \"zustand/middleware/immer\";\nimport { devtools, persist } from \"zustand/middleware\";\nimport { createThemeSlice } from \"./slice/themeSlice\";\nimport { createUserSlice } from \"./slice/userSlice\";\nimport { createBlogSlice } from \"./slice/blogSlice\";\n\nconst useStore = create(\n  devtools(\n    persist(\n      immer((...a) => ({\n        ...createThemeSlice(...a),\n        ...createUserSlice(...a),\n        ...createBlogSlice(...a),\n      })),\n      {\n        name: \"Nexus-store\",\n        version: 1,\n        enabled: true,\n      }\n    )\n  )\n);\n\nexport default useStore;\n```\n\n\n```\nconst initialUserState = {\n  isAuthenticated: false,\n  needsOtpVerification: false,\n  user: null,\n};\n\nexport const createUserSlice = (set) => ({\n  ...initialUserState, // Spread the state instead of nesting it\n  setIsAuthenticated: (isAuthenticated) =>\n    set(() => ({ isAuthenticated }), false, \"user/setIsAuthenticated\"),\n  setUser: (user) => set(() => ({ user }), false, \"user/setUser\"),\n  clearUser: () => set(() => ({ user: null }), false, \"user/clearUser\"),\n  setNeedsOtpVerification: (value) =>\n    set(\n      () => ({ needsOtpVerification: value }),\n      false,\n      \"user/setNeedsOtpVerification\"\n    ),\n});\n\n```\n\n```\nimport { BLOG_STATUS } from \"../../../../common/constants/constants\";\n\nconst initialBlogState = {\n  title: \"\",\n  coverImage: {\n    url: \"\",\n    public_id: \"\",\n  },\n  content: {},\n  category: \"\",\n  tags: [],\n  shortDescription: \"\",\n  status: BLOG_STATUS.DRAFT,\n  scheduleDate: \"\",\n  readingTime: {\n    minutes: 0,\n    words: 0,\n  },\n};\n\nexport const createBlogSlice = (set) => ({\n  blog: initialBlogState,\n  setBlogData: (data) =>\n    set(\n      (state) => {\n        Object.assign(state.blog, data);\n      },\n      false,\n      \"blog/setBlogData\"\n    ),\n\n  clearBlogData: () =>\n    set(() => ({ blog: initialBlogState }), false, \"blog/clearBlogData\"),\n});\n```\n\n```\nconst initialThemeState = {\n  isDarkTheme: true,\n};\n\nexport const createThemeSlice = (set) => ({\n  ...initialThemeState, // Spread the state instead of nesting it\n  toggleTheme: () =>\n    set(\n      (state) => ({ isDarkTheme: !state.isDarkTheme }), // Return new state object\n      false,\n      \"theme/toggleTheme\"\n    ),\n});\n```\n\n```\nconst {\n    isDarkTheme,\n    toggleTheme,\n    isAuthenticated,\n    user,\n    clearUser,\n    setIsAuthenticated,\n  } = useStore(\n    useShallow((state) => ({\n      isDarkTheme: state.isDarkTheme,\n      toggleTheme: state.toggleTheme,\n      isAuthenticated: state.isAuthenticated,\n      user: state.user,\n      clearUser: state.clearUser,\n      setIsAuthenticated: state.setIsAuthenticated,\n    }))\n  );\n\n````\n\n\n",
    "created_utc": 1745809044.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1k9ljpg/feedback_wanted_is_this_zustand_setup/",
    "score": 4,
    "num_comments": 3
  },
  {
    "subreddit": "reactjs",
    "title": "Tailwind CSS not applying styles in Vite + React (no errors, builds fine)",
    "text": "    I'm currently using **Vite (6.3.3)** + **React** with **Tailwind CSS (v4.1.4)** on an Ubuntu Linux machine. My environment appears to be set up correctly according to the latest docs (as of April 2025). The build completes without errors, and the dev server (`npm run dev`) runs without issues. Tailwind compiles, but my styles are not being applied at all.\n    \n    **Specifically:**\n    \n    - The `vite.config.js` is standard:\n    ```js\n    import { defineConfig } from 'vite';\n    import react from '@vitejs/plugin-react';\n    \n    export default defineConfig({\n      plugins: [react()],\n    });\n    ```\n    \n    - `postcss.config.js` is:\n    ```js\n    export default {\n      plugins: {\n        '@tailwindcss/postcss': {},\n        autoprefixer: {},\n      },\n    };\n    ```\n    \n    - `tailwind.config.js` is:\n    ```js\n    export default {\n      content: [\n        \"./index.html\",\n        \"./src/**/*.{js,jsx}\",\n      ],\n      theme: {\n        extend: {},\n      },\n      plugins: [],\n    };\n    ```\n    \n    - `src/index.css` correctly imports Tailwind:\n    ```css\n    @tailwind base;\n    @tailwind components;\n    @tailwind utilities;\n    ```\n    \n    - In `src/main.jsx`, I'm importing `index.css` explicitly:\n    ```jsx\n    import React from 'react';\n    import ReactDOM from 'react-dom/client';\n    import App from './App.jsx';\n    import './index.css';\n    \n    ReactDOM.createRoot(document.getElementById('root')).render(\n      <React.StrictMode>\n        <App />\n      </React.StrictMode>,\n    );\n    ```\n    \n    - My `App.jsx` component:\n    ```jsx\n    export default function App() {\n      return (\n        <div className=\"flex items-center justify-center h-screen bg-blue-600 text-white\">\n          <h1 className=\"text-3xl font-bold\">\n            Tailwind is working!\n          </h1>\n        </div>\n      );\n    }\n    ```\n    \n    **Issue:**  \n    When loading the page (`localhost:5173`), it simply displays the text without Tailwind's styling. Developer tools console shows no errors or warnings. Tailwind clearly compiles but doesn't style the output.\n    \n    **Additional context:**  \n    - Ubuntu Linux environment (permissions are fine)\n    - Incognito browser session for testing\n    - No caching issues\n    \n    This feels like something subtle but critical. Has anyone encountered this with recent Tailwind + Vite + React setups (April 2025)? Appreciate any insights, as I'm currently stuck after verifying and double-checking every configuration file.",
    "created_utc": 1745768980.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1k972uy/tailwind_css_not_applying_styles_in_vite_react_no/",
    "score": 0,
    "num_comments": 5
  },
  {
    "subreddit": "reactjs",
    "title": "Finding a good SVG shouldn't be a side quest. My solution? Spending years curating icons.",
    "text": "Hey r/react,\n\nEver get tired of hunting down decent, standardized icons for the various services, tools, or apps you're integrating into your UIs? Finding a clean SVG or PNG shouldn't be that hard.\n\nFor a while now, I've been working on [Dashboard Icons](https://github.com/homarr-labs/dashboard-icons), a curated collection of over 1800+ icons specifically for applications and services. Think icons for databases, CI/CD tools, cloud services, media servers, APIs, etc. It started as a personal project but grew quite a bit.\n\nRecently, collaborating with the [Homarr team](https://github.com/homarr-labs), we've pushed out some major updates focused on making these icons easier to find and use:\n\n* **New website:** [**https://dashboardicons.com**](https://dashboardicons.com) We built a proper site to easily search, filter, preview (light/dark), and download icons in SVG, PNG, or WebP formats. Copying SVG code directly is also an option.\n* **Metadata for integration:** This is pretty useful for devs \u2013 every icon now has a corresponding `.json` file (and a global `tree.json`) with metadata like names, aliases, and categories. Makes it much easier to integrate the icon set programmatically into your own components, icon pickers, or design systems.\n* **Optimized & standardized:** All icons are optimized, and available in standardized formats, including WebP.\n\nThe whole collection is open source and available on GitHub. If you're building dashboards, admin panels, or any UI that needs logos for specific services, this might save you some time.\n\nYou can browse everything on the [website](https://dashboardicons.com) and check out the [repo here](https://github.com/homarr-labs/dashboard-icons). If you see something missing, feel free to [suggest an icon via GitHub issues](https://github.com/homarr-labs/dashboard-icons/issues/new/choose).\n\nHope this is helpful for some of you!\n\nCheers",
    "created_utc": 1745693212.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1k8k4i9/finding_a_good_svg_shouldnt_be_a_side_quest_my/",
    "score": 24,
    "num_comments": 8
  },
  {
    "subreddit": "reactjs",
    "title": "What's the 'best' drag & drop library?",
    "text": "I'm using React & Mui, I want to create a list of components I can reorder by dragging. Might need something more complicated in the future. What's the best library for it? I saw so many and I can't choose... Thanks!",
    "created_utc": 1745683920.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1k8gjxw/whats_the_best_drag_drop_library/",
    "score": 25,
    "num_comments": 23
  },
  {
    "subreddit": "reactjs",
    "title": "React for Task Management app?",
    "text": "I'm a solo founder embarking on building a task management app with some AI functionality. Which platform should I be focusing on building first, both for functionality and adoption? \nI think the product would be more suited to desktop applications initially so I was thinking React for web (utilising shadcn components). Though I'm aware there will likely be more adoption on mobile (I'm an iOS user). \nWas initially considering using Flutter but after some testing and recommendations I don't think it's going to be performant enough for a task management app with drag & drop, long lists, etc. \nCan anyone help point me in the right direction. Are there any examples/data from other productivity startups and the approach they took? Thanks ",
    "created_utc": 1745677438.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1k8e4ie/react_for_task_management_app/",
    "score": 3,
    "num_comments": 0
  },
  {
    "subreddit": "reactjs",
    "title": "Has anyone used AI to write unit tests?",
    "text": "I'm trying to improve test coverage on a legacy project and thought maybe AI could help speed up writing basic unit tests. I know some tools can generate boilerplate, but how good are they really at making useful tests?\nHas anyone here leaned on AI for this and was it worth it?",
    "created_utc": 1745675999.0,
    "url": "https://www.reddit.com/r/reactjs/comments/1k8dlnh/has_anyone_used_ai_to_write_unit_tests/",
    "score": 0,
    "num_comments": 27
  },
  {
    "subreddit": "reactjs",
    "title": "I wrote a blog about enhancing React Hook Form with Signals and Observables \ud83d\ude80",
    "text": "Hey everyone! \ud83d\udc4b\n\nI've been diving deep into form state management recently and wanted to share a blog post I wrote:  \n\ud83d\udc49 [Super React Hook Form: Revolutionizing Form State Management with Signals and Observables](https://medium.com/@ahmedshaheen_57621/super-react-hook-form-revolutionizing-form-state-management-with-signals-and-observables-5cf311cc8b15)\n\nIn it, I explore how combining **React Hook Form** with **Signals**, **Observables**, and **Zod** can help make forms more reactive, efficient, and scalable \u2014 moving beyond the traditional centralized invalidation.\n\nIt covers:\n\n* Fine-grained form control using signals\n* Real-time validation using Zod\n* Cleaner form submission flows without unnecessary re-renders\n* A live demo and full GitHub repo\n\nIf you're interested in advanced form handling patterns, or just want to optimize your forms for better performance, I\u2019d love for you to give it a read. \ud83d\ude4c\n\nHappy to hear any feedback, thoughts, or improvements too!",
    "created_utc": 1745673977.0,
    "url": "https://medium.com/@ahmedshaheen_57621/super-react-hook-form-revolutionizing-form-state-management-with-signals-and-observables-5cf311cc8b15",
    "score": 27,
    "num_comments": 13
  },
  {
    "subreddit": "datascience",
    "title": "[D] Is Applied machine learning on time series doomed to be flawed bullshit almost all the time?",
    "text": "At this point, I genuinely can't trust any of the time series machine learning papers I have been reading especially in scientific domains like environmental science and medecine but it's the same story in other fields. Even when the dataset itself is reliable, which is rare, there\u2019s almost always something fundamentally broken in the methodology. God help me, if I see one more SHAP summary plot treated like it's the Rosetta Stone of model behavior, I might lose it. Even causal ML approaches where I had hoped we might find some solid approaches are messy, for example transfer entropy alone can be computed in 50 different ways and bottom line the closer we get to the actual truth the closer we get to Landau\u00b4s limit, finding the \u201ctruth\u201d requires so much effort that it's practically inaccessible...The worst part is almost no one has time to write critical reviews, so applied ML papers keep getting published, cited, and used to justify decisions in policy and science...Please, if you're working in ML interpretability, keep writing thoughtful critical reviews, we're in real need of more careful work to help sort out this growing mess.\n\n",
    "created_utc": 1746201671.0,
    "url": "https://www.reddit.com/r/datascience/comments/1kd4lul/d_is_applied_machine_learning_on_time_series/",
    "score": 201,
    "num_comments": 53
  },
  {
    "subreddit": "datascience",
    "title": "DS in healthcare",
    "text": "So I have a situation.   \nI have a dataset that contains real-world clinical vignettes drawn from frontline healthcare settings. Each sample presents a prompt representing a clinical case scenario, along with the response from a human clinician. The goal is to predict the the phisician's response based on the prompt.\n\nThese vignettes simulate the types of decisions nurses  must make every day, particularly in low-resource environments where access to specialists or diagnostic equipment may be limited.\n\n* These are real clinical scenarios, and the dataset is small because expert-labelled data is difficult and time-consuming to collect.\n* Prompts are diverse across medical specialties, geographic regions, and healthcare facility levels, requiring broad clinical reasoning and adaptability.\n* Responses may include abbreviations, structured reasoning (e.g. \"Summary:\", \"Diagnosis:\", \"Plan:\"), or free text.\n\nmy first go to is to fine tune a small LLM to do this but I have feeling it won't be enough given how diverse the specialties are and the size of the dataset.  \nAnyone has done something like this before? any help or resources would be welcomed.",
    "created_utc": 1745980467.0,
    "url": "https://www.reddit.com/r/datascience/comments/1kb5xj6/ds_in_healthcare/",
    "score": 11,
    "num_comments": 19
  },
  {
    "subreddit": "datascience",
    "title": "Real-time machine learning systems",
    "text": "I will be responsible for building a model that works in real time to detect anomalies (cyber security attacks) and I have zero knowledge in that. \nI need to learn how to do so, I need to learn kafka I guess, to ingest the real time data from the service that issues audit logs, use a trained ml model or predifined parameters (one is user specific and other is global and the parameters are for ips with no historical data) to be able to issue a \"signal or an alert\" for the other tier, that basically determines the attack type and do some read write to a database or s3 or something as such, also does that detection or determenation with a model that will be trained first day on synthetic data that I will simulate and later on will learn more and more parameters. At the end of the day, the model that is used in the stream will be retrained, excluding today's marked windows (if that's the right term to use) and that's the whole pipeline. \n\nWhat should I do, kinda feel lost, I'll be working alone, only know I can count on your experience and wisdom. \n\n\nTL;DR\nI need to know where to study real-time processing with machine learning integrated in the process.but I don't know where to start.\n\nThanks. ",
    "created_utc": 1745977733.0,
    "url": "https://www.reddit.com/r/datascience/comments/1kb51oz/realtime_machine_learning_systems/",
    "score": 41,
    "num_comments": 8
  },
  {
    "subreddit": "datascience",
    "title": "Putting Forecast model into Production help",
    "text": "I am looking for feedback on deploying a Sarima model. \n\n\nI am using the model to predict sales revenue on a monthly basis. The goal is identifying the trend of our revenue and then making purchasing decisions based on the trend moving up or down. I am currently forecasting 3 months into the future, storing those predictions in a table, and exporting the table onto our SQL server. \n\n\nIt is now time to refresh the forecast. I think that I retrain the model on all of the data, including the last 3 months, and then forecast another 3 months. \n\n\nMy concern is that I will not be able to rollback the model to the original version if I need to do so for whatever reason. Is this a reasonable concern? Also, should I just forecast 1 month in advance instead of 3 if I am retraining the model anyway? \n\n\nThis is my first time deploying a time series model. I am a one person shop, so I don't have anyone with experience to guide me. Please and thank you. ",
    "created_utc": 1745960564.0,
    "url": "https://www.reddit.com/r/datascience/comments/1kayvx4/putting_forecast_model_into_production_help/",
    "score": 8,
    "num_comments": 12
  },
  {
    "subreddit": "datascience",
    "title": "What is the best way to parse and order a PDF from forum screenshots that includes a lot of cached text, quotes, random order and overall a mess.",
    "text": "Hello dear people! Been dealing with this very interesting problem that I'm not 100% sure how to tackle. A local forum went down some time ago and they lost a few hours worth of data since backups aren't hourly. Quite a few topics were lost, as well as some of them apparently became corrupted and also got lost. One of them included a very nice discussion about local mountaineering and beautiful locations which a lot of people are saddened to lost since we discussed many trails. Somehow, people managed to collect data from various cached sources, computers, some screenshots, but mostly old google, bing caches while they worked and webarchive. \n\nNow it's all properly ordered in pdf document but the thing is the layouts often change and so does resolution but the general idea of how data is represented is the same. There's also some artifacts in data from webarchive for example - they have an element hovering over text and you can't see it, but if you ctrl-f to search for it it's there somehow, hidden under the image haha. No javascript in PDF, something else, probably  colored, no idea.\n\nThe ideas I had were (btw PDF is OCR'd already):\n\n&nbsp;\n\n- PDF to text and try to regex + LLM process it all somehow?\n\n- Somehow \"train\" (if train is a proper word here?) machine vision / machine learning for each separate layout so that it knows how to extract data\n\n&nbsp;\n\nBut I also face issue that some posts are for example screenshoted in \"half\", e.g. page 360 has the text cut out and continue on page 361 with random stuff on top from the archival's page (e.g. webarchive or bing cache info). I would need to also truncate this, but that should be easy.\n\n&nbsp;\n\n- Or option 3 with those new LLMs that can somehow recognize images or work with PDF (idk how they do it) I could maybe have the LLM do the whole heavy load of processing? I could pick up one of better new models with big context length and remembrance, I just checked total character count, it's 8.588.362 characters or 2.147.090 tokens approximately, but I believe the data could be split and later manually combined or something? I'm not sure I'm really new to this. The main goal is to have a nice json output with all data properly curated.\n\n&nbsp;\n\nMany thanks! Much appreciated.",
    "created_utc": 1745937058.0,
    "url": "https://www.reddit.com/r/datascience/comments/1kapczj/what_is_the_best_way_to_parse_and_order_a_pdf/",
    "score": 5,
    "num_comments": 6
  },
  {
    "subreddit": "datascience",
    "title": "is it data leakage?",
    "text": "We are predicting conversion. Conversion means customer converted from paying one-off to paying regular (subscribe)\n\nIf one feature is categorical feature \"Activity\" , consisting 15+ categories and one of the category is \"conversion\" (labelling whether the customer converted or not). The other 14 categories are various. Examples are emails, newsletter, acquisition, etc. they're companies recorded of how it got this customers (no matter it's one-off or regular customer) It may or may not be converted customers\n\nso we definitely cannot use the one category as a feature in our model otherwise it would create data leakage. What about the other 14 categories?\n\nWhat if i create dummy variables from these 15 categories + and select just 2-3 to help modelling? Would it still create leakage ?\n\nI asked this to 1. my professor 2. A professional data analyst They gave different answers. Can anyone help adding some more ideas?\n\nI tried using the whole features (convert it to dummy and drop 1), it helps the model. For random forests, the top one with high feature importance is this Activity\\_conversion (dummy of activity - conversion) feature\n\n  \nNote: found this question on a forum.",
    "created_utc": 1745921981.0,
    "url": "https://www.reddit.com/r/datascience/comments/1kaki1s/is_it_data_leakage/",
    "score": 6,
    "num_comments": 13
  },
  {
    "subreddit": "datascience",
    "title": "People here working in Healthcare how do you communicate with Healthcare professionals?",
    "text": "I'm pursuing my doctoral deg in data science. My domain is ai in Healthcare. We collab with a hospital from where I get my data. In return im practically at their beck and call. They expect me analyze some of their data and automate a few tasks. Not a big deal when I have to build a model it's usually a simple classification model where I use ml models or do some transfer learning. The problem is communicating the feature selection/extraction process. I don't need that many features for the given number of data points. \n\nHow do I explain to them that even if clinically those two features are the most important for the diagnosis I still have to scrape one of them. It's too correlated(>0.9) and is only adding noise. And I do ask them to give me more variable data and they can't. They insist I do dimensionality reduction but then I end up with lower accuracy. I don't understand why people think ai is intuitive or will know things that we humans don't. It can only perform based on the data given. \n\n",
    "created_utc": 1745662481.0,
    "url": "https://www.reddit.com/r/datascience/comments/1k89ohp/people_here_working_in_healthcare_how_do_you/",
    "score": 30,
    "num_comments": 10
  },
  {
    "subreddit": "datascience",
    "title": "Thoughts on getting a Masters while working as a DS?",
    "text": "I entered DS straight after an undergrad in Computer Science. During my degree I did multiple DS internships and an ML research internship. I figured out I didn't like research so a PhD was out. I couldn't afford to stay on for a Masters so I went straight into work and found a DS role, where I'm performing very well and getting promoted quickly.\n\nI like my current org but it's a very narrow field of work so I might want to move on in 2-3 years. I see a lot of postings (both internally and externally) require a Masters, so I'm wondering if I'm putting myself at a disadvantage by not having one.\n\nMy current employer has tuition reimbursement up to ~$6k a year so I was thinking of doing a part-time Masters (something like OMSCS, OMSA, or a statistics MS program offered by a local uni) - partially for the signalling of having a Masters, and partially because I just really love learning and I feel like the learning has stagnated in my current role... \n\nOn the other hand I'm worried that doing a Masters alongside work will impact my ability to focus on my job & progression plans. I've already done two Masters courses part-time (free, credit-bearing but can't transfer them to a degree) and found it ok but any of the degrees I've been considering would be much more workload. \n\nAnother option would be to take a year out between jobs and do a Masters, but with the job market the way it is that feels like a big risk.\n\nThanks in advance for your opinions/discussion :)",
    "created_utc": 1745654754.0,
    "url": "https://www.reddit.com/r/datascience/comments/1k87wnq/thoughts_on_getting_a_masters_while_working_as_a/",
    "score": 66,
    "num_comments": 46
  },
  {
    "subreddit": "datascience",
    "title": "Responsible Tech Certificates: A Worthwhile Expense?",
    "text": "Curious what people here think about this article: [\nResponsible Tech Certificates: A Worthwhile Expense?\n](https://alltechishuman.org/all-tech-is-human-blog/responsible-tech-certificates-a-worthwhile-expense) \n\nPersonally I find these to be mostly a waste of money, but as someone who's interested in getting into ethical AI, was wondering if anyone has had a similar experience and if it helped them get their foot in the door.",
    "created_utc": 1745619428.0,
    "url": "https://www.reddit.com/r/datascience/comments/1k7xi9g/responsible_tech_certificates_a_worthwhile_expense/",
    "score": 5,
    "num_comments": 5
  },
  {
    "subreddit": "datascience",
    "title": "How can I come up with better feature ideas?",
    "text": "I'm currently working on a credit scoring model. I have tried various feature engineering approaches using my domain knowledge, and my manager has also shared some suggestions. Additionally, I\u2019ve explored several feature selection techniques. However, the model's performance still isn't meeting my manager\u2019s expectations.\n\nAt this point, I\u2019ve even tried manually adding and removing features step by step to observe any changes in performance. I understand that modeling is all about domain knowledge, but I can't help wishing there were a magical tool that could suggest the best feature ideas.",
    "created_utc": 1745418250.0,
    "url": "https://www.reddit.com/r/datascience/comments/1k60gey/how_can_i_come_up_with_better_feature_ideas/",
    "score": 21,
    "num_comments": 19
  },
  {
    "subreddit": "datascience",
    "title": "How is your teaming using AI for DS?",
    "text": "I see a lot of job posting saying \u201cleverage AI to add value\u201d. What does this actually mean? Using AI to complete DS work or is AI is an extension of DS work?\n\nI\u2019ve seen a lot of cool is cases outside of DS like content generation or agents but not as much in DS itself. Mostly just code assist of document creation/summary which is a tool to help DS but not DS itself.",
    "created_utc": 1745358495.0,
    "url": "https://www.reddit.com/r/datascience/comments/1k5ikzd/how_is_your_teaming_using_ai_for_ds/",
    "score": 70,
    "num_comments": 51
  },
  {
    "subreddit": "datascience",
    "title": "Pandas, why the hype?",
    "text": "I'm an R user and I'm at the point where I'm not really improving my programming skills all that much, so I finally decided to learn Python in earnest. I've put together a few projects that combine general programming, ML implementation, and basic data analysis. And overall, I quite like python and it really hasn't been too difficult to pick up. And the few times I've run into an issue, I've generally blamed it on R (e.g . the day I learned about mutable objects was a frustrating one). However, basic analysis - like summary stats - feels impossible.\n\nAll this time I've heard Python users hype up pandas. But now that I am actually learning it, I can't help think why? Simple aggregations and other tasks require so much code. But more confusng is the syntax, which seems to be odds with itself at times.  Sometimes we put the column name in the parentheses of a function, other times be but the column name in brackets before the function. Sometimes we call the function normally (e.g.mean()), other times it is contain by quotations. The whole thing reminds me of the Angostura bitters bottle story, where one of the brothers designed the bottles and the other designed the label without talking to one another.\n\nAnyway, this wasn't really meant to be a rant. I'm sticking with it, but does it get better? Should I look at polars instead?\n\nTo R users, everyone needs to figure out what Hadley Wickham drinks and send him a case of it.",
    "created_utc": 1745159796.0,
    "url": "https://www.reddit.com/r/datascience/comments/1k3nxj7/pandas_why_the_hype/",
    "score": 398,
    "num_comments": 211
  },
  {
    "subreddit": "datascience",
    "title": "Python users, which R packages do you use, if any?",
    "text": "I'm currently writing an R package called [rixpress](https://github.com/b-rodrigues/rixpress) which aims to set up reproducible pipelines with simple R code by using Nix as the underlying build tool. Because it uses Nix as the build tool, it is also possible to write targets that are built using Python.\n[Here is an example of a pipeline that mixes R and Python.](https://github.com/b-rodrigues/rixpress_demos/blob/master/python_r/gen-pipeline.R)\n\nI think rixpress can be quite useful to Python users as well (and I might even translate the package to Python in the future), and I'm looking for examples of Python users that need to also work with certain R packages. These examples would help me make sure that passing objects from and between the two languages can be as seamless as possible.\n\nSo Python data scientists, which R packages do you use, if any? \n",
    "created_utc": 1745086504.0,
    "url": "https://www.reddit.com/r/datascience/comments/1k32lrl/python_users_which_r_packages_do_you_use_if_any/",
    "score": 101,
    "num_comments": 75
  },
  {
    "subreddit": "datascience",
    "title": "What does a good DS manager look like to you? How does one manage a DS project?",
    "text": "Hi all, \n\nI have found myself numerous times in leadership roles for data science projects. I never feel that I am doing a sufficient job. I find that I either end have up doing a lot of the work on my own and failing to split up task in the data science realm. A lot of these projects, and I hate to say it like this without sounding cocky, I feel that I can do on my own from end to end. Maybe some minimal support from other teams in helping with data flow issues, etc. I'm not a manager by any means, I am individual contributor. \n\nFor those in this subreddit who are managers, what are some ways you found success in managing data science teams and projects? For those as individual contributors, what are some things that you like to have in a data science manager?",
    "created_utc": 1744998234.0,
    "url": "https://www.reddit.com/r/datascience/comments/1k2ax74/what_does_a_good_ds_manager_look_like_to_you_how/",
    "score": 54,
    "num_comments": 23
  },
  {
    "subreddit": "datascience",
    "title": "Working with distance",
    "text": "I'm super curious about the solutions you're using to calculate distances. \n\nI can't share too many details, but we have data that includes two addresses and the GPS coordinates between these locations. While the results we've obtained so far are interesting, they only reflect the straight-line distance.\n\nGoogle has an API that allows you to query travel distances by car and even via public transport. However, my understanding is that their terms of service restrict storing the results of these queries and the volume of the calls.\n\nHave any of you experts explored other tools or data sources that could fulfill this need? This is for a corporate solution in the UK, so it needs to be compliant with regulations.\n\nEdit: thanks, you guys are legends ",
    "created_utc": 1744974637.0,
    "url": "https://www.reddit.com/r/datascience/comments/1k22cd4/working_with_distance/",
    "score": 15,
    "num_comments": 32
  },
  {
    "subreddit": "datascience",
    "title": "Have a lot of experience but not getting any interviews - help",
    "text": "Hi,\n\nI was here a few weeks back and you helped me to cut down my CV and demo more impact.  I have applied to jobs all over and get only rejections.\n\nI know the market is hard right now, but I would think that I would at least get invited to have at least initial conversations.  This makes me think, there must be something really missing.  Could you tell me what you think it could be?\n\nDue to AI hype there are a lot of postings with LLMs.  I don't have corporate experience there but I plan to do projects to learn & demo it.\n\nThis week I have lowered my salary requirements by 10k and still get rejections.\n\nI have 2 versions - a 2 pager and a 1 pager.  Have been applying with the 2 pager mostly until now.\n\nAm grateful for your feedback and any help you can give me\n\nhttps://preview.redd.it/e4pubfms4kve1.png?width=1414&format=png&auto=webp&s=853c4ae00db446784cb42ff17048611e5fb03a81\n\nhttps://preview.redd.it/mzsfifmv4kve1.png?width=1414&format=png&auto=webp&s=ca35aeac336eb834a54b55008efc51936c26658d\n\nhttps://preview.redd.it/l9jz6b6w4kve1.png?width=1414&format=png&auto=webp&s=802f98f4dfdb7cc5d39346c6d1a91cf6b08b95b6\n\n",
    "created_utc": 1744966399.0,
    "url": "https://www.reddit.com/r/datascience/comments/1k20azb/have_a_lot_of_experience_but_not_getting_any/",
    "score": 0,
    "num_comments": 19
  },
  {
    "subreddit": "datascience",
    "title": "What is the difference between DiD and incremental testing? I did search online and gpt but didn\u2019t find convincing difference",
    "text": "Hi \n\nWhat is the difference between DiD and incremental testing? I did search online and gpt but didn\u2019t find convincing difference, i don\u2019t get it as both are basically difference between control and treatment group. If anyone could explain then would be great help. Thanks!",
    "created_utc": 1744953050.0,
    "url": "https://www.reddit.com/r/datascience/comments/1k1x464/what_is_the_difference_between_did_and/",
    "score": 9,
    "num_comments": 8
  },
  {
    "subreddit": "datascience",
    "title": "Advice before getting data engineer fellowship position",
    "text": "Hey everybody,\n\nI need some advice. I have an MsC in Data Science and have really struggled to find jobs. I got an average paying, \u201cdata science adjacent but not data science enough\u201d quantitative analyst job in a bank. In fact , I feel like I get dumber every day I\u2019m there and I\u2019m miserable. None of the skills or achievements there are noteworthy : no model building, no big analyses, no data engineering or Gen ai work, just model validation work (helping other people fix their modeling solutions).\n\nLong story short, I\u2019m interviewing for a fellowship position to be a data engineer in a nonprofit. It lasts for one year and exposes me to many clients that I will aid. At most I can extend the fellowship for one additional year. It sounds exciting. It pays 10K less, but it\u2019s a step in the right direction. It gets me closer to what I actually studied.\n\nThe reason I write this post is because I want to know if it will negatively impact my resume or future chances. If I take this job, my resume will look like this : data analyst job (3 years) with a bit of sql and excel, two data science internships (one 3 months and one 8 months) at the university, quantitative analyst (6months), data engineer fellowship (1 year). Will this make companies look at me like a problem and not give me a chance to even interview? Thanks in advance, everybody.\n",
    "created_utc": 1744947829.0,
    "url": "https://www.reddit.com/r/datascience/comments/1k1vo23/advice_before_getting_data_engineer_fellowship/",
    "score": 7,
    "num_comments": 3
  },
  {
    "subreddit": "datascience",
    "title": "Lead DS book suggestions",
    "text": "Ive landed my first role as a lead DS. My responsibilities outside actual DS work is upskilling the analytics team in Python, R and powerBI which I've got 5+ experience with. However, this is the first role where I'm mentoring/coaching/leading a team. I would welcome any suggestions for reading materials that would help me in this new leadership role. Thank you for your time!",
    "created_utc": 1744920922.0,
    "url": "https://www.reddit.com/r/datascience/comments/1k1mjok/lead_ds_book_suggestions/",
    "score": 84,
    "num_comments": 23
  },
  {
    "subreddit": "datascience",
    "title": "Data Engineer trying to understand data science to provide better support.",
    "text": "I work as a data engineer who mainly builds & maintains data warehouses but now I\u2019m starting to get projects assigned to me asking me to build custom data pipelines for various data science projects and I\u2019m assuming deployment of Data Science/ML models to production. \n\nSince my background is data engineering, how can I learn data science in a structured bottom up manner so that I can best understand what exactly the data scientists want? \n\nThis may sound like overkill to some but so far the data scientist I\u2019m working with is trying to build a data science model that requires enriched historical data for the training of the data science model. Ok no problem so far. \n\nHowever, they then want to run the data science model on the data as it\u2019s collected (before enrichment) but the problem is this data science model is trained on enriched historical data that wont have the exact same schema as the data that\u2019s being collected real time?\n\nWhat\u2019s even more confusing is some data scientists have said this is ok and some said it isn\u2019t.\n\nI don\u2019t know which person is right. So, I\u2019d rather learn at least the basics, preferably through some good books & projects so that I can understand when the data scientists are asking for something unreasonable.\n\nI need to be able to easily speak the language of data scientists so I can provide better support and let them know when there\u2019s an issue with the data that may effect their data science model in unexpected ways. ",
    "created_utc": 1744848145.0,
    "url": "https://www.reddit.com/r/datascience/comments/1k0zcye/data_engineer_trying_to_understand_data_science/",
    "score": 65,
    "num_comments": 34
  },
  {
    "subreddit": "datascience",
    "title": "Is Agentic AI remotely useful for real business problems?",
    "text": "Agentic AI is the latest hype train to leave the station, and there has been an explosion of frameworks, tools etc. for developing LLM-based agents. The terminology is all over the place, although the definitions in the Anthropic blog \u2018Building Effective Agents\u2019 seem to be popular (I like them). \n\nHas anyone actually deployed an agentic solution to solve a business problem? Is it in production (i.e more than a PoC)? Is it actually agentic or just a workflow? I can see clear utility for open-ended web searching tasks (e.g. deep research, where the user validates everything) - but having agents autonomously navigate the internal systems of a business (and actually being useful and reliable) just seems fanciful to me, for all kinds of reasons. How can you debug these things? \n\nThere seems to be a vast disconnect between expectation and reality, more than we\u2019ve ever seen in AI. Am I wrong?",
    "created_utc": 1744705044.0,
    "url": "https://www.reddit.com/r/datascience/comments/1jzml32/is_agentic_ai_remotely_useful_for_real_business/",
    "score": 92,
    "num_comments": 55
  },
  {
    "subreddit": "datascience",
    "title": "PowerBI but not PowerBI",
    "text": "Figured this was the best community to ask this question:\n\nI have a bunch of personal data (think personal finance spreadsheet type stuff), and I'd love to build a dashboard for it - purely for me. I have access to Power BI through my work so I know how to build the sort of thing I want.\n\nHowever\n\nI obviously can't use my work account to create a personal dashboard with my personal data etc, so I'm trying to find alternative solutions.\n\nTo set up a personal PBI account seems to need a lot of hoops like owning your own domain for an email address etc, so I'm wondering if anyone in this community might use any other dashboard tools that they reccomend and that would have similar basic functionality and be a bit less faff to try and set up a personal account?",
    "created_utc": 1744620386.0,
    "url": "https://www.reddit.com/r/datascience/comments/1jyu503/powerbi_but_not_powerbi/",
    "score": 29,
    "num_comments": 40
  },
  {
    "subreddit": "datascience",
    "title": "Which topics or questions frequently asked for a data science role in traditional banks? Or for fraud detection/risk modeling topics?",
    "text": "Hi,\n\nI am proficient with statistics(causal inference , parametric non parametric tests) and ML models, but i don\u2019t what models, statistical techniques are used in fraud detection and risk modeling, especially in finance industry. So, could anyone suggest FAQs? Or topics i should focus more on? Or any not common topic you ask to candidates that are crucial to know? Role requires 3+ years of experience.\n\nAlso, would like to know what techniques you work on in your day to work in fraud detection. It would help me great how it works in industry and prepare for a potential interview. Thanks! \n\n\nEdit-\nWould you consider it to be similar like anomaly detection in time series? If so what methods you use in your company, i know concept of a few methods like z-score, arima, sarima, med and other but would like to know in practice what you use as well\n\nEdit 2- i am interested more on the topics that i could learn, like i know sql and python will be there",
    "created_utc": 1744499468.0,
    "url": "https://www.reddit.com/r/datascience/comments/1jxtzs1/which_topics_or_questions_frequently_asked_for_a/",
    "score": 24,
    "num_comments": 16
  },
  {
    "subreddit": "datascience",
    "title": "Ace The Interview - SQL Intuitively and Exhaustively Explained",
    "text": "SQL is easy to learn and hard to master. Realistically, the difficulty of the questions you get will largely be dictated by the job role you're trying to fill.\n\nFrom it's highest level, SQL is a \"declarative language\", meaning it doesn't define a set of operations, but rather a desired end result. This can make SQL incredibly expressive, but also a bit counterintuitive, especially if you aren't fully aware of it's declarative nature.\n\nSQL expressions are passed through an SQL engine, like PostgreSQL, MySQL, and others. Thes engines parse out your SQL expressions, optimize them, and turn them into an actual list of steps to get the data you want. While not as often discussed, for beginners I recommend SQLite. It's easy to set up in virtually any environment, and allows you to get rocking with SQL quickly. If you're working in big data, I recommend also brushing up on something like PostgreSQL, but the differences are not so bad once you have a solid SQL understanding.\n\nIn being a high level declaration, SQL\u2019s grammatical structure is, fittingly, fairly high level. It\u2019s kind of a weird, super rigid version of English. SQL queries are largely made up of:\n\n* **Keywords:**\u00a0special words in SQL that tell an engine what to do. Some common ones, which we\u2019ll discuss, are\u00a0`SELECT, FROM, WHERE, INSERT, UPDATE, DELETE, JOIN, ORDER BY, GROUP BY`\u00a0. They can be lowercase or uppercase, but usually they\u2019re written in uppercase.\n* **Identifiers:**\u00a0Identifiers are the names of database objects like tables, columns, etc.\n* **Literals:**\u00a0numbers, text, and other hardcoded values\n* **Operators:**\u00a0Special characters or keywords used in comparison and arithmetic operations. For example\u00a0`!=`,\u00a0`<`\u00a0,`OR`,\u00a0`NOT`\u00a0,\u00a0`*`,\u00a0`/`,\u00a0`%`\u00a0,\u00a0`IN`,\u00a0`LIKE`\u00a0. We\u2019ll cover these later.\n* **Clauses:**\u00a0These are the major building block of SQL, and can be stitched together to combine a queries general behavior. They usually start with a keyword, like \n   * `SELECT`\u00a0\u2013 defines which columns to return \n   * `FROM`\u00a0\u2013 defines the source table \n   * `WHERE`\u00a0\u2013 filters rows \n   * `GROUP BY`\u00a0\u2013 groups rows etc.  \n\nBy combining these clauses, you create an SQL query\n\nThere are a ton of things you can do in SQL, like create tables:\n\n    CREATE TABLE People(first_name, last_name, age, favorite_color)\n\nInsert data into tables:\n\n    INSERT INTO People\n    VALUES\n        ('Tom', 'Sawyer', 19, 'White'),\n        ('Mel', 'Gibson', 69, 'Green'),\n        ('Daniel', 'Warfiled', 27, 'Yellow')\n\nSelect certain data from tables:\n\n    SELECT first_name, favorite_color FROM People\n\nSearch based on some filter\n\n    SELECT * FROM People WHERE id = 3\n\nAnd Delete Data\n\n    DELETE FROM People WHERE age < 30 \n\nWhat was previously mentioned makes up the cornerstone of pretty much all of SQL. Everything else builds on it, and there is a lot.\n\n**Primary and Foreign Keys**  \nA *primary key* is a unique identifier for each record in a table. A *foreign key* references a primary key in another table, allowing you to relate data across tables. This is the backbone of relational database design.\n\n**Super Keys and Composite Keys**  \nA *super key* is any combination of columns that can uniquely identify a row. When a unique combination requires multiple columns, it\u2019s often called a *composite key* \u2014 useful in complex schemas like logs or transactions.\n\n**Normalization and Database Design**  \nNormalization is the process of splitting data into multiple related tables to reduce redundancy. First Normal Form (1NF) ensures atomic rows, Second Normal Form (2NF) separates logically distinct data, and Third Normal Form (3NF) eliminates derived data stored in the same table.\n\n**Creating Relational Schemas in SQLite**  \nYou can explicitly define tables with `FOREIGN KEY` constraints using `CREATE TABLE`. These relationships enforce referential integrity and enable behaviors like cascading deletes. SQLite enforces `NOT NULL` and `UNIQUE` constraints strictly, making your schema more robust.\n\n**Entity Relationship Diagrams (ERDs)**  \nERDs visually represent tables and their relationships. Dotted lines and cardinality markers like `{0,1}` or `0..N` indicate how many records in one table relate to another, which helps document and debug schema logic.\n\n**JOINs**  \nJOIN operations combine rows from multiple tables using foreign keys. `INNER JOIN` includes only matched rows, `LEFT JOIN` includes all from the left table, and `FULL OUTER JOIN` (emulated in SQLite) combines both. Proper JOINs are critical for data integration.\n\n**Filtering and LEFT/RIGHT JOIN Differences**  \nJOIN order affects which rows are preserved when there\u2019s no match. For example, using `LEFT JOIN` ensures all left-hand rows are kept \u2014 useful for identifying unmatched data. SQLite lacks `RIGHT JOIN`, but you can simulate it by flipping the table order in a `LEFT JOIN`.\n\n**Simulating FULL OUTER JOINs**  \nSQLite doesn\u2019t support `FULL OUTER JOIN`, but you can emulate it with a `UNION` of two `LEFT JOIN` queries and a `WHERE` clause to catch nulls from both sides. This approach ensures no records are lost in either table.\n\n**The WHERE Clause and Filtration**  \n`WHERE` filters records based on conditions, supporting logical operators (`AND`, `OR`), numeric comparisons, and string operations like `LIKE`, `IN`, and `REGEXP`. It's one of the most frequently used clauses in SQL.\n\n**DISTINCT Selections**  \nUse `SELECT DISTINCT` to retrieve unique values from a column. You can also select distinct combinations of columns (e.g., `SELECT DISTINCT name, grade`) to avoid duplicate rows in the result.\n\n**Grouping and Aggregation Functions**  \nWith `GROUP BY`, you can compute metrics like `AVG`, `SUM`, or `COUNT` for each group. `HAVING` lets you filter grouped results, like showing only departments with an average salary above a threshold.\n\n**Ordering and Limiting Results**  \n`ORDER BY` sorts results by one or more columns in ascending (`ASC`) or descending (`DESC`) order. `LIMIT` restricts the number of rows returned, and `OFFSET` lets you skip rows \u2014 useful for pagination or ranked listings.\n\n**Updating and Deleting Data**  \n`UPDATE` modifies existing rows using `SET`, while `DELETE` removes rows based on `WHERE` filters. These operations can be combined with other clauses to selectively change or clean up data.\n\n**Handling NULLs**  \n`NULL` represents missing or undefined values. You can detect them using `IS NULL` or replace them with defaults using `COALESCE`. Aggregates like `AVG(column)` ignore NULLs by default, while `COUNT(*)` includes all rows.\n\n**Subqueries**  \nSubqueries are nested `SELECT` statements used inside `WHERE`, `FROM`, or `SELECT`. They\u2019re useful for filtering by aggregates, comparisons, or generating intermediate results for more complex logic.\n\n**Correlated Subqueries**  \nThese are subqueries that reference columns from the outer query. Each row in the outer query is matched against a custom condition in the subquery \u2014 powerful but often inefficient unless optimized.\n\n**Common Table Expressions (CTEs)**  \nCTEs let you define temporary named result sets with `WITH`. They make complex queries readable by breaking them into logical steps and can be used multiple times within the same query.\n\n**Recursive CTEs**  \nRecursive CTEs solve hierarchical problems like org charts or category trees. A base case defines the start, and a recursive step extends the output until no new rows are added. Useful for generating sequences or computing reporting chains.\n\n**Window Functions**  \nWindow functions perform calculations across a set of table rows related to the current row. Examples include `RANK()`, `ROW_NUMBER()`, `LAG()`, `LEAD()`, `SUM() OVER ()`, and moving averages with sliding windows.\n\nThese all can be combined together to do a lot of different stuff.\n\nIn my opinion, this is too much to learn efficiently learn outright. It requires practice and the slow aggregation of concepts over many projects. If you're new to SQL, I recommend studying the basics and learning through doing. However, if you're on the job hunt and you need to cram, you might find this breakdown useful: [https://iaee.substack.com/p/structured-query-language-intuitively](https://iaee.substack.com/p/structured-query-language-intuitively)",
    "created_utc": 1744474855.0,
    "url": "https://www.reddit.com/r/datascience/comments/1jxl18x/ace_the_interview_sql_intuitively_and/",
    "score": 224,
    "num_comments": 14
  },
  {
    "subreddit": "datascience",
    "title": "[Help] Modeling Tariff Impacts on Trade Flow",
    "text": "\nI'm working on a trade flow forecasting system that uses the RAS algorithm to disaggregate high-level forecasts to detailed commodity classifications. The system works well with historical data, but now I need to incorporate the impact of new tariffs without having historical tariff data to work with.\n\nCurrent approach:\n- Use historical trade patterns as a base matrix\n- Apply RAS to distribute aggregate forecasts while preserving patterns\n\nNeed help with:\n- Methods to estimate tariff impacts on trade volumes by commodity\n- Incorporating price elasticity of demand\n- Modeling substitution effects (trade diversion)\n- Integrating these elements with our RAS framework\n\nAny suggestions for modeling approaches that could work with limited historical tariff data? Particularly interested in econometric methods or data science techniques that maintain consistency across aggregation levels.\n\nThanks in advance!",
    "created_utc": 1744453493.0,
    "url": "https://www.reddit.com/r/datascience/comments/1jxe7rg/help_modeling_tariff_impacts_on_trade_flow/",
    "score": 5,
    "num_comments": 5
  },
  {
    "subreddit": "datascience",
    "title": "Fixing the Agent Handoff Problem in LlamaIndex's AgentWorkflow System",
    "text": "[Fixing the Agent Handoff Problem in LlamaIndex's AgentWorkflow System](https://preview.redd.it/shjbjpxccyte1.png?width=1280&format=png&auto=webp&s=3338b6859f2cc9e4852d1ec0a3ffd59e3511c3e3)\n\n# The position bias in LLMs is the root cause of the problem\n\nI've been working with LlamaIndex's AgentWorkflow framework - a promising multi-agent orchestration system that lets different specialized AI agents hand off tasks to each other. But there's been one frustrating issue: when Agent A hands off to Agent B, Agent B often fails to continue processing the user's original request, forcing users to repeat themselves.\n\nThis breaks the natural flow of conversation and creates a poor user experience. Imagine asking for research help, having an agent gather sources and notes, then when it hands off to the writing agent - silence. You have to ask your question again!\n\n[The receiving agent doesn't immediately respond to the user's latest request - the user has to repeat their question.](https://preview.redd.it/ucl76xnmcyte1.png?width=883&format=png&auto=webp&s=4fc975569f3bda5238ebb5ed1e5b08ff7cc86049)\n\n**Why This Happens: The Position Bias Problem**\n\nAfter investigating, I discovered this stems from how large language models (LLMs) handle long conversations. They suffer from \"position bias\" - where information at the beginning of a chat gets \"forgotten\" as new messages pile up.\n\n[Different positions in the chat context have different attention weights. Arxiv 2407.01100](https://preview.redd.it/ugtqdq2tdyte1.png?width=519&format=png&auto=webp&s=cf9978aef461521633c8e20786ed48d8a106a2de)\n\nIn AgentWorkflow:\n\n1. User requests go into a memory queue first\n2. Each tool call adds 2+ messages (call + result)\n3. The original request gets pushed deeper into history\n4. By handoff time, it's either buried or evicted due to token limits\n\n[FunctionAgent puts both tool\\_call and tool\\_call\\_result info into ChatMemory, which pushes user requests to the back of the queue.](https://preview.redd.it/ypd4caewdyte1.png?width=786&format=png&auto=webp&s=240629c41c2f581dd7c3c8917912827358db5525)\n\nResearch shows that in an 8k token context window, information in the first 10% of positions can lose over 60% of its influence weight. The LLM essentially \"forgets\" the original request amid all the tool call chatter.\n\n**Failed Attempts**\n\nFirst, I tried the developer-suggested approach - modifying the handoff prompt to include the original request. This helped the receiving agent see the request, but it still lacked context about previous steps.\n\n[The original handoff implementation didn't include user request information.](https://preview.redd.it/lbnm2laxcyte1.png?width=681&format=png&auto=webp&s=261eb162385f7f471c92a7812c188404ed682548)\n\n[The output of the updated handoff now includes both chat history review and user request information.](https://preview.redd.it/u5eukjkycyte1.png?width=681&format=png&auto=webp&s=2956e9aa2f88ce7aa65da0f09fbdb93a7930aa27)\n\nNext, I tried reinserting the original request after handoff. This worked better - the agent responded - but it didn't understand the full history, producing incomplete results.\n\n[After each handoff, I copy the original user request to the queue's end. ](https://preview.redd.it/j5irsta0dyte1.png?width=807&format=png&auto=webp&s=f4cbaf58ca093a06938e0ccf9cd7ea9164def92d)\n\n**The Solution: Strategic Memory Management**\n\nThe breakthrough came when I realized we needed to work with the LLM's natural attention patterns rather than against them. My solution:\n\n1. **Clean Chat History**: Only keep actual user messages and agent responses in the conversation flow\n2. **Tool Results to System Prompt**: Move all tool call results into the system prompt where they get 3-5x more attention weight\n3. **State Management**: Use the framework's state system to preserve critical context between agents\n\n[Attach the tool call result as state info in the system\\_prompt.](https://preview.redd.it/yj1wmx06eyte1.png?width=634&format=png&auto=webp&s=96272c1d5ead65d83881780ae6ee4d92d7c0e7aa)\n\nThis approach respects how LLMs actually process information while maintaining all necessary context.\n\n**The Results**\n\nAfter implementing this:\n\n* Receiving agents immediately continue the conversation\n* They have full awareness of previous steps\n* The workflow completes naturally without repetition\n* Output quality improves significantly\n\nFor example, in a research workflow:\n\n1. Search agent finds sources and takes notes\n2. Writing agent receives handoff\n3. It immediately produces a complete report using all gathered information\n\n[ResearchAgent not only continues processing the user request but fully perceives the search notes, ultimately producing a perfect research report.](https://preview.redd.it/1hw8vza8dyte1.png?width=671&format=png&auto=webp&s=b721645671c5639c2e0b7990395ed077a992900f)\n\n**Why This Matters**\n\nUnderstanding position bias isn't just about fixing this specific issue - it's crucial for anyone building LLM applications. These principles apply to:\n\n* All multi-agent systems\n* Complex workflows\n* Any application with extended conversations\n\nThe key lesson: LLMs don't treat all context equally. Design your memory systems accordingly.\n\n[In different LLMs, the positions where the model focuses on important info don't always match the actual important info spots. ](https://preview.redd.it/ex69ri8cdyte1.png?width=575&format=png&auto=webp&s=d680659f6e9889775c4d24b650e06ac9791945df)\n\n**Want More Details?**\n\nIf you're interested in:\n\n* The exact code implementation\n* Deeper technical explanations\n* Additional experiments and findings\n\nCheck out the full article on\n\n[https://www.dataleadsfuture.com/fixing-the-agent-handoff-problem-in-llamaindexs-agentworkflow-system/](https://www.dataleadsfuture.com/fixing-the-agent-handoff-problem-in-llamaindexs-agentworkflow-system/)\n\nI've included all source code and a more thorough discussion of position bias research.\n\nHave you encountered similar issues with agent handoffs? What solutions have you tried? Let's discuss in the comments!",
    "created_utc": 1744267056.0,
    "url": "https://www.reddit.com/r/datascience/comments/1jvrgr5/fixing_the_agent_handoff_problem_in_llamaindexs/",
    "score": 21,
    "num_comments": 5
  },
  {
    "subreddit": "datascience",
    "title": "Hi, I\u2019m a junior in high school and I am interested in Data Science. What\u2019s steps should I take to get there (from now to the end of high school)?",
    "text": "Picture will be referenced later\n\nFor some background all I\u2019ve done related to data science is a harvard edx python course which I took twice (first time I got all the way to the final project then quit, the second time I wasn\u2019t able to finish all the lectures). Though I know I have the skills, I really need a refresher on the language.\n\nSome questions I have are:\n1. Is it good to take certifications in this field. For example, in the computer networking role, the CCNA is an extremely important certification and can easily get you hired for an entry level position. Is there anything similar in data science?\n\n2. Any way to find data science internships? Idk why but it\u2019s kinda hard to find data science internships. I did manage to find a few, but idk which ones the best use of my time. Any help here?\n\n3. In the picture I put a roadmap that i found online. The words are kinda small; to clarify, first they say to learn python, then R, then GIT, then data structures and algorithms, after that they recommend learning SQL, then math/statistics, then data processing and visualization, machine learning, deep learning, and finally big data. Is this a good path to follow? If so how should I approach going down this route? Any resources I can use to start learning?\n\nAny other tips would be greatly appreciated, thank you all for reading I really appreciate it.",
    "created_utc": 1744202852.0,
    "url": "https://i.redd.it/o565hwzk2tte1.jpeg",
    "score": 0,
    "num_comments": 31
  },
  {
    "subreddit": "datascience",
    "title": "Familiar matchmaking in gaming; to match players with players they like and have played with before",
    "text": "I've seen the classic MMRs before based on skill level in many different games. \n\nBut the truth is gaming is about fun, and playing with people you already like or who are similar to people you like is a massive fun multiplier\n\nSo the challenge is how would you design a method to achieve that? Multiple algorithms, or something simpler?  \n  \nMy initial idea is raw, and ripe for improvement\n\nDuring or after a game session is over you get to thumbs up or thumbs down players you enjoyed playing with. \n\nLater on if you are in a matchmaking queue the list of players you've thumbed up is consulted and the party that has players with the greatest total thumbs up points at the top of that list gets matched to your party if there is free space, and if you are at the top of the available people on their end too.\n\nThe end goal here is to make public matchmaking more fun, and feel more familiar as you get to play repeatedly with players you've enjoyed playing with before.\n\nThe main issue with this type of matchmaking is that over time it would be difficult for newer players to get enough thumbs up to get higher on the list. Harder to get to play with the people who already have a large pool of people they like to play with. I don't know how to solve that issue at the moment.",
    "created_utc": 1744180578.0,
    "url": "https://www.reddit.com/r/datascience/comments/1juzclh/familiar_matchmaking_in_gaming_to_match_players/",
    "score": 22,
    "num_comments": 7
  },
  {
    "subreddit": "datascience",
    "title": "Absolutely BOMBED Interview",
    "text": "I landed a position 3 weeks ago, and so far wasn\u2019t what I expected in terms of skills. Basically, look at graphs all day and reboot IT issues. Not ideal, but I guess it\u2019s an ok start. \n\nRight when I started, I got another interview from a company paying similar, but more aligned to my skill set in a different industry. I decided to do it for practice based on advice from l people on here.\n\nFirst interview went well, then got a technical interview scheduled for today and ABSOLUTELY BOMBED it. It was BAD BADD. It made me realize how confused I was with some of the basics when it comes to the field and that I was just jumping to more advanced skills, similar to what a lot of people on this group do. It was literally so embarrassing and I know I won\u2019t be moving to the next steps. \n\nBasically the advice I got from the senior data scientist was to focus on the basics and don\u2019t rush ahead to making complex models and deployments. Know the basics of SQL, Statistics (linear regression, logistic, xgboost) and how you\u2019re getting your coefficients and what they mean, and Python. \n\nKnow the basics!!",
    "created_utc": 1744145436.0,
    "url": "https://www.reddit.com/r/datascience/comments/1juo7ue/absolutely_bombed_interview/",
    "score": 521,
    "num_comments": 68
  },
  {
    "subreddit": "datascience",
    "title": "Career Crossroads: DS Manager (Retail) w/ Finance Background -> Head of Finance Analytics Offer - Seeking Guidance & Perspectives",
    "text": "\nHey r/datascience,\n\nHoping to tap into the collective wisdom here regarding a potential career move. I'd appreciate any insights or perspectives you might have.\n\nMy Background:\n\nCurrent Role: Data Science Manager at a Retail company.\n\nExperience: ~8 years in Data Science (started as IC, now Manager).\n\nPrior Experience: ~5 years in Finance/M&A before transitioning into data science.\nThe Opportunity:\n\nI have an opportunity for a Head of Finance Analytics role, situated within (or closely supporting) the Financial Planning & Analysis (FP&A) function.\n\nThe Appeal: \nThis role feels like a potentially great way to merge my two distinct career paths (Finance + Data Science). It leverages my domain knowledge from both worlds. The \"Head of\" title also suggests significant leadership scope.\n\nThe Nature of the Work:\nThe primary focus will be data analysis using SQL and BI tools to support financial planning and decision-making.\nRevenue forecasting is also a key component.\nHowever, it's not a traditional data science role. Expect limited exposure to diverse ML projects or building complex predictive models beyond forecasting.\nThe tech stack is not particularly advanced (likely more SQL/BI-centric than Python/R ML libraries).\n\n\nMy Concerns / Questions for the Community:\n\nCareer Trajectory - Title vs. Substance? \nMoving from a \"Data Science Manager\" to a \"Head of Finance Analytics\" seems like a step up title-wise. However, is shifting focus primarily to SQL/BI-driven analysis and forecasting, away from broader ML/DS projects and advanced techniques, a potential functional downstep or specialization that might limit future pure DS leadership roles?\n\nTechnical Depth vs. Seniority: \nAs you move towards Head of/Director/VP levels, how critical is maintaining cutting-edge data science technical depth versus deep domain expertise (finance), strategic impact through analysis, and leadership? Does the type of technical work (e.g., complex SQL/BI vs. complex ML) become less defining at these senior levels?\n\nCompensation Outlook: \nWhat does the compensation landscape typically look like for senior analytics leadership roles like \"Head of Finance Analytics,\" especially within FP&A or finance departments, compared to pure Data Science management/director tracks in tech or other industries? Trying to gauge the long-term financial implications.\n\nI'm essentially weighing the unique opportunity to blend my background and gain a significant leadership title (\"Head of\") against the trade-offs in the type of technical work and the potential divergence from a purely data science leadership path.\n\nHas anyone made a similar move or have insights into navigating careers at the intersection of Data Science and Finance/FP&A, particularly in roles heavy on analysis and forecasting? Any perspectives on whether this is a strategic pivot leveraging my unique background or a potential limitation for future high-level DS roles would be incredibly helpful.\n\nThanks in advance for your thoughts!\n\nTL;DR: DS Manager (8 YOE DS, 5 YOE Finance) considering \"Head of Finance Analytics\" role. Opportunity to blend background + senior title. Work is mainly SQL/BI analysis + forecasting, less diverse/advanced DS. Worried about technical \"downstep\" vs. pure DS track & long-term compensation. Seeking advice.\n",
    "created_utc": 1744073148.0,
    "url": "https://www.reddit.com/r/datascience/comments/1ju139m/career_crossroads_ds_manager_retail_w_finance/",
    "score": 26,
    "num_comments": 15
  },
  {
    "subreddit": "coding",
    "title": "Mastering Kafka in .NET: Schema Registry, Error Handling & Multi-Message Topics",
    "text": "",
    "created_utc": 1746521049.0,
    "url": "https://hamedsalameh.com/mastering-kafka-in-net-schema-registry-amp-error-handling/",
    "score": 1,
    "num_comments": 0
  },
  {
    "subreddit": "coding",
    "title": "No \"I made a ____\" posts. No AI slop posts. No advertising. No discord links. No surveys.",
    "text": "Please abide by the rules. Message the moderators the word \"tuna\" if you actually read them and feel like your post was removed or you were banned in error.",
    "created_utc": 1746376827.0,
    "url": "https://www.reddit.com/r/coding/comments/1keo68j/no_i_made_a_posts_no_ai_slop_posts_no_advertising/",
    "score": 81,
    "num_comments": 2
  },
  {
    "subreddit": "coding",
    "title": "Debugging Tips",
    "text": "",
    "created_utc": 1745157853.0,
    "url": "https://www.ladderly.io/blog/2025-03-30-debugging-tips",
    "score": 1,
    "num_comments": 0
  },
  {
    "subreddit": "coding",
    "title": "Resource Injection in Java (Deepdive help/suggestions)",
    "text": "",
    "created_utc": 1744277176.0,
    "url": "https://medium.com/@anishnarayan/resource-injection-in-java-c14e16035ebf",
    "score": 3,
    "num_comments": 0
  },
  {
    "subreddit": "Python",
    "title": "Logfire-callback: observability for Hugging Face Transformers training",
    "text": "I am pleased to introduce\u00a0logfire-callback, an open-source initiative aimed at enhancing the observability of machine learning model training by integrating Hugging Face\u2019s Transformers library with the Pydantic Logfire logging service. This tool facilitates real-time monitoring of training progress, metrics, and events, thereby improving the transparency and efficiency of the training process.\n\n**What it does:** logfire-callback\u00a0is an open-source Python package designed to integrate Hugging Face\u2019s Transformers training workflows with the Logfire observability platform. It provides a custom\u00a0TrainerCallback\u00a0that logs key training events\u2014such as epoch progression, evaluation metrics, and loss values\u2014directly to Logfire. This integration facilitates real-time monitoring and diagnostics of machine learning model training processes.The callback captures and transmits structured logs, enabling developers to visualize training dynamics and performance metrics within the Logfire interface. This observability is crucial for identifying bottlenecks, diagnosing issues, and optimizing training workflows.\n\n**Target audience:** This project is tailored for machine learning engineers and researchers who utilize Hugging Face\u2019s Transformers library for model training and seek enhanced observability of their training processes. It is particularly beneficial for those aiming to monitor training metrics in real-time, debug training issues, and maintain comprehensive logs for auditing and analysis purposes.\n\n**Comparison:** While Hugging Face\u2019s Transformers library offers built-in logging capabilities,\u00a0**logfire-callback**\u00a0distinguishes itself by integrating with Logfire, a platform that provides advanced observability features. This integration allows for more sophisticated monitoring, including real-time visualization of training metrics, structured logging, and seamless integration with other observability tools supported by Logfire.\n\nCompared to other logging solutions,\u00a0logfire-callback\u00a0offers a streamlined and specialized approach for users already within the Hugging Face and Logfire ecosystems. Its design emphasizes ease of integration and immediate utility, reducing the overhead typically associated with setting up comprehensive observability for machine learning training workflows.\n\nThe project is licensed under the Apache-2.0 License, ensuring flexibility for both personal and commercial use.\n\nFor more details and to contribute to the project, please visit the GitHub repository containing the source code:\u00a0[https://github.com/louisbrulenaudet/logfire-callback](https://github.com/louisbrulenaudet/logfire-callback)\n\nI welcome feedback, contributions, and discussions to enhance tool\u2019s functionality and applicability.",
    "created_utc": 1746472230.0,
    "url": "https://www.reddit.com/r/Python/comments/1kfk2i8/logfirecallback_observability_for_hugging_face/",
    "score": 2,
    "num_comments": 0
  },
  {
    "subreddit": "Python",
    "title": "uv-version-bumper \u2013 Simple version bumping & tagging for Python projects using uv",
    "text": "# What My Project Does\n\n[`uv-version-bumper`](https://github.com/alltuner/uv-version-bumper) is a small utility that automates version bumping, dependency lockfile updates, and git tagging for Python projects managed with [`uv`](https://github.com/astral-sh/uv) using the recently added `uv version` command.\n\nIt\u2019s powered by a `justfile`, which you can run using `uvx`\u2014so there\u2019s no need to install anything extra. It handles:\n\n* Ensuring your git repo is clean\n* Bumping the version (`patch`, `minor`, or `major`) in `pyproject.toml`\n* Running `uv sync` to regenerate the lockfile\n* Committing changes\n* Creating annotated git tags (if not already present)\n* Optionally pushing everything to your remote\n\nExample usage:\n\n    uvx --from just-bin just bump-patch\n    uvx --from just-bin just push-all\n\n# Target Audience\n\nThis tool is meant for developers who are:\n\n* Already using `uv` as their package/dependency manager\n* Looking for a simple and scriptable way to bump versions and tag releases\n* Not interested in heavier tools like `semantic-release` or complex CI pipelines\n* Comfortable with using a `justfile` for light project automation\n\nIt's intended for real-world use in small to medium projects, but doesn't try to do too much. No changelog generation or CI/CD hooks\u2014just basic version/tag automation.\n\n# Comparison\n\nThere are several tools out there for version management in Python projects:\n\n* [`bump2version`](https://github.com/c4urself/bump2version) \u2013 flexible but requires config and extra install\n* [`python-semantic-release`](https://github.com/python-semantic-release/python-semantic-release) \u2013 great for CI/CD pipelines but overkill for simpler workflows\n* [`release-it`](https://github.com/release-it/release-it) \u2013 powerful, cross-language tool but not Python-focused\n\nIn contrast, `uv-version-bumper` is:\n\n* **Zero-dependency (beyond** `uv`**)**\n* **Integrated into your** `uv`**-based workflow** using `uvx`\n* **Intentionally minimal**\u2014no YAML config, no changelog, no opinions on your branching model\n\nIt\u2019s also designed as a temporary bridge until native task support is added to `uv` ([discussion](https://github.com/astral-sh/uv/issues/5903)).\n\nGive it a try: \ud83d\udce6 [https://github.com/alltuner/uv-version-bumper](https://github.com/alltuner/uv-version-bumper) \ud83d\udcdd Blog post with context: [https://davidpoblador.com/blog/introducing-uv-version-bumper-simple-version-bumping-with-uv.html](https://davidpoblador.com/blog/introducing-uv-version-bumper-simple-version-bumping-with-uv.html)\n\nWould love feedback\u2014especially if you're building things with `uv`.",
    "created_utc": 1746468884.0,
    "url": "https://www.reddit.com/r/Python/comments/1kfinsq/uvversionbumper_simple_version_bumping_tagging/",
    "score": 35,
    "num_comments": 11
  },
  {
    "subreddit": "Python",
    "title": "Monday Daily Thread: Project ideas!",
    "text": "# Weekly Thread: Project Ideas \ud83d\udca1\n\nWelcome to our weekly Project Ideas thread! Whether you're a newbie looking for a first project or an expert seeking a new challenge, this is the place for you.\n\n## How it Works:\n\n1. **Suggest a Project**: Comment your project idea\u2014be it beginner-friendly or advanced.\n2. **Build & Share**: If you complete a project, reply to the original comment, share your experience, and attach your source code.\n3. **Explore**: Looking for ideas? Check out Al Sweigart's [\"The Big Book of Small Python Projects\"](https://www.amazon.com/Big-Book-Small-Python-Programming/dp/1718501242) for inspiration.\n\n## Guidelines:\n\n* Clearly state the difficulty level.\n* Provide a brief description and, if possible, outline the tech stack.\n* Feel free to link to tutorials or resources that might help.\n\n# Example Submissions:\n\n## Project Idea: Chatbot\n\n**Difficulty**: Intermediate\n\n**Tech Stack**: Python, NLP, Flask/FastAPI/Litestar \n\n**Description**: Create a chatbot that can answer FAQs for a website.\n\n**Resources**: [Building a Chatbot with Python](https://www.youtube.com/watch?v=a37BL0stIuM)\n\n# Project Idea: Weather Dashboard\n\n**Difficulty**: Beginner\n\n**Tech Stack**: HTML, CSS, JavaScript, API\n\n**Description**: Build a dashboard that displays real-time weather information using a weather API.\n\n**Resources**: [Weather API Tutorial](https://www.youtube.com/watch?v=9P5MY_2i7K8)\n\n## Project Idea: File Organizer\n\n**Difficulty**: Beginner\n\n**Tech Stack**: Python, File I/O\n\n**Description**: Create a script that organizes files in a directory into sub-folders based on file type.\n\n**Resources**: [Automate the Boring Stuff: Organizing Files](https://automatetheboringstuff.com/2e/chapter9/)\n\nLet's help each other grow. Happy coding! \ud83c\udf1f",
    "created_utc": 1746403228.0,
    "url": "https://www.reddit.com/r/Python/comments/1key6k7/monday_daily_thread_project_ideas/",
    "score": 2,
    "num_comments": 1
  },
  {
    "subreddit": "Python",
    "title": "\ud83d\ude80 Introducing TkRouter \u2014 Declarative Routing for Tkinter",
    "text": "Hey folks!\n\nI just released **TkRouter**, a lightweight library that brings *declarative routing* to your multi-page **Tkinter** apps \u2014 with support for:\n\n\u2728 Features:\n- `/users/<id>` style dynamic routing  \n- Query string parsing: `/logs?level=error`  \n- Animated transitions (`slide`, `fade`) between pages  \n- Route guards and redirect fallback logic  \n- Back/forward history stack  \n- Built-in navigation widgets: `RouteLinkButton`, `RouteLinkLabel`\n\nHere\u2019s a minimal example:\n\n```python\nfrom tkinter import Tk\nfrom tkrouter import create_router, get_router, RouterOutlet\nfrom tkrouter.views import RoutedView\nfrom tkrouter.widgets import RouteLinkButton\n\nclass Home(RoutedView):\n    def __init__(self, master):\n        super().__init__(master)\n        RouteLinkButton(self, \"/about\", text=\"Go to About\").pack()\n\nclass About(RoutedView):\n    def __init__(self, master):\n        super().__init__(master)\n        RouteLinkButton(self, \"/\", text=\"Back to Home\").pack()\n\nROUTES = {\n    \"/\": Home,\n    \"/about\": About,\n}\n\nroot = Tk()\noutlet = RouterOutlet(root)\noutlet.pack(fill=\"both\", expand=True)\ncreate_router(ROUTES, outlet).navigate(\"/\")\nroot.mainloop()\n```\n\n\ud83d\udce6 **Install via pip**\n```\npip install tkrouter\n```\n\n\ud83d\udcd8 **Docs**  \nhttps://tkrouter.readthedocs.io\n\n\ud83d\udcbb **GitHub**  \nhttps://github.com/israel-dryer/tkrouter\n\n\ud83c\udfc1 Includes built-in demo commands like:\n```bash\ntkrouter-demo-admin     # sidebar layout with query params\ntkrouter-demo-unified   # /dashboard/stats with transitions\ntkrouter-demo-guarded   # simulate login and access guard\n```\n\nWould love feedback from fellow devs. Happy to answer questions or take suggestions!",
    "created_utc": 1746397480.0,
    "url": "https://www.reddit.com/r/Python/comments/1kew6fz/introducing_tkrouter_declarative_routing_for/",
    "score": 71,
    "num_comments": 7
  },
  {
    "subreddit": "Python",
    "title": "Manim Layout Manager Ideas",
    "text": "I\u2019ve noticed that many people and apps nowadays are using LLMs to dynamically generate Manim code for creating videos. However, these auto-generated videos often suffer from layout issues\u2014such as overlapping objects, elements going off-screen, or poor spacing. I\u2019m interested in developing a layout manager that can dynamically manage positioning, animation handling and spacing animations to address these problems. Could anyone suggest algorithms or resources that might help with this?\n\nMy current approach is writing bounds check to keep mobjects within the screen and set opacity to zero to make objects that don\u2019t take part in the animation invisible while performing animations. Then repeat.",
    "created_utc": 1746372928.0,
    "url": "https://www.reddit.com/r/Python/comments/1kemn5p/manim_layout_manager_ideas/",
    "score": 4,
    "num_comments": 2
  },
  {
    "subreddit": "Python",
    "title": "AsyncMQ \u2013 Async-native task queue for Python with Redis, retries, TTL, job events, and CLI support",
    "text": "**What the project does**:\n\nAsyncMQ is a modern, async-native task queue for Python. It was built from the ground up to fully support asyncio and comes with:\n\n* Redis and NATS backends\n* Retry strategies, TTLs, and dead-letter queues\n* Pub/sub job events\n* Optional PostgreSQL/MongoDB-based job store\n* Metadata, filtering, querying\n* A CLI for job management\n* A lot more...\n\nIntegration-ready with any async Python stack\n\n\nOfficial docs: https://asyncmq.dymmond.com\n\nGitHub: https://github.com/dymmond/asyncmq\n\n**Target Audience**:\n\nAsyncMQ is meant for developers building production-grade async services in Python, especially those frustrated with legacy tools like Celery or RQ when working with async code. It\u2019s also suitable for hobbyists and framework authors who want a fast, native queue system without heavy dependencies.\n\n**Comparison**:\n\n* Unlike Celery, AsyncMQ is async-native and doesn\u2019t require blocking workers or complex setup.\n\n* Compared to RQ, it supports pub/sub, TTL, retries, and job metadata natively.\n\n* Inspired by BullMQ (Node.js), it offers similar patterns like job events, queues, and job stores.\n\n* Works seamlessly with modern tools like asyncz for scheduling.\n\n* Works seamlessly with modern ASGI frameworks like Esmerald, FastAPI, Sanic, Quartz....\n\nIn the upcoming version, the Dashboard UI will be coming too as it's a nice to have for those who enjoy a nice look and feel on top of these tools.\n\nWould love feedback, questions, or ideas! I'm actively developing it and open to contributors as well. \n\nEDIT: I posted the wrong URL (still in analysis) for the official docs. Now it's ok.",
    "created_utc": 1746350627.0,
    "url": "https://www.reddit.com/r/Python/comments/1kefrsj/asyncmq_asyncnative_task_queue_for_python_with/",
    "score": 36,
    "num_comments": 44
  },
  {
    "subreddit": "Python",
    "title": "Sunday Daily Thread: What's everyone working on this week?",
    "text": "# Weekly Thread: What's Everyone Working On This Week? \ud83d\udee0\ufe0f\n\nHello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to!\n\n## How it Works:\n\n1. **Show & Tell**: Share your current projects, completed works, or future ideas.\n2. **Discuss**: Get feedback, find collaborators, or just chat about your project.\n3. **Inspire**: Your project might inspire someone else, just as you might get inspired here.\n\n## Guidelines:\n\n* Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome.\n* Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here.\n\n## Example Shares:\n\n1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!\n2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better.\n3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!\n\nLet's build and grow together! Share your journey and learn from others. Happy coding! \ud83c\udf1f",
    "created_utc": 1746316831.0,
    "url": "https://www.reddit.com/r/Python/comments/1ke6s0y/sunday_daily_thread_whats_everyone_working_on/",
    "score": 5,
    "num_comments": 1
  },
  {
    "subreddit": "Python",
    "title": "Adding Reactivity to Jupyter Notebooks with reaktiv",
    "text": "Have you ever been frustrated when using Jupyter notebooks because you had to manually re-run cells after changing a variable? Or wished your data visualizations would automatically update when parameters change?\n\nWhile specialized platforms like [Marimo](https://marimo.io/) offer reactive notebooks, you don't need to leave the Jupyter ecosystem to get these benefits. With the `reaktiv` library, you can add reactive computing to your existing Jupyter notebooks and VSCode notebooks!\n\nIn this article, I'll show you how to leverage `reaktiv` to create reactive computing experiences without switching platforms, making your data exploration more fluid and interactive while retaining access to all the tools and extensions you know and love.\n\n# Full Example Notebook\n\nYou can find the complete example notebook in the reaktiv repository:\n\n[reactive\\_jupyter\\_notebook.ipynb](https://github.com/buiapp/reaktiv/blob/main/examples/reactive_jupyter_notebook.ipynb)\n\nThis example shows how to build fully reactive data exploration interfaces that work in both Jupyter and VSCode environments.\n\n# What is reaktiv?\n\n[Reaktiv](https://github.com/buiapp/reaktiv) is a Python library that enables reactive programming through automatic dependency tracking. It provides three core primitives:\n\n1. **Signals**: Store values and notify dependents when they change\n2. **Computed Signals**: Derive values that automatically update when dependencies change\n3. **Effects**: Run side effects when signals or computed signals change\n\nThis reactive model, inspired by modern web frameworks like Angular, is perfect for enhancing your existing notebooks with reactivity!\n\n# Benefits of Adding Reactivity to Jupyter\n\nBy using `reaktiv` with your existing Jupyter setup, you get:\n\n* **Reactive updates** without leaving the familiar Jupyter environment\n* **Access to the entire Jupyter ecosystem** of extensions and tools\n* **VSCode notebook compatibility** for those who prefer that editor\n* **No platform lock-in** \\- your notebooks remain standard .ipynb files\n* **Incremental adoption** \\- add reactivity only where needed\n\n# Getting Started\n\nFirst, let's install the library:\n\n    pip install reaktiv\n    # or with uv\n    uv pip install reaktiv\n\nNow let's create our first reactive notebook:\n\n# Example 1: Basic Reactive Parameters\n\n    from reaktiv import Signal, Computed, Effect\n    import matplotlib.pyplot as plt\n    from IPython.display import display\n    import numpy as np\n    import ipywidgets as widgets\n    \n    # Create reactive parameters\n    x_min = Signal(-10)\n    x_max = Signal(10)\n    num_points = Signal(100)\n    function_type = Signal(\"sin\")  # \"sin\" or \"cos\"\n    amplitude = Signal(1.0)\n    \n    # Create a computed signal for the data\n    def compute_data():\n        x = np.linspace(x_min(), x_max(), num_points())\n        \n        if function_type() == \"sin\":\n            y = amplitude() * np.sin(x)\n        else:\n            y = amplitude() * np.cos(x)\n        \n        return x, y\n    \n    plot_data = Computed(compute_data)\n    \n    # Create an output widget for the plot\n    plot_output = widgets.Output(layout={'height': '400px', 'border': '1px solid #ddd'})\n    \n    # Create a reactive plotting function\n    def plot_reactive_chart():\n        # Clear only the output widget content, not the whole cell\n        plot_output.clear_output(wait=True)\n        \n        # Use the output widget context manager to restrict display to the widget\n        with plot_output:\n            x, y = plot_data()\n            \n            fig, ax = plt.subplots(figsize=(10, 6))\n            ax.plot(x, y)\n            ax.set_title(f\"{function_type().capitalize()} Function with Amplitude {amplitude()}\")\n            ax.set_xlabel(\"x\")\n            ax.set_ylabel(\"y\")\n            ax.grid(True)\n            ax.set_ylim(-1.5 * amplitude(), 1.5 * amplitude())\n            plt.show()\n            \n            print(f\"Function: {function_type()}\")\n            print(f\"Range: [{x_min()}, {x_max()}]\")\n            print(f\"Number of points: {num_points()}\")\n    \n    # Display the output widget\n    display(plot_output)\n    \n    # Create an effect that will automatically re-run when dependencies change\n    chart_effect = Effect(plot_reactive_chart)\n\nNow we have a reactive chart! Let's modify some parameters and see it update automatically:\n\n    # Change the function type - chart updates automatically!\n    function_type.set(\"cos\")\n    \n    # Change the x range - chart updates automatically!\n    x_min.set(-5)\n    x_max.set(5)\n    \n    # Change the resolution - chart updates automatically!\n    num_points.set(200)\n\n# Example 2: Interactive Controls with ipywidgets\n\nLet's create a more interactive example by adding control widgets that connect to our reactive signals:\n\n    from reaktiv import Signal, Computed, Effect\n    import matplotlib.pyplot as plt\n    import ipywidgets as widgets\n    from IPython.display import display\n    import numpy as np\n    \n    # We can reuse the signals and computed data from Example 1\n    # Create an output widget specifically for this example\n    chart_output = widgets.Output(layout={'height': '400px', 'border': '1px solid #ddd'})\n    \n    # Create widgets\n    function_dropdown = widgets.Dropdown(\n        options=[('Sine', 'sin'), ('Cosine', 'cos')],\n        value=function_type(),\n        description='Function:'\n    )\n    \n    amplitude_slider = widgets.FloatSlider(\n        value=amplitude(),\n        min=0.1,\n        max=5.0,\n        step=0.1,\n        description='Amplitude:'\n    )\n    \n    range_slider = widgets.FloatRangeSlider(\n        value=[x_min(), x_max()],\n        min=-20.0,\n        max=20.0,\n        step=1.0,\n        description='X Range:'\n    )\n    \n    points_slider = widgets.IntSlider(\n        value=num_points(),\n        min=10,\n        max=500,\n        step=10,\n        description='Points:'\n    )\n    \n    # Connect widgets to signals\n    function_dropdown.observe(lambda change: function_type.set(change['new']), names='value')\n    amplitude_slider.observe(lambda change: amplitude.set(change['new']), names='value')\n    range_slider.observe(lambda change: (x_min.set(change['new'][0]), x_max.set(change['new'][1])), names='value')\n    points_slider.observe(lambda change: num_points.set(change['new']), names='value')\n    \n    # Create a function to update the visualization\n    def update_chart():\n        chart_output.clear_output(wait=True)\n        \n        with chart_output:\n            x, y = plot_data()\n            \n            fig, ax = plt.subplots(figsize=(10, 6))\n            ax.plot(x, y)\n            ax.set_title(f\"{function_type().capitalize()} Function with Amplitude {amplitude()}\")\n            ax.set_xlabel(\"x\")\n            ax.set_ylabel(\"y\")\n            ax.grid(True)\n            plt.show()\n    \n    # Create control panel\n    control_panel = widgets.VBox([\n        widgets.HBox([function_dropdown, amplitude_slider]),\n        widgets.HBox([range_slider, points_slider])\n    ])\n    \n    # Display controls and output widget together\n    display(widgets.VBox([\n        control_panel,    # Controls stay at the top\n        chart_output      # Chart updates below\n    ]))\n    \n    # Then create the reactive effect\n    widget_effect = Effect(update_chart)\n\n# Example 3: Reactive Data Analysis\n\nLet's build a more sophisticated example for exploring a dataset, which works identically in Jupyter Lab, Jupyter Notebook, or VSCode:\n\n    from reaktiv import Signal, Computed, Effect\n    import pandas as pd\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    from ipywidgets import Output, Dropdown, VBox, HBox\n    from IPython.display import display\n    \n    # Load the Iris dataset\n    iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n    \n    # Create reactive parameters\n    x_feature = Signal(\"sepal_length\")\n    y_feature = Signal(\"sepal_width\")\n    species_filter = Signal(\"all\")  # \"all\", \"setosa\", \"versicolor\", or \"virginica\"\n    plot_type = Signal(\"scatter\")   # \"scatter\", \"boxplot\", or \"histogram\"\n    \n    # Create an output widget to contain our visualization\n    # Setting explicit height and border ensures visibility in both Jupyter and VSCode\n    viz_output = Output(layout={'height': '500px', 'border': '1px solid #ddd'})\n    \n    # Computed value for the filtered dataset\n    def get_filtered_data():\n        if species_filter() == \"all\":\n            return iris\n        else:\n            return iris[iris.species == species_filter()]\n    \n    filtered_data = Computed(get_filtered_data)\n    \n    # Reactive visualization\n    def plot_data_viz():\n        # Clear only the output widget content, not the whole cell\n        viz_output.clear_output(wait=True)\n        \n        # Use the output widget context manager to restrict display to the widget\n        with viz_output:\n            data = filtered_data()\n            x = x_feature()\n            y = y_feature()\n            \n            fig, ax = plt.subplots(figsize=(10, 6))\n            \n            if plot_type() == \"scatter\":\n                sns.scatterplot(data=data, x=x, y=y, hue=\"species\", ax=ax)\n                plt.title(f\"Scatter Plot: {x} vs {y}\")\n            elif plot_type() == \"boxplot\":\n                sns.boxplot(data=data, y=x, x=\"species\", ax=ax)\n                plt.title(f\"Box Plot of {x} by Species\")\n            else:  # histogram\n                sns.histplot(data=data, x=x, hue=\"species\", kde=True, ax=ax)\n                plt.title(f\"Histogram of {x}\")\n            \n            plt.tight_layout()\n            plt.show()\n            \n            # Display summary statistics\n            print(f\"Summary Statistics for {x_feature()}:\")\n            print(data[x].describe())\n    \n    # Create interactive widgets\n    feature_options = list(iris.select_dtypes(include='number').columns)\n    species_options = [\"all\"] + list(iris.species.unique())\n    plot_options = [\"scatter\", \"boxplot\", \"histogram\"]\n    \n    x_dropdown = Dropdown(options=feature_options, value=x_feature(), description='X Feature:')\n    y_dropdown = Dropdown(options=feature_options, value=y_feature(), description='Y Feature:')\n    species_dropdown = Dropdown(options=species_options, value=species_filter(), description='Species:')\n    plot_dropdown = Dropdown(options=plot_options, value=plot_type(), description='Plot Type:')\n    \n    # Link widgets to signals\n    x_dropdown.observe(lambda change: x_feature.set(change['new']), names='value')\n    y_dropdown.observe(lambda change: y_feature.set(change['new']), names='value')\n    species_dropdown.observe(lambda change: species_filter.set(change['new']), names='value')\n    plot_dropdown.observe(lambda change: plot_type.set(change['new']), names='value')\n    \n    # Create control panel\n    controls = VBox([\n        HBox([x_dropdown, y_dropdown]),\n        HBox([species_dropdown, plot_dropdown])\n    ])\n    \n    # Display widgets and visualization together\n    display(VBox([\n        controls,    # Controls stay at top\n        viz_output   # Visualization updates below\n    ]))\n    \n    # Create effect for automatic visualization\n    viz_effect = Effect(plot_data_viz)\n\n# How It Works\n\nThe magic of `reaktiv` is in how it automatically tracks dependencies between signals, computed values, and effects. When you call a signal inside a computed function or effect, `reaktiv` records this dependency. Later, when a signal's value changes, it notifies only the dependent computed values and effects.\n\nThis creates a reactive computation graph that efficiently updates only what needs to be updated, similar to how modern frontend frameworks handle UI updates.\n\nHere's what happens when you change a parameter in our examples:\n\n1. You call `x_min.set(-5)` to update a signal\n2. The signal notifies all its dependents (computed values and effects)\n3. Dependent computed values recalculate their values\n4. Effects run, updating visualizations or outputs\n5. The notebook shows updated results without manually re-running cells\n\n# Best Practices for Reactive Notebooks\n\nTo ensure your reactive notebooks work correctly in both Jupyter and VSCode environments:\n\n1. **Use Output widgets for visualizations**: Always place plots and their related outputs within dedicated Output widgets\n2. **Set explicit dimensions for output widgets**: Add height and border to ensure visibility:output = widgets.Output(layout={'height': '400px', 'border': '1px solid #ddd'})\n3. **Keep references to Effects**: Always assign Effects to variables to prevent garbage collection.\n4. **Use context managers with Output widgets**\n\n# Benefits of This Approach\n\nUsing `reaktiv` in standard Jupyter notebooks offers several advantages:\n\n1. **Keep your existing workflows** \\- no need to learn a new notebook platform\n2. **Use all Jupyter extensions** you've come to rely on\n3. **Work in your preferred environment** \\- Jupyter Lab, classic Notebook, or VSCode\n4. **Share notebooks normally** \\- they're still standard .ipynb files\n5. **Gradual adoption** \\- add reactivity only to the parts that need it\n\n# Troubleshooting\n\nIf your visualizations don't appear correctly:\n\n1. **Check widget height**: If plots aren't visible, try increasing the height in the Output widget creation\n2. **Widget context manager**: Ensure all plot rendering happens inside the `with output_widget:` context\n3. **Variable retention**: Keep references to all widgets and Effects to prevent garbage collection\n\n# Conclusion\n\nWith `reaktiv`, you can bring the benefits of reactive programming to your existing Jupyter notebooks without switching platforms. This approach gives you the best of both worlds: the familiar Jupyter environment you know, with the reactive updates that make data exploration more fluid and efficient.\n\nNext time you find yourself repeatedly running notebook cells after parameter changes, consider adding a bit of reactivity with `reaktiv` and see how it transforms your workflow!\n\n# Resources\n\n* [reaktiv GitHub repository](https://github.com/buiapp/reaktiv)\n* [reaktiv Documentation](https://reaktiv.readthedocs.io/)\n* [Jupyter Notebooks](https://jupyter.org/)\n* [ipywidgets Documentation](https://ipywidgets.readthedocs.io/)\n* [VSCode Jupyter Extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter)",
    "created_utc": 1746312105.0,
    "url": "https://www.reddit.com/r/Python/comments/1ke56y7/adding_reactivity_to_jupyter_notebooks_with/",
    "score": 7,
    "num_comments": 4
  },
  {
    "subreddit": "Python",
    "title": "Arkalos Beta 5 - Dashboards, JSONL Logs, Crawling, Deployment, Fullstack FastAPI+React framework",
    "text": "# Comparison\n\nThere is no full-fledged and beginner and DX-friendly Python framework for modern data apps.\n\nPeople have to manually set up projects, venv, env, many dependencies and search for basic utils.\n\nToo much abstraction, bad design, docs, lack of batteries and control.\n\n# What My Project Does\n\nRe-Introducing Arkalos - an easy-to-use modern Python framework for data analysis, building data apps, warehouses, dashboards, AI agents, robots, ML, training LLMs with elegant syntax. It just works.\n\n# Modern Frontend UI and Interactive Dashboard\n\nArkalos is a pre-configured fullstack FastAPI and React based framework. Ready to analyze data or write business applications.\n\nSimply return Altair and Polars DataFrame charts, like you do in a Jupyter Notebook, from the Python FastAPI endpoint.\n\nAnd frontend React will render a responsive and interactive chart automatically:\n\n**Check the images and visual examples at the top of the** [**https://arkalos.com**](https://arkalos.com)\n\n# Beta 5 Updates:\n\n* CRITICAL: Add .env to gitignore.\n* New deployment guide and ready-to-use configs:\n   * ecosystem.config.js - configuration for PM2 - advanced production process manager to keep Arkalos app running on the server.\n   * .devops/nginx/sites-enabled/example.com.conf - Nginx site configuration for the new site and domain with redirects and SSL. Replace example com with your own domain.\n   * .github/workflows/deploy.yml - a GitHub action to automatically deploy on git push Arkalos and Python projects to the VPS, such as DigitalOcean.\n* New FRONTEND directory:\n   * with Vite, React and RR7 and pre-configured starter UI project with some custom components and CSS\n   * with Altair charts automatically rendered in React, fully responsive\n   * and a Dashboard, Chat and Logs page examples.\n   * Web routes removed from the HTTP Server. Use Python only for backend API routes. And React for web UI.\n* Backend API Route files are automatically discovered. Just add a new file in the app/http/routes directory.\n* REVAMPED Logger:\n   * Use JSONL (JSON Line) file logging format.\n   * Take full control over uvicorn, FastAPI and other logs. No logs are logged twice or lost.\n   * New ACCESS log level (15).\n   * A helper function to read log files.\n   * Beautiful and short exception logging.\n   * Read log files visually from the UI on the Logs page.\n* NEW FILE UTIL class: FileReader:\n   * efficiently read files line by line,\n   * including backwards,\n   * with built-in support for pagination.\n   * Optimized for large files using chunk-based reading.\n* New WebExtractor unstructured data extractor (crawler)\n* New component - WebBrowser automation\n* Update the URL class to closer match the WHATWG standard\n* And more\n\nChangelog since the last update on Reddit:\n\n[https://github.com/arkaloscom/arkalos/releases/tag/0.5.1](https://github.com/arkaloscom/arkalos/releases/tag/0.5.1)\n\n[https://github.com/arkaloscom/arkalos/releases/tag/0.4.0](https://github.com/arkaloscom/arkalos/releases/tag/0.4.0)\n\n# Target Audience\n\nAnyone from beginners to data analysts, engineers and scientists.\n\n# Documentation and GitHub:\n\n[https://arkalos.com](https://arkalos.com)\n\n[https://github.com/arkaloscom/arkalos/](https://github.com/arkaloscom/arkalos/)",
    "created_utc": 1746290220.0,
    "url": "https://www.reddit.com/r/Python/comments/1kdx45g/arkalos_beta_5_dashboards_jsonl_logs_crawling/",
    "score": 7,
    "num_comments": 2
  },
  {
    "subreddit": "Python",
    "title": "After #ruff and #uv, #astral announced their next tool for the python ecosystem",
    "text": "\nA new type checker for python (like e.g. mypy or pyright) called Ty\n\n- Ty: A new Python type checker (previously codenamed \"Rednot\")\n- The team has been working on it for almost a year\n- The name follows Astral's pattern of short, easy-to-type commands (like \"ty check\")\n\nSource: https://www.youtube.com/watch?v=XVwpL_cAvrw\n\nIn your own opinion, after this, what tool do you think they should work on next in the python ecosystem?\n\nEdit:  Development is in the ruff repo under the red-knot label.\n\nhttps://github.com/astral-sh/ruff/issues?q=%20label%3Ared-knot%20\n\nThere's also an online playground.\n- https://types.ruff.rs/",
    "created_utc": 1746283218.0,
    "url": "https://www.reddit.com/r/Python/comments/1kdui8w/after_ruff_and_uv_astral_announced_their_next/",
    "score": 567,
    "num_comments": 114
  },
  {
    "subreddit": "Python",
    "title": "I built a PySpark data validation framework to replace PyDeequ \u2014 feedback welcome",
    "text": "Hey everyone,  \nI\u2019d like to share a project I\u2019ve been working on: [**SparkDQ**](https://github.com/sparkdq-community/sparkdq) \u2014 an open-source framework for validating data in PySpark.\n\n**What it does:**  \nSparkDQ helps you validate your data \u2014 both at the row level and aggregate level \u2014 directly inside your Spark pipelines.  \nIt supports Python-native and declarative configs (e.g. YAML, JSON, or external sources like DynamoDB), with built-in support for fail-fast and quarantine-based validation strategies.\n\n**Target audience:**  \nThis is built for data engineers and analysts working with Spark in production. Whether you're building ETL pipelines or preparing data for ML, SparkDQ is designed to give you full control over your data quality logic \u2014 without relying on heavy wrappers.\n\n**Comparison:**\n\n* Fully written in Python\n* Row-level visibility with structured error metadata\n* Plugin architecture for custom checks\n* Zero heavy dependencies (just PySpark + Pydantic)\n* Clean separation of valid and invalid data \u2014 with built-in handling for quarantining bad records\n\nIf you\u2019ve used PyDeequ or struggled with validating Spark data in a Pythonic way, I\u2019d love your feedback \u2014 on naming, structure, design, anything.\n\n* \u2b50 [GitHub Repo \u2013 SparkDQ](https://github.com/sparkdq-community/sparkdq)\n* \u270d\ufe0f [Medium article \u2013 Why I moved beyond PyDeequ](https://medium.com/aws-tip/goodbye-pydeequ-time-to-upgrade-your-data-quality-stack-d86fe9cdc5be)\n\nThanks for reading!",
    "created_utc": 1746234030.0,
    "url": "https://www.reddit.com/r/Python/comments/1kdgumc/i_built_a_pyspark_data_validation_framework_to/",
    "score": 8,
    "num_comments": 3
  },
  {
    "subreddit": "Python",
    "title": "Saturday Daily Thread: Resource Request and Sharing! Daily Thread",
    "text": "# Weekly Thread: Resource Request and Sharing \ud83d\udcda\n\nStumbled upon a useful Python resource? Or are you looking for a guide on a specific topic? Welcome to the Resource Request and Sharing thread!\n\n## How it Works:\n\n1. **Request**: Can't find a resource on a particular topic? Ask here!\n2. **Share**: Found something useful? Share it with the community.\n3. **Review**: Give or get opinions on Python resources you've used.\n\n## Guidelines:\n\n* Please include the type of resource (e.g., book, video, article) and the topic.\n* Always be respectful when reviewing someone else's shared resource.\n\n## Example Shares:\n\n1. **Book**: [\"Fluent Python\"](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) \\- Great for understanding Pythonic idioms.\n2. **Video**: [Python Data Structures](https://www.youtube.com/watch?v=pkYVOmU3MgA) \\- Excellent overview of Python's built-in data structures.\n3. **Article**: [Understanding Python Decorators](https://realpython.com/primer-on-python-decorators/) \\- A deep dive into decorators.\n\n## Example Requests:\n\n1. **Looking for**: Video tutorials on web scraping with Python.\n2. **Need**: Book recommendations for Python machine learning.\n\nShare the knowledge, enrich the community. Happy learning! \ud83c\udf1f",
    "created_utc": 1746230431.0,
    "url": "https://www.reddit.com/r/Python/comments/1kdfo8x/saturday_daily_thread_resource_request_and/",
    "score": 2,
    "num_comments": 0
  },
  {
    "subreddit": "Python",
    "title": "PgQueuer \u2013 PostgreSQL-native job & schedule queue, gathering ideas for 1.0 \ud83c\udfaf",
    "text": "### What My Project Does\nPgQueuer converts any PostgreSQL database into a durable background-job and cron scheduler. It relies on **LISTEN/NOTIFY** for real-time worker wake-ups and `FOR UPDATE SKIP LOCKED` for high-concurrency locking, so you don\u2019t need Redis, RabbitMQ, Celery, or any extra broker.  \nEverything\u2014jobs, schedules, retries, statistics\u2014lives as rows you can query.\n\n**Highlights since my last post**\n\n* Cron-style recurring jobs (`* * * * *`) with automatic `next_run`\n* Heartbeat API to re-queue tasks that die mid-run\n* Async **and** sync drivers (asyncpg & psycopg v3) plus a one-command CLI for install / upgrade / live dashboard\n* Pluggable executors with back-off helpers\n* Zero-downtime schema migrations (`pgqueuer upgrade`)\n\nSource & docs \u2192 **https://github.com/janbjorge/pgqueuer**\n\n---\n\n### Target Audience\n* Teams already running PostgreSQL who want *one fewer* moving part in production  \n* Python devs who love `async/await` but need sync compatibility  \n* Apps on Heroku/Fly.io/Railway or serverless platforms where running Redis isn\u2019t practical\n\n---\n\n### How PgQueuer Stands Out\n* **Single-service architecture** \u2013 everything runs inside the DB you already use  \n* **SQL-backed durability** \u2013 jobs are ACID rows you can inspect and JOIN  \n* **Extensible** \u2013 swap in your own executor, customise retries, stream metrics from the stats table\n\n---\n\n### I\u2019d Love Your Feedback \ud83d\ude4f\nI\u2019m drafting the 1.0 roadmap and would love to know which of these (or something else!) would make *you* adopt a Postgres-only queue:\n\n* Dead-letter queues / automatically park repeatedly failing jobs  \n* Edit-in-flight: change priority or delay of queued jobs  \n* Web dashboard (FastAPI/React) for ops  \n* Auto-managed migrations  \n* Helm chart / Docker images for quick deployments  \n\nHave another idea or pain-point? Drop a comment here or open an issue/PR on GitHub.\n",
    "created_utc": 1746206005.0,
    "url": "https://www.reddit.com/r/Python/comments/1kd6ci0/pgqueuer_postgresqlnative_job_schedule_queue/",
    "score": 28,
    "num_comments": 10
  },
  {
    "subreddit": "Python",
    "title": "I just published an update for my articles on Python packaging (PEP 751) and some remaining issues",
    "text": "Hi everyone!\n\nMy last two articles on Python packaging received a lot of, interactions. So when PEP 751 was accepted I thought of updating my articles, but it felt, dishonest. I mean, one could just read the PEP and get the gist of it. Like, it doesn't require a whole article for it. But then at work I had to help a lot across projects on the packaging part and through the questions I got asked here and there, I could see a structure for a somewhat interesting article.\n\nSo the structure goes like this, why not just use the good old requirements.txt (yes we still do, or, did, that here and there at work), what were the issues with it, how some can be solved, how the lock file solves some of them, why the current \\`pylock.toml\\` is not perfect yet, the differences with \\`uv.lock\\`. \n\nAnd since CUDA is the bane of my existence, I decided to also include a section talking about different issues with the current Python packaging state. This was the hardest part I think. Because it has to be simple enough to onboard everyone and not too simple that it's simply wrong from an expert's point of view. I only tackled the native dependencies and the accelerator-aware packages parts since they share some similarities and since I'm only familiar with that. I'm pretty sure there are many other issues to talk about and I'd love to hear about that from you. If I can include them in my article, I'd be very happy!\n\nHere is the link: [https://reinforcedknowledge.com/python-project-management-and-packaging-pep-751-update-and-some-of-the-remaining-issues-of-packaging/](https://reinforcedknowledge.com/python-project-management-and-packaging-pep-751-update-and-some-of-the-remaining-issues-of-packaging/)\n\nI'm sorry again for those who can't follow on long article. I'm the same but somehow when it comes to writing I can't write different smaller articles. I'm even having trouble structuring one article, let alone structure a whole topic into different articles. Also sorry for the grammar or syntax errors. I'll have to use a better writing ecosystem to catch those easily \\^\\^'\n\nThank you to anyone who reads the blog post. If you have any review or criticism or anything you think I got wrong or didn't explain well, I'd be very glad to hear about it. Thank you!",
    "created_utc": 1746168779.0,
    "url": "https://www.reddit.com/r/Python/comments/1kcumjf/i_just_published_an_update_for_my_articles_on/",
    "score": 38,
    "num_comments": 5
  },
  {
    "subreddit": "Python",
    "title": "Pytocpp: A toy transpiler from a subset of Python to C++",
    "text": "Ever since i have started working with python, there has been one thing that has been bugging me: Pythons performance. Of course, Python is an interpreted language and dynamically typed, so the slow performance is the result of those features, but I have always been wondering if simply embedding a minimal python runtime environment, adapted to the given program into an executable with the program itself would be feasible. Well\u2026 I think it is.\n\n#What my project does\n\nWhat the pytocpp Python to C++ Transpiler does is accept a program in a (still relatively simple) subset of python and generate a fully functional standalone c++ program. This program can be compiled and ran and behaves just like if it was ran with Python, but about 2 times faster.\n\n#Target audience\n\nAs described in the title, this project is still just a toy project. There are certainly still some bugs present and the supported subset is simply too small for writing meaningful programs. In the future, I might extend this project to support more features of the Python language.\n\n#Comparison\n\nAs far as my knowledge goes, there are currently no tools which are able to generate c/c++ code from native python code. Tools like Cython etc. all require type annotations and work in a statically typed way.\n\nThe pytocpp github project is linked [here](https://www.github.com/b3d3vtvng/pytocpp)\n\nI am happy about any feedback or ideas for improvement. Sadly, I cannot yet accept contributions to this project as I am currently writing a thesis about it and my school would interpret any foreign code as plagiarism. This will change in exactly four days when I will have submitted my thesis :).",
    "created_utc": 1746112980.0,
    "url": "https://www.reddit.com/r/Python/comments/1kcbepg/pytocpp_a_toy_transpiler_from_a_subset_of_python/",
    "score": 7,
    "num_comments": 14
  },
  {
    "subreddit": "Python",
    "title": "PEP 790 \u2013 Python 3.15 Release Schedule",
    "text": "[https://peps.python.org/pep-0790/](https://peps.python.org/pep-0790/)\n\nExpected:\n\n* 3.15 development begins: Tuesday, 2025-05-06\n* 3.15.0 alpha 1: Tuesday, 2025-10-14\n* 3.15.0 alpha 2: Tuesday, 2025-11-18\n* 3.15.0 alpha 3: Tuesday, 2025-12-16\n* 3.15.0 alpha 4: Tuesday, 2026-01-13\n* 3.15.0 alpha 5: Tuesday, 2026-02-10\n* 3.15.0 alpha 6: Tuesday, 2026-03-10\n* 3.15.0 alpha 7: Tuesday, 2026-04-07\n* 3.15.0 beta 1: Tuesday, 2026-05-05 (No new features beyond this point.)\n* 3.15.0 beta 2: Tuesday, 2026-05-26\n* 3.15.0 beta 3: Tuesday, 2026-06-16\n* 3.15.0 beta 4: Tuesday, 2026-07-14\n* 3.15.0 candidate 1: Tuesday, 2026-07-28\n* 3.15.0 candidate 2: Tuesday, 2026-09-01\n* 3.15.0 final: Thursday, 2026-10-01\n\n# 3.15 lifespan\n\n* Python 3.15 will receive bugfix updates approximately every second month for two years.\n* Around the time of the release of 3.18.0 final, the final 3.15 bugfix update will be released.\n* After that, it is expected that security updates (source only) will be released for the next three years, until five years after the release of 3.15.0 final, so until approximately October 2031.",
    "created_utc": 1746058955.0,
    "url": "https://www.reddit.com/r/Python/comments/1kbvpr4/pep_790_python_315_release_schedule/",
    "score": 58,
    "num_comments": 18
  },
  {
    "subreddit": "Python",
    "title": "Thursday Daily Thread: Python Careers, Courses, and Furthering Education!",
    "text": "# Weekly Thread: Professional Use, Jobs, and Education \ud83c\udfe2\n\nWelcome to this week's discussion on Python in the professional world! This is your spot to talk about job hunting, career growth, and educational resources in Python. Please note, this thread is **not for recruitment**.\n\n---\n\n## How it Works:\n\n1. **Career Talk**: Discuss using Python in your job, or the job market for Python roles.\n2. **Education Q&A**: Ask or answer questions about Python courses, certifications, and educational resources.\n3. **Workplace Chat**: Share your experiences, challenges, or success stories about using Python professionally.\n\n---\n\n## Guidelines:\n\n- This thread is **not for recruitment**. For job postings, please see r/PythonJobs or the recruitment thread in the sidebar.\n- Keep discussions relevant to Python in the professional and educational context.\n  \n---\n\n## Example Topics:\n\n1. **Career Paths**: What kinds of roles are out there for Python developers?\n2. **Certifications**: Are Python certifications worth it?\n3. **Course Recommendations**: Any good advanced Python courses to recommend?\n4. **Workplace Tools**: What Python libraries are indispensable in your professional work?\n5. **Interview Tips**: What types of Python questions are commonly asked in interviews?\n\n---\n\nLet's help each other grow in our careers and education. Happy discussing! \ud83c\udf1f",
    "created_utc": 1746057633.0,
    "url": "https://www.reddit.com/r/Python/comments/1kbv9e0/thursday_daily_thread_python_careers_courses_and/",
    "score": 5,
    "num_comments": 0
  },
  {
    "subreddit": "Python",
    "title": "I created a logging module for python, feedback/idea are welcome !",
    "text": "Hello guys, I am working on a library for python allowing to create logs that are easily readable, and simple to use. I ended up with that :  \nGithub : [https://github.com/T0ine34/gamuLogger](https://github.com/T0ine34/gamuLogger)  \nPypi : [https://pypi.org/project/gamuLogger/](https://pypi.org/project/gamuLogger/)\n\n**What My Project Does**\n\nIt allow to log anything during the execution of a program written in Python.\n\n**Target Audience**\n\nAnyone who use python, no special skills are required to use it.\n\n**Comparison**\n\n* suitable for projects of all sizes, from a simple script, to a heavy web server.\n* allow to print logs to differents target (files, terminal) at the same time, with different levels (ex: the all logs including trace and debug will be in the file, but will not be visible in the terminal)\n* Do not require to create a instance of the logger, so it doesn't need a global variable\n* Oriented object\n* automatic colored output if writing in a terminal\n* support multi-threading and multi-processsing\n\nPlease go check it, any idea, improvement, fix, or feedback are welcome !",
    "created_utc": 1746050969.0,
    "url": "https://www.reddit.com/r/Python/comments/1kbsvyq/i_created_a_logging_module_for_python/",
    "score": 43,
    "num_comments": 11
  },
  {
    "subreddit": "Python",
    "title": "inline - function & method inliner (by ast)",
    "text": "github: [SamG101-Developer/inline](https://github.com/SamG101-Developer/inline)\n\n# what my project does\n\nthis project is a tiny library that allows functions to be inlined in Python. it works by using an import hook to modify python code before it is run, replacing calls to functions/methods decorated with \\`@inline\\` with the respective function body, including an argument to parameter mapping.\n\nthe readme shows the context in which the inlined functions can be called, and also lists some restrictions of the module.\n\n# target audience\n\nmostly just a toy project, but i have found it useful when profiling and rendering with gprofdot, as it allows me to skip helper functions that have 100s of arrows pointing into the nodes.\n\n# comparison\n\ni created this library because i couldn't find any other python3 libraries that did this. i did find a python2 library [inliner](https://github.com/orf/inliner) and briefly forked it but i was getting weird ast errors and didn't fully understand the transforms so i started from scratch.",
    "created_utc": 1746040382.0,
    "url": "https://www.reddit.com/r/Python/comments/1kboqlu/inline_function_method_inliner_by_ast/",
    "score": 171,
    "num_comments": 11
  },
  {
    "subreddit": "Python",
    "title": "LiveConfig - Live configuration of Python programs",
    "text": "PyPi: [https://pypi.org/project/liveconfig/](https://pypi.org/project/liveconfig/)\n\nGitHub: [https://github.com/Fergus-Gault/LiveConfig](https://github.com/Fergus-Gault/LiveConfig)\n\nPLEASE NOTE: The project is still in beta, so there are likely bugs that could crash your program. Not recommended to test on anything critical.\n\n# What My Project Does\n\nLiveConfig allows you to modify instance attributes and variables in real-time. Attributes and variables are saved to a JSON file, where they can be loaded on startup. You can interact with LiveConfig through either a command line, or a web interface.\n\nFunction triggers can be added to call a function through the interface of choice.\n\n# Target Audience\n\nLiveConfig could be useful for those developing computer vision projects, machine learning, game engines etc...\n\nIt's particularly useful for projects that take ages to load and could require a lot of fine-tuning.\n\n# Comparison\n\nThere is one alternative that I have found, LiveTune. I discovered this after I had begun development on LiveConfig, and while certain features like live variables overlap, I think LiveConfig is different enough to be its own thing.\n\n  \nI was inspired to create this project during a recent university course. I had created a program that used computer vision, and every time I wanted to make a small change for fine-tuning, I had to restart the program, which took ages each time.\n\nFeel free to check out the project and leave any suggestions for improvements or feature ideas in the comments. I'm interested to see if there is actually a use case for this package for other people.\n\nThanks!",
    "created_utc": 1746031210.0,
    "url": "https://www.reddit.com/r/Python/comments/1kbl1n0/liveconfig_live_configuration_of_python_programs/",
    "score": 78,
    "num_comments": 5
  },
  {
    "subreddit": "Python",
    "title": "JobSpy Docker API - A FastAPI-based Job Search API",
    "text": "GitHub: [https://github.com/rainmanjam/jobspy-api](https://github.com/rainmanjam/jobspy-api)  \nDocker Hub: [https://hub.docker.com/r/rainmanjam/jobspy-api](https://hub.docker.com/r/rainmanjam/jobspy-api)\n\n# What This Project Does\n\nI've built a Docker-containerized FastAPI application that provides a RESTful API for the Python JobSpy library. It allows users to search for jobs across multiple platforms, including LinkedIn, Indeed, Glassdoor, Google, ZipRecruiter, Bayt, and Naukri through a single API call.\n\nKey features:\n\n* Comprehensive job search across multiple job boards\n* API key authentication\n* Rate limiting to prevent abuse\n* Response caching for improved performance\n* Proxy support for avoiding IP blocks\n* Customizable search parameters\n* Detailed error handling with suggestions\n\n# Target Audience\n\nThis is meant for developers who want to integrate job search functionality into their applications without dealing with the complexities of scraping job sites directly. It's production-ready but can also be used for personal projects, data analysis, or research.\n\n# Comparison\n\nUnlike most job search libraries that either focus on a single job board or require a complex setup, JobSpy Docker API:\n\n* Provides a consistent API across multiple job boards\n* Handles authentication, rate limiting, and error handling out of the box\n* Is containerized for easy deployment\n* Includes comprehensive documentation and examples\n* Offers standardized responses across different job sites\n\nThe project is written in Python using FastAPI, with Docker for containerization, and includes testing, logging, and configuration management following best practices.",
    "created_utc": 1746028330.0,
    "url": "https://www.reddit.com/r/Python/comments/1kbjvtr/jobspy_docker_api_a_fastapibased_job_search_api/",
    "score": 132,
    "num_comments": 2
  },
  {
    "subreddit": "Python",
    "title": "Wednesday Daily Thread: Beginner questions",
    "text": "# Weekly Thread: Beginner Questions \ud83d\udc0d\n\nWelcome to our Beginner Questions thread! Whether you're new to Python or just looking to clarify some basics, this is the thread for you.\n\n## How it Works:\n\n1. **Ask Anything**: Feel free to ask any Python-related question. There are no bad questions here!\n2. **Community Support**: Get answers and advice from the community.\n3. **Resource Sharing**: Discover tutorials, articles, and beginner-friendly resources.\n\n## Guidelines:\n\n* This thread is specifically for **beginner questions**. For more advanced queries, check out our [Advanced Questions Thread](#advanced-questions-thread-link).\n\n## Recommended Resources:\n\n* If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance.\n\n## Example Questions:\n\n1. **What is the difference between a list and a tuple?**\n2. **How do I read a CSV file in Python?**\n3. **What are Python decorators and how do I use them?**\n4. **How do I install a Python package using pip?**\n5. **What is a virtual environment and why should I use one?**\n\nLet's help each other learn Python! \ud83c\udf1f",
    "created_utc": 1745971228.0,
    "url": "https://www.reddit.com/r/Python/comments/1kb2vim/wednesday_daily_thread_beginner_questions/",
    "score": 3,
    "num_comments": 2
  },
  {
    "subreddit": "Python",
    "title": "Crypto google trends",
    "text": "Hello,\n\nI am trying to obtain data of let\u2019s say 50 crypto coins in google trends data. I have tried to run a python script to obtain this data but get error code 429. I am interested in daily data for preferable as many years as possible (2017). I tried stitching data together and delaying my requests. Does someone have a Python script that downloads google trends for multiple years of multiple searching terms that works in 2025?",
    "created_utc": 1745963837.0,
    "url": "https://www.reddit.com/r/Python/comments/1kb06mo/crypto_google_trends/",
    "score": 42,
    "num_comments": 20
  },
  {
    "subreddit": "Python",
    "title": "What to Do When HTTP Status Codes Don\u2019t Fit Your Business Error",
    "text": "Question:\n\nHow would you choose a status code for an order that could not be processed because the customer's shipping address is outside the delivery zone?\n\n\nIn this blog post, I discussed what are the common solutions for returning business error response when there is no clear status code associated with the error, as well as some industrial standards related to these solutions. At the end, I mentioned how big tech like stripe solves this problem and then give my own solution to this\n\nSee \n\n[blog post](https://www.lihil.cc/blog/what-to-do-when-http-status-codes-dont-fit-your-business-error)\nLink:\nhttps://www.lihil.cc/blog/what-to-do-when-http-status-codes-dont-fit-your-business-error",
    "created_utc": 1745947527.0,
    "url": "https://www.reddit.com/r/Python/comments/1katmkr/what_to_do_when_http_status_codes_dont_fit_your/",
    "score": 0,
    "num_comments": 16
  },
  {
    "subreddit": "Python",
    "title": "Python for Engineers and Scientists",
    "text": "Hi folks,\n\nHarry here, author of the 10-Day Python Bootcamp for Engineers and Scientists (over 8,000 enrolments on Udemy with 4.6/5 average).\n\nI'm just in the process of migrating my course to my own platform. Money on Udemy is absolutely shite unless you're in the hundreds of thousands of enrolments thanks to Udemy's aggressive discounting and price parity (depending on where you are in the world the price changes - I've seen my course being sold for $1 - we can debate the vitues of this separately!!)\n\nAnyway onto my plea - would anybody be up for helping me out with this transition? I am basically looking for people to take the course and leave me a review in exchange.\n\nI've made 100 free vouchers for the course - you need to type the coupon code REDDIT-FREE at the checkout.\n\nIf you do take the course I'd be super super grateful for the review (the request comes through via email a few days after you enrol). And if you have any really scathing feedback (which can be fixed), I'd be grateful for a DM so I can fix it!\n\nThanks in advance to those who decide to help out.\n\nHere's the link to my new course landing page: [https://www.schoolofsimulation.com/course\\_python\\_bootcamp](https://www.schoolofsimulation.com/course_python_bootcamp)",
    "created_utc": 1745944898.0,
    "url": "https://www.reddit.com/r/Python/comments/1kasj6r/python_for_engineers_and_scientists/",
    "score": 0,
    "num_comments": 9
  },
  {
    "subreddit": "Python",
    "title": "Lexy - CLI tool that fetches programming tutorials from \"Learn X in Y Minutes\"",
    "text": "Hello everyone!\n\nI'm excited to share **Lexy** \u2014 my second \"serious\" project, built with Python! \ud83d\ude04\n\nIt\u2019s still in beta, but it already works. You can maybe find some bugs.\n\nYou can find the project here: [https://github.com/antoniorodr/lexy](https://github.com/antoniorodr/lexy)\n\nYou can see a demo in the repository!\n\n# \ud83d\ude80 What does it do?\n\n**Lexy** is a lightweight command-line tool that fetches programming tutorials from [\u201cLearn X in Y Minutes\u201d](https://github.com/adambard/learnxinyminutes-docs) \u2014 and displays them directly in your terminal. Instantly explore language syntax, idioms, and example-driven tutorials without ever leaving your workflow.\n\n# \ud83d\udc64 Who is it for?\n\nIf you're a developer who works mostly in the terminal, **Lexy** can save you from switching to a browser just to remember how to do a `for` loop in Go or how list comprehensions work in Python. It\u2019s perfect for:\n\n* Terminal-first developers\n* Polyglot programmers\n* Students or self-learners\n* Anyone who loves concise, no-fluff documentation\n\n# \ud83d\udca1 Why Lexy?\n\nI made Lexy because I kept Googling \"language X syntax\" or skimming docs whenever I jumped between languages. I love the [\"Learn X in Y Minutes\"](https://github.com/adambard/learnxinyminutes-docs) project and wanted a faster, terminal-native way to access it.\n\nLexy is:\n\n* Fast\n* Offline-friendly after first fetch\n* Minimal and distraction-free\n* Easy to use and scriptable\n\n# \ud83d\udce6 Installation\n\nRight now, **Lexy** can be installed in two ways:\n\n* From source\n* Via **Homebrew**\n\nSupport for installation via curl (and maybe other ways) is on the roadmap.\n\n# \ud83c\udfc6 Target Audience\n\n**Lexy** is designed for developers who prefer working in the terminal and need quick access to programming tutorials. It is ideal for:\n\n* Terminal-centric developers\n* Language-switchers or polyglots\n* Students or self-learners looking for concise, no-fluff tutorials\n\n# \ud83d\udd0d Comparison\n\nThere are other tools that fetch documentation from various resources, but **Lexy** is unique because:\n\n* It pulls from the \"Learn X in Y Minutes\" collection, which focuses on concise, example-driven tutorials.\n* It\u2019s entirely terminal-based and does not require leaving your workflow to search online.\n* It can be used offline after the first fetch, unlike other tools that require a constant internet connection.\n\nHuge thanks to the maintainers of Learn X in Y Minutes \u2014 your work is fantastic, and this project wouldn\u2019t exist without it. \u2764\ufe0f\n",
    "created_utc": 1745939026.0,
    "url": "https://www.reddit.com/r/Python/comments/1kaq4sm/lexy_cli_tool_that_fetches_programming_tutorials/",
    "score": 0,
    "num_comments": 1
  },
  {
    "subreddit": "Python",
    "title": "guys i made this code pls me check this and tell me whats wrong (if any)",
    "text": "[https://github.com/code50/132076489/tree/main](https://github.com/code50/132076489/tree/main)\n\nimport streamlit as st\n\n\n\n\\# Function to create Lo Shu Grid\n\ndef create\\_loshu\\_grid(dob\\_digits):\n\n\\# Fixed Lo Shu Magic Square layout\n\nloshu\\_grid = \\[\n\n\\[4, 9, 2\\],\n\n\\[3, 5, 7\\],\n\n\\[8, 1, 6\\]\n\n\\]\n\n\n\n\\# Initialize a 3x3 grid with empty strings\n\ngrid = \\[\\[\"\" for \\_ in range(3)\\] for \\_ in range(3)\\]\n\n\n\n\\# Place numbers in the grid based on their frequency in dob\\_digits\n\nfor digit in dob\\_digits:\n\nfor i in range(3):\n\nfor j in range(3):\n\nif loshu\\_grid\\[i\\]\\[j\\] == digit:\n\nif grid\\[i\\]\\[j\\] == \"\":\n\ngrid\\[i\\]\\[j\\] = str(digit)\n\nelse:\n\ngrid\\[i\\]\\[j\\] += f\", {digit}\"  # Append if multiple occurrences\n\n\n\nreturn grid\n\n\n\n\\# Function to calculate Mulank (Root Number)\n\ndef calculate\\_mulank(dob):\n\ndob = dob.replace(\"/\", \"\")  # Remove slashes\n\ndob\\_digits = \\[int(d) for d in dob\\]  # Convert to a list of digits\n\nreturn sum(dob\\_digits) % 9 or 9  # Mulank is the sum of digits reduced to a single digit\n\n\n\n\\# Function to calculate Bhagyank (Destiny Number)\n\ndef calculate\\_bhagyank(dob):\n\ndob = dob.replace(\"/\", \"\")  # Remove slashes\n\ndob\\_digits = \\[int(d) for d in dob\\]  # Convert to a list of digits\n\ntotal = sum(dob\\_digits)\n\nwhile total > 9:  # Reduce to a single digit\n\ntotal = sum(int(d) for d in str(total))\n\nreturn total\n\n\n\n\\# Streamlit UI\n\nst.title(\"Lo Shu Grid Generator with Mulank and Bhagyank\")\n\n\n\ndob = st.text\\_input(\"Enter Your Date of Birth\", placeholder=\"eg. 12/09/1998\")\n\nbtn = st.button(\"Generate Lo Shu Grid\")\n\n\n\nif btn:\n\ndob = dob.replace(\"/\", \"\")  # Remove slashes\n\nif dob.isdigit():  # Ensure input is numeric\n\ndob\\_digits = \\[int(d) for d in dob\\]  # Convert to a list of digits\n\n\n\n\\# Calculate Mulank and Bhagyank\n\nmulank = calculate\\_mulank(dob)\n\nbhagyank = calculate\\_bhagyank(dob)\n\n\n\n\\# Generate Lo Shu Grid\n\ngrid = create\\_loshu\\_grid(dob\\_digits)\n\n\n\n\\# Display Mulank and Bhagyank\n\nst.write(f\"### Your Mulank (Root Number): {mulank}\")\n\nst.write(f\"### Your Bhagyank (Destiny Number): {bhagyank}\")\n\n\n\n\\# Create a table for the Lo Shu Grid\n\nst.write(\"### Your Lo Shu Grid:\")\n\ntable\\_html = \"\"\"\n\n<table style='border-collapse: collapse; width: 50%; text-align: center; margin: auto;'>\n\n\"\"\"\n\nfor row in grid:\n\ntable\\_html += \"<tr>\"\n\nfor cell in row:\n\ntable\\_html += f\"<td style='border: 1px solid black; padding: 20px; width: 33%; height: 33%;'>{cell if cell else ' '}</td>\"\n\ntable\\_html += \"</tr>\"\n\ntable\\_html += \"</table>\"\n\n\n\n\\# Display the table\n\nst.markdown(table\\_html, unsafe\\_allow\\_html=True)\n\nelse:\n\nst.error(\"Please enter a valid numeric date of birth in the format DD/MM/YYYY.\")",
    "created_utc": 1745915295.0,
    "url": "https://www.reddit.com/r/Python/comments/1kaiz29/guys_i_made_this_code_pls_me_check_this_and_tell/",
    "score": 0,
    "num_comments": 8
  },
  {
    "subreddit": "Python",
    "title": "Some security in LLM based apps",
    "text": "Hi everyone!\n\nI'm excited to share a project I've been working on: Resk-LLM, a Python library designed to enhance the security of applications based on Large Language Models (LLMs) like OpenAI, Anthropic, Cohere, and others.\n\n## What My Project Does\nResk-LLM focuses on adding a protective layer to LLM interactions, helping developers experiment with strategies to mitigate risks like prompt injection, data leaks, and content moderation challenges.\n\n\ud83d\udd17 GitHub Repository: https://github.com/Resk-Security/Resk-LLM\n\n## Motivation\nAs LLMs become more integrated into apps, security challenges like prompt injection, data leakage, and manipulation attacks have become serious concerns.\nHowever, many developers lack accessible tools to experiment with LLM security mechanisms easily.\n\nWhile some solutions exist, they are often closed-source, narrowly scoped, or too tied to a single provider.\n\nI built Resk-LLM to make it easier for developers to prototype, test, and understand LLM vulnerabilities and defenses \u2014 with a focus on transparency, flexibility, and multi-provider support.\n\nThe project is still experimental and intended for learning and prototyping, not production-grade security yet \u2014 but I'm excited to open it up for feedback and contributions.\n\n## Target Audience\nResk-LLM is aimed at:\n\nDevelopers building LLM-based applications who want to explore basic security protections.\n\nSecurity researchers interested in LLM attack surface exploration.\n\nHobbyists or students learning about the security challenges of generative AI systems.\n\nWhether you're experimenting locally, building internal tools, or simply curious about AI safety, Resk-LLM offers a lightweight, flexible framework to prototype defenses.\n\n\u26a0\ufe0f Important Note:\nResk-LLM is not audited by third-party security professionals. It is experimental and should not be trusted to secure sensitive production workloads without extensive review.\n\n## Comparison\nCompared to other available security tools for LLMs:\n\nGuardrails.ai and similar frameworks mainly focus on output filtering.\n\nSome platform-specific defenses (like OpenAI Moderation API) are vendor locked.\n\nResearch libraries often address single vulnerabilities (e.g., prompt injection only).\n\nResk-LLM tries to be modular, provider-agnostic, and multi-dimensional, addressing different attack surfaces at once:\n\nPrompt injection protection (pattern matching, semantic similarity)\n\nPII and doxxing detection\n\nContent moderation with customizable rules\n\nContext management to avoid unintentional leakage\n\nMalicious URL and IP leak detection\n\nCanary token insertion to monitor for data leaks\n\nAnd more (full features in the README)\n\nAdditionally, Resk-LLM allows custom security rule ingestion via flexible regex patterns or embeddings, letting users tailor defenses based on their own threat models.\n\n## Key Features\n\ud83d\udee1\ufe0f Prompt Injection Protection\n\n\ud83d\udd12 Input Sanitization\n\n\ud83d\udcca Content Moderation\n\n\ud83e\udde0 Customizable Security Patterns\n\n\ud83d\udd0d PII and Doxxing Detection\n\n\ud83e\uddea Deployment and Heuristic Testing Tools\n\n\ud83d\udd75\ufe0f Pre-filtering malicious prompts with vector-based similarity\n\n\ud83d\udcda Support for OpenAI, Anthropic, Cohere, DeepSeek, OpenRouter APIs\n\n\ud83d\udea8 Canary Token Leak Detection\n\n\ud83c\udf10 IP and URL leak prevention\n\n\ud83d\udccb Pattern Ingestion for Flexible Security Rules\n\nDocumentation & Source Code\nThe full installation guide, usage instructions, and example setups are available on the GitHub repository. Contributions, feature requests, and discussions are very welcome! \ud83d\ude80\n\n\ud83d\udd17 GitHub Repository - Resk-LLM\n\nConclusion\nI hope this post gives you a good overview of what Resk-LLM is aiming for.\nI'm looking forward to feedback, new ideas, and collaborations to push this project forward.\n\nIf you try it out or have thoughts on additional security layers that could be explored, please feel free to leave a comment \u2014 I'd love to hear from you!\n\nHappy experimenting and stay safe! \ud83d\udee1\ufe0f",
    "created_utc": 1745910605.0,
    "url": "https://www.reddit.com/r/Python/comments/1kahx5r/some_security_in_llm_based_apps/",
    "score": 77,
    "num_comments": 3
  },
  {
    "subreddit": "Python",
    "title": "Fukinotou \u2014 A type-safe data loader that validates CSV/JSONL rows using Pydantic models",
    "text": "# \ud83d\udee0\ufe0f What My Project Does\n\n**Fukinotou** is a Python library that loads CSV or JSONL files while validating each row against your domain model defined with **Pydantic**. It also tracks which file each row originated from.\n\n# \ud83d\udc65 Target Audience\n\n* Data engineers and analysts who want **early validation at data load time**\n* Python developers who define **domain logic with Pydantic models**\n* Anyone working with **multi-source CSV/JSONL data pipelines**\n\n# \ud83d\udd0d Comparison to Alternatives\n\nLibraries like [`pandera`](https://pandera.readthedocs.io/) are great for validating `pandas` DataFrames but usually require defining **separate validation schemas**.  \nFukinotou lets you reuse **plain Pydantic models** directly and provides row-level context like the source `Path`.\n\n# \u2728 Features\n\n* \u2705 Validates each row using a user-defined `BaseModel`\n* \u2705 Preserves `pathlib.Path` of the source file per row\n* \u2705 Converts clean data to `pandas` or `polars` DataFrame\n* \u2705 Raises precise error messages with row/file context\n* \u2705 Supports multiple files (ideal for batch processing)\n\n# \ud83d\udce6 GitHub\n\n\ud83d\udc49 [https://github.com/shunsock/fukinotou](https://github.com/shunsock/fukinotou)\n\nI built this for internal use but figured it might help others too. Feedback, issues, or stars are very welcome! \ud83c\udf31",
    "created_utc": 1745908444.0,
    "url": "https://www.reddit.com/r/Python/comments/1kahf26/fukinotou_a_typesafe_data_loader_that_validates/",
    "score": 11,
    "num_comments": 5
  },
  {
    "subreddit": "Python",
    "title": "CyCompile: Democratizing Performance \u2014 Easy Function-Level Optimization with Cython",
    "text": "Hi everyone!\n\nI\u2019m excited to share a new project I've been working on: **CyCompile,** a Python package that makes function-level optimization with Cython simpler and more accessible for everyone. **Democratizing Performance** is at the heart of **CyCompile**, allowing developers of all skill levels to easily enhance their Python code without needing to become Cython experts!\n\n# Motivation\n\nAs a Python developer, I\u2019ve often encountered the frustration of dealing with Python\u2019s inherent performance limitations. When working with resource-intensive tasks or performance-critical applications, Python can feel slow and inefficient. While Cython can provide significant performance improvements, optimizing functions with it can be a daunting task. It requires understanding low-level C concepts, manually configuring the setup, and fine-tuning code for maximum efficiency.\n\nTo solve this problem, I created **CyCompile**, which breaks down the barriers to Cython usage and provides a simple, no-fuss way for developers to optimize their code. With just a decorator, Python developers can leverage the power of Cython\u2019s compiled code, boosting performance without needing to dive into its complexities. Whether you\u2019re new to Cython or just want a quick performance boost, **CyCompile** makes function-level optimization easy and accessible for everyone.\n\n# Target Audience\n\n**CyCompile** is for **any Python developer** who wants to optimize their code, regardless of their experience level. Whether you're a beginner or an expert, **CyCompile** allows you to boost performance with minimal setup and effort. It\u2019s especially useful in environments like **notebooks**, **rapid prototyping**, or **production systems**, where precise performance improvements are needed without impacting the rest of the codebase.\n\nAt its core, **CyCompile** bridges the gap between **Python\u2019s elegance** and **C-level speed**, making it accessible to everyone. You don\u2019t need to be a compiler expert to take advantage of Cython\u2019s powerful performance benefits, **CyCompile** empowers **anyone** to optimize their functions easily and efficiently.\n\n# Comparison\n\nUnlike Numba\u2019s `njit`, which often implicitly compiles entire dependency chains and helper functions, or Cython\u2019s `cython.compile()`, which is generally applied to full modules or .pyx files, **CyCompile's** `cycompile()` is specifically designed for **targeted**, **function-by-function** performance upgrades. With **CyCompile**, you stay in control: only the functions you explicitly decorate get compiled, leaving the rest of your code untouched. This makes it ideal for speeding up **critical hotspots** without overcomplicating your project structure.\n\nOn top of this, **CyCompile's** `cycompile()` decorator offers several distinct advantages over Cython's `cython.compile()` decorator. It supports recursive functions natively, eliminating the need for special workarounds. Additionally, it integrates seamlessly with static Python type annotations, allowing you to annotate your code without requiring Cython-specific syntax or modifications. For more advanced users, **CyCompile** provides fine-tuned control over compilation parameters, such as Cython directives and C compiler flags, offering greater flexibility and customizability. Furthermore, its simple and customizable approach can, in some cases, outperform `cython.compile()` due to the precision and control it offers. Unlike Cython, **CyCompile** also provides a mechanism for clearing the cache, helping you manage file clutter and keep your project clean.\n\n# Key Features\n\n* **Non-invasive design**\u00a0\u2014 requires no changes to your existing project structure or imports, just add a decorator.\n* **Understands standard Python type hints**\u00a0\u2014 avoiding the need for Cython-specific rewrites.\n* **Handles recursive functions**\u00a0\u2014 overcoming a common limitation in traditional function-level compilation tools.\n* **Supports user-defined objects**\u00a0and custom logic more gracefully than many static compilers.\n* **Offers fine-grained control**\u00a0over Cython directives and compiler flags for advanced users.\n* **Intelligent source-based caching**\u00a0\u2014 automatically avoids unnecessary recompilation by detecting source changes.\n* **Includes a manual cache cleanup option**\u00a0\u2014 giving developers control over the binary cache when desired.\n\n# Documentation & Source Code\n\nFull installation steps and usage instructions are available on both the [README](https://github.com/Ranuja01/cycompile/blob/main/README.md)\u00a0and\u00a0[PyPI page](https://pypi.org/project/cycompile/). **I also wrote a detailed Medium article covering use cases** (r/Python rules don't allow Medium links, but you can find it linked in the README!). \n\nFor those interested in how the implementation works under the hood or who want to contribute, the full source is available on [GitHub](https://github.com/Ranuja01/cycompile). **CyCompile** is actively maintained, and any contributions or suggestions for improvement are welcome!\n\n# Conclusion\n\nI hope this post has given you a good understanding of what **CyCompile** can do for your Python code. I encourage you to try it out, experiment with different configurations, and see how it can speed up your critical functions. You can find installation instructions and [example code](https://github.com/Ranuja01/cycompile/tree/main/examples) on GitHub to get started.\n\n**CyCompile** makes it easy to optimize specific parts of your code without major refactoring, and its flexibility means you can customize exactly what gets accelerated. That said, given the large variety of potential use cases, it\u2019s difficult to anticipate every edge case or library that may not work as expected. However, I look forward to seeing how the community uses this tool and how it can evolve from there.\n\nIf you try it out, feel free to share your thoughts or suggestions in the comments, I\u2019d love to hear from you!\n\nHappy compiling!\n\n",
    "created_utc": 1745859693.0,
    "url": "https://www.reddit.com/r/Python/comments/1ka0m88/cycompile_democratizing_performance_easy/",
    "score": 49,
    "num_comments": 13
  },
  {
    "subreddit": "Python",
    "title": "Garmin Grafana Dashboard : Visualize your health metrics from your Garmin with Python",
    "text": "\u2705\u00a0\u00a0\u00a0**Please check out the project :**\u00a0\u00a0\u00a0[**https://github.com/arpanghosh8453/garmin-grafana**](https://github.com/arpanghosh8453/garmin-grafana)\n\nPlease check out the\u00a0`Automatic Install with helper script`in the readme to get started if you don't have trust on your technical abilities.\u00a0**You should be able to run this on any platform (including any Linux variants i.e. Debian, Ubuntu, or Windows or Mac) following the instructions**\u00a0. If you encounter any issues with it, which is not obvious from the error messages, feel free to let me know.\n\n**Please give it a try (it's free and open-source)!**\n\n# Target Audience\n\nAny Garmin watch user who wants to have control on their health data and visualize them better - supports every Garmin watch model\n\n# What my project does\n\nIt fetches the data synced with Garmin Connect to a local database (InfluxDB) and provides a dashboard where you can view and analyze the data however you want. New data is fetched on a schedule basis so you will see them appear on the dashboard as soon as they sync with Connect Plus app. \n\n# Features\n\n* Automatic data collection from Garmin\n* Collects comprehensive health metrics including:\n   * Heart Rate Data\n   * Hourly steps Heatmap\n   * Daily Step Count\n   * Sleep Data and patterns\n   * Sleep regularity (Visualize sleep routine)\n   * Stress Data\n   * Body Battery data\n   * Calories\n   * Sleep Score\n   * Activity Minutes and HR zones\n   * Activity Timeline (workouts)\n   * GPS data from workouts (track, pace, altitude, HR)\n   * And more...\n* Automated data fetching in regular interval (set and forget)\n* Historical data back-filling\n\n# Comparison\u00a0: What are the advantages?\n\n1. You keep a local copy of your data, and the best part is it's set and forget. The script will fetch future data as soon as it syncs with your Garmin Connect - No action is necessary on your end.\n2. You are not limited by the visual representation of your data by Garmin app. You own the raw data and can visualize however you want - combine multiple matrices on the same panel? what to zoom on a specific section of your data? want to visualize a weeks worth of data without averaging values by date? this project got you covered!\n3. You can play around your data in various ways to discover your potential and what you care about more.\n4. You can view your daily metrics - not only activity ones (provided by other online services)\n\n# Love this project?\n\nIt's\u00a0\u00a0**Free for everyone (and will stay forever without any paywall)**\u00a0\u00a0to setup and use. If this works for you and you love the visual, a\u00a0simple\u00a0**word of support**\u00a0\u00a0here will be very appreciated. I spend a lot of my free time to develop and work on future updates + resolving issues, often working late-night hours on this. You can\u00a0[**star the repository**\u00a0](https://github.com/arpanghosh8453/garmin-grafana)as well to show your appreciation.\n\nPlease\u00a0**share your thoughts on the project in comments or private chat**\u00a0and I look forward to hearing back from the users.",
    "created_utc": 1745842105.0,
    "url": "https://www.reddit.com/r/Python/comments/1k9txqf/garmin_grafana_dashboard_visualize_your_health/",
    "score": 43,
    "num_comments": 3
  },
  {
    "subreddit": "Python",
    "title": "I am a Teacher looking for a career change. Is knowing Python enough to land me a job?",
    "text": "If so which jobs and where do I find them? If not, what else would I need? \n\nAfter 10 years as an English teacher I can't do it any longer and am looking for a career change. I have a lot of skills honed in the classroom and I am wondering if knowing Python on top of this is enough to land me a job?\n\nThanks. ",
    "created_utc": 1745836890.0,
    "url": "https://www.reddit.com/r/Python/comments/1k9sftq/i_am_a_teacher_looking_for_a_career_change_is/",
    "score": 152,
    "num_comments": 187
  },
  {
    "subreddit": "Python",
    "title": "Monday Daily Thread: Project ideas!",
    "text": "# Weekly Thread: Project Ideas \ud83d\udca1\n\nWelcome to our weekly Project Ideas thread! Whether you're a newbie looking for a first project or an expert seeking a new challenge, this is the place for you.\n\n## How it Works:\n\n1. **Suggest a Project**: Comment your project idea\u2014be it beginner-friendly or advanced.\n2. **Build & Share**: If you complete a project, reply to the original comment, share your experience, and attach your source code.\n3. **Explore**: Looking for ideas? Check out Al Sweigart's [\"The Big Book of Small Python Projects\"](https://www.amazon.com/Big-Book-Small-Python-Programming/dp/1718501242) for inspiration.\n\n## Guidelines:\n\n* Clearly state the difficulty level.\n* Provide a brief description and, if possible, outline the tech stack.\n* Feel free to link to tutorials or resources that might help.\n\n# Example Submissions:\n\n## Project Idea: Chatbot\n\n**Difficulty**: Intermediate\n\n**Tech Stack**: Python, NLP, Flask/FastAPI/Litestar \n\n**Description**: Create a chatbot that can answer FAQs for a website.\n\n**Resources**: [Building a Chatbot with Python](https://www.youtube.com/watch?v=a37BL0stIuM)\n\n# Project Idea: Weather Dashboard\n\n**Difficulty**: Beginner\n\n**Tech Stack**: HTML, CSS, JavaScript, API\n\n**Description**: Build a dashboard that displays real-time weather information using a weather API.\n\n**Resources**: [Weather API Tutorial](https://www.youtube.com/watch?v=9P5MY_2i7K8)\n\n## Project Idea: File Organizer\n\n**Difficulty**: Beginner\n\n**Tech Stack**: Python, File I/O\n\n**Description**: Create a script that organizes files in a directory into sub-folders based on file type.\n\n**Resources**: [Automate the Boring Stuff: Organizing Files](https://automatetheboringstuff.com/2e/chapter9/)\n\nLet's help each other grow. Happy coding! \ud83c\udf1f",
    "created_utc": 1745798430.0,
    "url": "https://www.reddit.com/r/Python/comments/1k9i87u/monday_daily_thread_project_ideas/",
    "score": 5,
    "num_comments": 0
  },
  {
    "subreddit": "Python",
    "title": "How does NGINX Unit perform vs Uvicorn in production for FastAPI / Litestar deployments?",
    "text": "Hi Peeps,\n\nI'm setting up a new production environment for a project (built with FastAPI) and evaluating ASGI server options. I've used Uvicorn workers with Gunicorn in the past, but I'm curious about [NGINX Unit](https://unit.nginx.org/howto/fastapi/) as an alternative.\n\nFor those who have experience with both in production:\n\n- How does NGINX Unit's performance compare to Uvicorn for FastAPI/Litestar apps? Any benchmarks or real-world observations?\n\n- What are the main advantages/disadvantages of NGINX Unit vs Uvicorn+Gunicorn setup?\n\n- Are there any particular workloads where one significantly outperforms the other? (high concurrency, websockets, etc.)\n\n- Any gotchas or issues you've encountered with either option?\n\nI'd appreciate insights from anyone running these frameworks in production. Thanks!",
    "created_utc": 1745793120.0,
    "url": "https://www.reddit.com/r/Python/comments/1k9gf7w/how_does_nginx_unit_perform_vs_uvicorn_in/",
    "score": 7,
    "num_comments": 2
  },
  {
    "subreddit": "Python",
    "title": "Debugging Python f-string errors",
    "text": "https://brandonchinn178.github.io/posts/2025/04/26/debugging-python-fstring-errors/\n\nToday, I encountered a fun bug where f\"{x}\" threw a TypeError, but str(x) worked. Join me on my journey unravelling what f-strings do and uncovering the mystery of why an object might not be what it seems.",
    "created_utc": 1745770904.0,
    "url": "https://www.reddit.com/r/Python/comments/1k97u9w/debugging_python_fstring_errors/",
    "score": 121,
    "num_comments": 18
  },
  {
    "subreddit": "Python",
    "title": "Imgui with pygame and mgl?",
    "text": "Hello i was trying to add dear in gui into my game\n\nI have a specific render pipeline with open gl shaders, but when i tried to add imgui to it it breaks rendering only one screen triangle without imgui\nAnd imgui is really pissed me off with io display sizes and key mappings\nPls help",
    "created_utc": 1745749962.0,
    "url": "https://www.reddit.com/r/Python/comments/1k90xb7/imgui_with_pygame_and_mgl/",
    "score": 0,
    "num_comments": 1
  },
  {
    "subreddit": "Python",
    "title": "I have some free time...",
    "text": "Hey guys, I have some *free time* right now, so I'd like to **work** on some project you're stuck on or whatever. I'm not looking for ~~monetary rewards~~, just to multiply my **experience**. It can be any field, if I don't know it better, something new to study :D",
    "created_utc": 1745745627.0,
    "url": "https://www.reddit.com/r/Python/comments/1k8zwp3/i_have_some_free_time/",
    "score": 0,
    "num_comments": 12
  },
  {
    "subreddit": "Python",
    "title": "How does Python 3.13 perform vs 3.11 in single-threaded mode?",
    "text": "When Python 3.12 was released, I had held back from migrating my Python 3.11 applications as there were some mixed opinions back then about Python 3.12's performance vs 3.11. Then, 3.13 was released, and I decided to give it some time to mature before evaluating it.\n\nNow, we're in Python 3.13.3 and the last bugfix release of 3.11 is out. When I Google'd, I only found performance studies on Python 3.13 in its experimental free-threaded mode, which is definitely slower than 3.11. However, I found nothing about 3.13 in regular GIL mode.\n\nWhat are you guys' thoughts on this? Performance-wise, how is Python 3.13 compared to Python 3.11 when both are in GIL-enabled, single-threaded mode? Does the experimental JIT compiler in 3.13 help in this regard?",
    "created_utc": 1745743256.0,
    "url": "https://www.reddit.com/r/Python/comments/1k8zcdi/how_does_python_313_perform_vs_311_in/",
    "score": 100,
    "num_comments": 36
  },
  {
    "subreddit": "Python",
    "title": "Sunday Daily Thread: What's everyone working on this week?",
    "text": "# Weekly Thread: What's Everyone Working On This Week? \ud83d\udee0\ufe0f\n\nHello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to!\n\n## How it Works:\n\n1. **Show & Tell**: Share your current projects, completed works, or future ideas.\n2. **Discuss**: Get feedback, find collaborators, or just chat about your project.\n3. **Inspire**: Your project might inspire someone else, just as you might get inspired here.\n\n## Guidelines:\n\n* Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome.\n* Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here.\n\n## Example Shares:\n\n1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!\n2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better.\n3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!\n\nLet's build and grow together! Share your journey and learn from others. Happy coding! \ud83c\udf1f",
    "created_utc": 1745712050.0,
    "url": "https://www.reddit.com/r/Python/comments/1k8qtm2/sunday_daily_thread_whats_everyone_working_on/",
    "score": 8,
    "num_comments": 6
  },
  {
    "subreddit": "Python",
    "title": "Can AI play a role in creating automated software tests?",
    "text": "In the latest episode of Test & Code, Anthony Shaw and Brian Okken discuss using copilot and other AI tools to generate automated software tests.\n\nHere's the episode: [The role of AI in software testing - Anthony Shaw](https://testandcode.com/episodes/ai-role-software-testing)\n\nAI is helping people write code. \u00a0  \nTests are one of those things that some people don't like to write.\u00a0 \u00a0  \n  \nCan AI play a role in creating automated software tests? \u00a0  \nWell, yes. But it's a nuanced yes. \u00a0  \n  \nAnthony Shaw comes on the show to discuss the topic and try to get AI to write some test for my very own cards project.  \n  \nWe discuss:\n\n* The promise of AI writing your tests for you\n* Downsides to not writing tests yourself\n* Bad ways to generate tests\n* Good ways to ask AI for help in writing tests\n* Tricks to get better results while using copilot and other AI tools\n\nA video version of this discussion was posted by Anthony:\u00a0[Should AI write tests?](https://www.youtube.com/watch?v=a_V-BH_luJ4)\n\nI'd love to hear from others:\n\n* Are you using AI to help generate (or completely generate) tests?\n* Do you have any good tricks?\n* Are there other reasons to NOT try this at home?\n\n",
    "created_utc": 1745684038.0,
    "url": "https://www.reddit.com/r/Python/comments/1k8glge/can_ai_play_a_role_in_creating_automated_software/",
    "score": 0,
    "num_comments": 4
  },
  {
    "subreddit": "Python",
    "title": "Python Makes Cloud Engineering 10x Easier \u2014 What's Your Take?",
    "text": "Hey everyone,\nLately while working with AWS and GCP, I've realized how much Python speeds up everything in the cloud world.\nSome quick thoughts:\n\n\u2022 Cloud platforms today (AWS, GCP, Azure) are all about automation.\n\n\u2022 Python is basically the go-to scripting language for Cloud Engineers now.\n\n\u2022 Whether it's writing Lambda functions, automating deployments, or integrating APIs \u2014 Python is everywhere.\n\n\u2022Without some coding, cloud skills kind of stay at the surface level.\n\n\nThe way I see it:\n\"Mastering basic Python will unlock serious Cloud magic.\"\n\nCurious \u2014 if you're working in cloud or DevOps, how much has Python helped you? Or if you\u2019re just learning, how are you approaching both together?\n\nWould love to hear your experience and thoughts!",
    "created_utc": 1745672675.0,
    "url": "https://www.reddit.com/r/Python/comments/1k8chge/python_makes_cloud_engineering_10x_easier_whats/",
    "score": 0,
    "num_comments": 9
  },
  {
    "subreddit": "java",
    "title": "ZGC is a mesh..",
    "text": "Hello everyone.  We have been trying to adopt zgc in our production environment for a while now and it has been a mesh.. \n\nFor a good that supposedly only needs the heap size to do it's magic we have been falling to pitfall after pitfall. \n\nTo give some context we use k8s and spring boot 3.3 with Java 21 and 24.\n\n\nFirst of all the memory reported to k8s is 2x based on the maxRamPercentage we have provided.\nSecondly the memory working set is close to the limit we have imposed although the actual heap usage is 50% less.\nThirdly we had to utilize the SoftMaxHeapSize in order to stay within cities and force some more aggressive GCs.\nLastly we have been searching for the source of our problems and trying to solve it by finding the best java options configuration, that based on documentation wouldn't be necessary..\n\nDoes anyone else have such issues? If so how did you overcome them( changing back to G1 is an acceptable answer)?\n\nThankss \n\nEdit 1: We used generational ZGC in our adoption attempts",
    "created_utc": 1746511148.0,
    "url": "https://www.reddit.com/r/java/comments/1kfxd44/zgc_is_a_mesh/",
    "score": 8,
    "num_comments": 18
  },
  {
    "subreddit": "java",
    "title": "Should we start dreaming about a \u201cJava 2.0\u201d?",
    "text": "Lately, I\u2019ve been wondering\u2014maybe it\u2019s time we imagine a real \u201cJava 2.0.\u201d A version of Java that breaks free from the decades-old design constraints and isn\u2019t burdened by always having to preserve backward compatibility.\n\nYes, compatibility has been one of Java\u2019s greatest strengths. But when it becomes a hard rule, it forces a lot of compromises. Just look at things like Date and Calendar\u2014we all know they\u2019re broken, yet they remain, because we can\u2019t remove anything without breaking someone\u2019s code.\n\nMeanwhile, most modern languages today don\u2019t even try to guarantee perpetual backward compatibility. Instead, they adopt semantic versioning or similar strategies to evolve the language over time. This gives them the freedom to redesign awkward parts of the language, deprecate outdated patterns, and experiment with new paradigms\u2014without being held hostage by legacy decisions.\n\nIn contrast, Java often adopts features years after they\u2019ve been proven in other languages\u2014like var, record, and now pattern matching. The most extreme case? Project Valhalla. It\u2019s been in the works for over 10 years, and may take 15 years to fully land. That\u2019s half the entire lifespan of Java itself. It sounds insane when you step back\u2014and honestly, it\u2019s no surprise that other language communities poke fun at us for this kind of timeline.\n\nOf course, breaking compatibility comes with pain. Python\u2019s transition from 2 to 3 was rough, no doubt. But look at Python today\u2014it\u2019s cleaner, more consistent, and thriving. That pain was temporary. What\u2019s worse is eternal stagnation in the name of safety.\n\nMaybe what we need isn\u2019t to blindly break stuff, but to invest in smoother migration paths. Imagine if Java provided official tools, clear upgrade guides, or even a \u201cforward-looking\u201d JDK mode\u2014something that helps developers move ahead without feeling abandoned. That kind of vision might be what finally unlocks real progress.\n\nJust some thoughts :)\n",
    "created_utc": 1746469361.0,
    "url": "https://www.reddit.com/r/java/comments/1kfiv6x/should_we_start_dreaming_about_a_java_20/",
    "score": 0,
    "num_comments": 74
  },
  {
    "subreddit": "java",
    "title": "Is there any way I can help contribute to Valhalla?",
    "text": "Hello!\n\nProject Valhalla interests me, and I'd love to help it along somehow. Is there any way I can contribute pull requests or something to fix bugs to make it arrive faster?",
    "created_utc": 1746072169.0,
    "url": "https://www.reddit.com/r/java/comments/1kbzu6v/is_there_any_way_i_can_help_contribute_to_valhalla/",
    "score": 36,
    "num_comments": 15
  },
  {
    "subreddit": "java",
    "title": "Java web framework help - has the /r/java community had good experiences with Javalin?",
    "text": "[https://javalin.io/](https://javalin.io/)\n\nI've been working on Java APIs, primarily using [spark](https://github.com/perwendel/spark) as a backend framework. I have completed the following steps to modernise the stack;\n\n* Updated to java 21\n* Docker image build with GraalVM native images\n* Updated all libraries (which is the motivation for this post)\n\nI want to consider an actively maintained web framework. I really like spark because it is very, very simple. The lastest spark version covers about 90% of requirements for a web framework in my use case so moving to a larger framework because of more features is not a strong argument.\n\nIs anyone using Javalin? It is the spiritual successor to spark. I'm also interested in any commments about other options (Quarkus, Micronaut, plain vert.x, and others).\n\nThere is zero chance of adopting Spring at my organisation, even discussing this is considered sacrilege",
    "created_utc": 1745902164.0,
    "url": "https://www.reddit.com/r/java/comments/1kafuez/java_web_framework_help_has_the_rjava_community/",
    "score": 20,
    "num_comments": 30
  },
  {
    "subreddit": "java",
    "title": "AI recommendations for Jira plugin development in Java",
    "text": "I'm a seasoned developer on Microsoft technology stack but pretty new to Java. My new role requires developing Jira Data Center plugins, and I'm hoping someone can help me recommend AI options that they're using for Jira plugins, what challenges they have run into, and how they overcame them. \n\nMany thanks!",
    "created_utc": 1745805817.0,
    "url": "https://www.reddit.com/r/java/comments/1k9kkda/ai_recommendations_for_jira_plugin_development_in/",
    "score": 0,
    "num_comments": 2
  },
  {
    "subreddit": "java",
    "title": "Flow Logix 9.0.10 Jakarta EE Components released!",
    "text": "What is Flow Logix Components? Last few remaining missing pieces in what is covered by Jakarta EE, PrimeFaces, OmniFaces, Apache Shiro and other very popular software.\n\n  \nNew and exciting updates:\n\n* 99% test coverage - real coverage with end-to-end tests, not getters and setters\n* All JavaDoc snippets and documentation examples are common, in src/java/demo directory, and are run and tested for correctness with the integration tests\n* One-line setup with Selenium and Arquillian / Drone / Graphene, great example how to set up end-to-end testing including UI testing.\n* Code \n\n# Is it a framework?\n\nNo. FlowLogix fits within the Jakarta EE design philosophy and works with MicroProfile, Jakarta EE, OmniFaces and PrimeFaces ecosystem. FlowLogix tries to be the least intrusive, automatic and with the fewest requirements possible.\n\nFeatures Included:\n\n* Provides automatic Data Access Helper for JPA with delegation and without inheritance\n* Adds Type-safe Native SQL query with JPA via generics\n* Declares Jakarta Faces PROJECT\\_STAGE development mode automatically\n* Automatically uses minified versions of assets with Jakarta Faces\n* Provides easy and automatic initialization of OmniFaces' UnmappedResourceHandler\n* Easier-to-use, Injected JPA Lazy Data Model for PrimeFaces DataTable that automatically supports clustered sessions (\"the original LazyDataModel\")\n* Automatically includes PrimeFaces font mime types in your web applications, preventing warnings and extra entries in your web.xml\n* Convert strings to arbitrary types on a best-effort basis\n* Transforms names between javax and jakarta namespaces\n* Checks if objects are truly serializable by testing them\n* Easy Transform Streams to Strings\n* Simplify creation and manipulation of ShrinkWrap and Arquillian test archives including assets\n\nFull documentation is here: [https://docs.flowlogix.com](https://docs.flowlogix.com)\n\nGitHub: [https://github.com/flowlogix/flowlogix](https://github.com/flowlogix/flowlogix)\n\n\n\n",
    "created_utc": 1745701381.0,
    "url": "https://www.reddit.com/r/java/comments/1k8n5gc/flow_logix_9010_jakarta_ee_components_released/",
    "score": 17,
    "num_comments": 5
  },
  {
    "subreddit": "java",
    "title": "Video - How to translate SQL queries to jOOQ with AI using JetBrains Junie",
    "text": "In this video, I'm giving a try to JetBrain Junie to help me translate a non-trivial SQL query to its jOOQ counterpart.\n\nNot only was the jOOQ query written properly, but the assert logic was included as well, helping us validate the result.",
    "created_utc": 1745564178.0,
    "url": "https://youtu.be/ruSp3y-ZxAE",
    "score": 0,
    "num_comments": 5
  },
  {
    "subreddit": "java",
    "title": "Spring Security CVE-2025-22234 on spring-security-crypto",
    "text": "Just saw new CVE posted and figured I'd share in case it affects any of your setups.\n\nCVE-2025-22234 (medium) dropped on April 22nd for Spring Security, and it has to do with `spring-security-crypto`. The fix for an earlier issue (CVE-2025-22228) broke timing attack protection in `DaoAuthenticationProvider`.\n\nLooks like if you\u2019re using `BCryptPasswordEncoder` and a user submits a password longer than 72 characters, it now throws an exception \u2014 and that exception could potentially leak info about which users exist in your system (aka timing attack vulnerability)\n\nVersions affected:  \n5.7.16, 5.8.18, 6.0.16, 6.1.14, 6.2.10, 6.3.8, 6.4.4\n\nIn support versions have a patch out, but out of support versions (5.x, 6.0.x) can only get fixes from commercial support providers.\n\nMore info: [https://www.herodevs.com/vulnerability-directory/cve-2025-22234](https://www.herodevs.com/vulnerability-directory/cve-2025-22234) ",
    "created_utc": 1745527653.0,
    "url": "https://www.reddit.com/r/java/comments/1k72zkn/spring_security_cve202522234_on/",
    "score": 40,
    "num_comments": 5
  },
  {
    "subreddit": "java",
    "title": "Netbeans Clipboard Copy and Paste bug",
    "text": "I created a Netbeans plugin to fix that error.\n\nBUG:\nCopy a piece of text in Netbeans\nPaste the text in an applicaiton\nIn From this application copy some other text\nPaste the text into netbeans\nPaste it somewhere\nCopy text again\nEvery new copy from netbeans from now on will not work anymore. If I do not copy in an outside application the clipboard will now be empty",
    "created_utc": 1745514963.0,
    "url": "https://github.com/mikaelarh/CopyPasteFixNetbeans/releases/tag/Release_0.1",
    "score": 20,
    "num_comments": 17
  },
  {
    "subreddit": "java",
    "title": "Discussion regarding module imports (JEP 511)",
    "text": "It looks like [JEP 511](https://openjdk.org/jeps/511) is scheduled to be finalized. I would like to discuss whether an alternative approach might be a better fit.\n\nWhile importing classes isn't a big problem per se, we can potentially change it to fit other use-cases. This alternative deals with these 2 issues:\n\n# Reducing the cognitive load of dealing with both modules and packages\n\nStarting from one of the goals of this JEP:\n\n>Allow beginners to more easily use third-party libraries and fundamental Java classes without having to learn where they are located in a package hierarchy.\n\nSay for example you're importing all from module `java.base` and using `List`, `Pattern` and `Files`. While still within `import *` syntax things are simple, you only need to know these are from `java.base`.\n\nBut, when the need arises to move from `import *` to import specific classes, now those beginners will face a new cognitive load. Not only will they need to learn to which packages `List`, `Pattern` and `Files` belong (`java.util`, `java.util.Regex` and `java.nio.files` respectively),  \nbut their mental map of *\"class List comes from java.base\"* is now obsolete.\n\nThe one above is a simple example, we may assume that most Java developers and students are somewhat familiar with `java.base` module,  \nbut if you go to third-party dependencies this problem only gets worse.\n\n# Using this feature in production code\n\nThis feature might be skipped for the same reasons `import com.package.*` is. There's probably many arguments pro or against `import *`, but the ones i've encountered so far fall into these categories:\n\n1. using `import com.package.*` means your source can break whenever your dependencies are updated (example another package adds `Context` class or any such generic named class)\n2. use of `import *` is undesirable when reviewing Pull Requests because you don't know from which package/module it comes from, sort of forcing you to review in IDE only\n\n# Potential implementation\n\nSo we have this as a hierarchy of units in Java (from largest to smallest):\n\n1. module\n2. package\n3. class\n4. property, method, etc\n\nOne thing that might work could be:  \n`from <MODULE> import [* | <MODULE_IMPORT_DECLARATION>]`.\n\nNote that syntax isn't the important part here, it just makes it easier to conceptualize:\n\n1. `from java.base import *` for beginners / prototyping\n2. `from java.base import { List, Files }` when moving to specific imports\n\nAt this second point we face 2 options, either **A)** import by simple class name only (`List`) or **B)** full path (`java.util.List`).  \nIn the original JEP, since the syntax only imports all the classes of a module, it makes the assumption that it can only be used if a module doesn't export any classes with the same name (simple name). So in that regard option **A** doesn't limit you more, it also permits a module exporting some classes with same simple name.\n\nNow we don't necessarily need to do it that way, the point is in Java we have a fixed hiearchy for organizing code: **modules / packages / classes / methods**. We can make these features interact well with each other instead being separate worlds, and developers needing to know it from multiple angles (both modules and packages).\n\nSuch a hierarchical approach IMO would be useful also for increasing adoption of modules, because it both pushes for use of modules, and also makes it easier (more natural?) to work with them.\n\n# Risks and final thoughts\n\nEven the most basic form `from <MODULE> import` is a larger syntax divergence than the proposed `import module <MODULE>`. Its extended form then adds a further shift from current import syntax, meaning more complexity added to the language.\n\nBesides increasing language complexity, a shift from the current import (`import <PACKAGE>.<CLASS>`) to import by modules, may cause issues with frameworks relying on package scanning, such as Spring Boot.\n\nWhile we usually want as little syntax as possible, we also want that syntax to cover many use cases.  \nBut maybe such discussion shouldn't start from syntax, rather how code is organized (and consumed) in Java.\n\n# Edit\n\nMaybe the JEP isn't really incompatible with the proposed changes.  \nThe syntax already proposed in JEP 511 could be extended to allow import classes of module, example `import module java.base.{List, Files}`\n\nIn that sense this JEP is fine, it doesn't block syntax to be extended with the above use-cases.",
    "created_utc": 1745436672.0,
    "url": "https://www.reddit.com/r/java/comments/1k683ad/discussion_regarding_module_imports_jep_511/",
    "score": 22,
    "num_comments": 42
  },
  {
    "subreddit": "java",
    "title": "Getting started with SDKMAN! \u2013 Manage Java, Maven, Gradle versions with ease",
    "text": "I put together a beginner-friendly guide on [SDKMAN!](https://sdkman.io), a super handy tool for managing parallel versions of Java SDKs, Maven, Gradle, and many other development tools right from your terminal.\n\nIf you've ever struggled with switching between Java versions for different projects, SDKMAN! can really simplify your workflow.\n\nIn the post, I cover:\n\n* What SDKMAN! is and why it\u2019s useful.\n* How to install it.\n* How to install and switch between SDKs.\n* Tips for setting a default version.\n\nHope it helps someone!",
    "created_utc": 1745169461.0,
    "url": "https://tanis.codes/posts/getting-started-with-sdkman/",
    "score": 85,
    "num_comments": 39
  },
  {
    "subreddit": "java",
    "title": "About credentials provided by a service at runtime and connection pools.",
    "text": "The company where I work has released a new policy: \n\n> All credentials will be stored at a server working as a Vault. This vault publish a rest service for retrieving the needed credentials by its assigned name.\n\nThe communication using this particular service will be made secure by networking configuration. I don't know how well this will work, but application developers won't be responsible for \"securing this communication channel\". So I'll just use it, \"how\" it will be made secure is someone else problem.\n\nThis new policy also prescribes :\n\n* the application must retrieve credentials at start or when it first needed\n* an application receiving a request and doesn't having valid credentials will return an error implying a temporary internal error.\n* before returning the error named in the previous point, the application may try to retrieve new credentials from the vault.\n* the credentials can be updated at any time in the vault, and the old ones will be render invalid.\n* the change of credentials at the vault won't be notified to applications.\n* when requests to upstream service fails, by default, the application will try to get new credentials.\n* when requests to upstream service fails and the error is clearly identified as something different from bad credentials, the application will handle it in a custom manner.\n* Even its easier to just restart the containers/applications needing fresh credentials, we wont do that. (Yes, I did asked)\n\nI think I can implement all this for one time connections. I think I have implemented more detailed strategies to retrieve tokens from _OAuth_ servers prone to fail requests on account of their many internal problems.\n\nBut **I never mixed an schema like this one with a _connection pool_, or with a _driver plus its built in connection pool_.** In particular, we already have _JDBC_ and _JTA_ (for AS400) connection pools in production but getting their credentials from environment variables.\n\nHave anyone worked with java applications with such constrains? **Any previous experiences, any ideas in the matter are welcome**.\n\n--------\n\n_To the Moderators: I think this question is a design matter and may fall under the \"Technical Discussion\". If I'm wrong, just delete the post without second thoughts and have my sincere apologies._",
    "created_utc": 1744948215.0,
    "url": "https://www.reddit.com/r/java/comments/1k1vs1s/about_credentials_provided_by_a_service_at/",
    "score": 24,
    "num_comments": 42
  },
  {
    "subreddit": "java",
    "title": "Framework to create your own languages in Java",
    "text": "This took me about 2 years of development from inception to the state it is now. It's a framework for creating interpreted programming languages called [LARF (Language Architect and Runtime Framework)](https://www.larf.dev). There are of course other frameworks and toolsets to do this e.g. ANTLR, but as far as I know I am the only one to take an object orientated approach to language development. Each literal, statement and associated logic is contained within its own single class. Want to add a new type of statement to your language? Simply create the class, define the grammar pattern and logic, add a single line to the config and see it in action! Here is an [example ](https://gitlab.com/tronied/larf-slop/-/blob/main/src/main/java/dev/larf/languages/slop/tokens/statements/ConditionalToken.java?ref_type=heads)of this for a ternary statement.\n\n  \nIt supports whitespace indentation or standard code-blocks, notation types (infix, suffix, prefix), typed / typeless and I tried to add as many features as I could think of. I didn't want anyone to be limited when using it... except perhaps by an unexpected bug which pops up now and then. I've made it fully [open-source](https://gitlab.com/tronied/larf) so please feel free to have a look. There are a couple of example projects as well as a fully realised language called [SLOP](https://gitlab.com/tronied/larf-slop) \\- It even has its own [website ](https://www.slop.dev/)I created for it. LARF is fairly flexible and can create anything from high-level to pseudo low level languages. Another example I wrote mimics an [assembly language interpreter](https://gitlab.com/tronied/mal), though it was only a small proof of concept and has limited functionality.\n\n  \nThere's a [tutorial ](https://www.larf.dev/docs/tutorial/getting-started)guide I wrote to get someone started in using it. I am planning on extending the tutorial much further, but it's quite time consuming to do so this will be a gradual process. Anyway, I'd appreciate any feedback you have. ",
    "created_utc": 1744926079.0,
    "url": "https://www.reddit.com/r/java/comments/1k1oje4/framework_to_create_your_own_languages_in_java/",
    "score": 62,
    "num_comments": 17
  },
  {
    "subreddit": "java",
    "title": "Sourcetrail 2025.4.1 released",
    "text": "Hi everybody,\n\nI'm the maintainer of this [Sourcetrail](https://github.com/petermost/Sourcetrail) fork, a C++/Java source explorer, and I released version [Sourcetrail 2025.4.1](https://github.com/petermost/Sourcetrail/releases/tag/2025.4.1)\n\nHave a look at the [Changelog](https://github.com/petermost/Sourcetrail/blob/master/CHANGELOG.md) to see what changes have been done since the last official release from Coati Software. Some noteworthy changes:\n\n* Java: Add Support for record classes\n* Java: Update Parser (Eclipse JDT) for Java 23\n* Java: Update Gradle support to 8.12\n* macOS: Fix vcpkg build. Thanks to [ChristianWieden](https://github.com/ChristianWieden) for the help\n* C++: Indexing of user defined conversion operators\n* C++: Indexing of the deduced type of auto variables\n* C++: Indexing of non-trivial destructor calls\n* C++: Update of libClang to Clang 18/19\n* C++: Update to Qt6\n\nBinary releases are available for [sponsors](https://github.com/sponsors/petermost).",
    "created_utc": 1744728575.0,
    "url": "https://www.reddit.com/r/java/comments/1jztsi5/sourcetrail_202541_released/",
    "score": 35,
    "num_comments": 2
  },
  {
    "subreddit": "java",
    "title": "A pain point when using Java to do CLI Scripting",
    "text": "The following JEP's have released recently.\n\n- [JEP 495: Simple Source Files and Instance Main Methods](https://openjdk.org/jeps/495)\n- [JEP 330: Launch Single-File Source-Code Programs](https://openjdk.org/jeps/330)\n- [JEP 222: jshell: The Java Shell (Read-Eval-Print Loop)](https://openjdk.org/jeps/222)\n\nThese have made it really easy for me to do CLI scripting in Java, as opposed to Bash. However, I've run into some pain points, as I've relied more and more on Java.\n\nFor starters, the hand off from Java --> Bash is kind of ugly. Bash --> Java is not bad, due to `void main(final String[] args)`, as well as Bash's `xargs`. But Java --> Bash is ugly, and here is an example demonstrating how/why.\n\n---\n\nI use AWS CLI to manage my dev environment. It's super powerful, and is all available directly from the CLI, using simple Bash or even CMD.\n\nLet's say I use AWS CLI to gather some ad-hoc information about my entire dev environment. How do I manage the multiple handoffs back and forth between AWS CLI and Java?\n\nThere are no good answers.\n\n1.  Store the results into a file, then use JShell/java(c) to process the output file from Bash/AWS CLI.\n    - There's multiple handoffs back and forth between AWS CLI and Java. So, every handoff from Java ---> AWS CLI means generating a new file, thus increasing the complexity and cruft. It's unideal.\n2. Use Java's [ProcessBuilder](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/lang/ProcessBuilder.html) and [Process](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/lang/Process.html) classes.\n   - This works, but is heavy-handed. Look at the examples in those links. That is multiple lines of code to represent a single bash command. It does appear to be the idiomatic way, though.\n3. Do all upstream processing with AWS CLI in Bash directly, then do only a single handoff to Java, once I have done all I need to with AWS CLI.\n   - This is definitely the least painful, but it also means I don't use much Java at all. And any changes in upstream processing must be done in Bash to avoid handoff headaches from AWS CLI ---> Java.\n4. Download the AWS SDK Jar files and just do it all in Java.\n   - Ignoring the fact that some things are much harder to do via the AWS Java SDK's, there's actually some functionality that just isn't available via the Java ones. I'd have to recreate it myself, and it would be a significant lift.\n\nOption 4 is best when I am building an application, but for ad-hoc checks that I want to do on the fly (my most common use-case by far), I have been using Option 3.\n\nI just wish I could use more Java. It's a ***FAR BETTER***tool than Bash, but I can't justify the level of effort for ad-hoc use cases because of the poor hand off from Java --> Bash. And since AWS CLI is only available via Bash/CMD, I'm stuck with a bunch of not-good choices.\n\n---\n\nCLI Scripting in Java is great, but I wanted to highlight this pain point to spread awareness.\n\nCan you relate?",
    "created_utc": 1744428759.0,
    "url": "https://www.reddit.com/r/java/comments/1jx87ys/a_pain_point_when_using_java_to_do_cli_scripting/",
    "score": 53,
    "num_comments": 77
  },
  {
    "subreddit": "java",
    "title": "Java Records Break Backward Compatibility",
    "text": "While widely adopting records, I found a problem: record constructor is not backward-compatible.\n\nFor example, I have a `record User(String name, int age) {}`, and there are 20 different places calling `new User(\"foo\", 0)`. Once I add a new field like `record User(String name, int age, List<String> hobbies) {}`, it breaks all existing constructor calls. If `User` resides in a library, upgrading that library will cause code to fail compilation.\n\nThis problem does not occur in Kotlin or Scala, thanks to default parameter values:\n\n    // Java\n    public class Main {\n        public static void main(String[] args) {\n            // ======= before =======\n            // record User(String name, int age) { }\n            // System.out.println(new User(\"Jackson\", 20));\n    \n            // ======= after =======\n            record User(String name, int age, List<String> hobbies) { }\n            System.out.println(new User(\"Jackson\", 20)); // \u274c\n            System.out.println(new User(\"Jackson\", 20, List.of(\"Java\"))); // \u2714\ufe0f\n        }\n    }\n    \n    // Kotlin\n    fun main() {\n        // ======= before =======\n        // data class User(val name: String, val age: Int)\n        // println(User(\"Jackson\", 20))\n    \n        // ======= after =======\n        data class User(val name: String, val age: Int, val hobbies: List<String> = listOf())\n    \n        println(User(\"Jackson\", 20)) // \u2714\ufe0f\n        println(User(\"Jackson\", 20, listOf(\"Java\"))) // \u2714\ufe0f\n    }\n    \n    // Scala\n    object Main extends App {\n      // ======= before =======\n      // case class User(name: String, age: Int)\n      // println(User(\"Jackson\", 20))\n    \n      // ======= after =======\n      case class User(name: String, age: Int, hobbies: List[String] = List())\n    \n      println(User(\"Jackson\", 20)) // \u2714\ufe0f\n      println(User(\"Jackson\", 20, List(\"Java\"))) // \u2714\ufe0f\n    }\n\nTo mitigate this issue in Java, we are forced to use builders, factory methods, or overloaded constructors. However, in practice, we\u2019ve found that developers strongly prefer a unified object creation approach. Factory methods and constructor overloading introduce inconsistencies and reduce code clarity. As a result, our team has standardized on using builders \u2014 specifically, Lombok\u2019s \\\\@Builder(toBuilder = true) \u2014 to enforce consistency and maintain backward compatibility.\n\nWhile there are libraries(lombok/record-builder) that attempt to address this, nothing matches the simplicity and elegance of built-in support.\n\nUltimately, the root cause of this problem lies in Java\u2019s lack of named parameters and default values. These features are commonplace in many modern languages and are critical for building APIs that evolve gracefully over time.\n\nSo the question remains: What is truly preventing Java from adopting named and default parameters?",
    "created_utc": 1744298562.0,
    "url": "https://www.reddit.com/r/java/comments/1jw0jun/java_records_break_backward_compatibility/",
    "score": 0,
    "num_comments": 28
  },
  {
    "subreddit": "java",
    "title": "How do you generally decrease off-heap memory?",
    "text": "**Background**\n\nMy company is moving from running on VMs to running on containers in Kubernetes. We run one application on Tomcat in a single container. On VMs, it needed about 1.2GB memory to run fine (edit: VM had a lot of memory, -Xmx was set to 1.2GB). It is a monolith, and that is not going to change anytime soon (sadly).\n\nWhen moving to containers, we found that we needed to give the containers MUCH more memory. More than double. We run out of memory (after some time) until we gave the pods 3.2GB. It surprised us that it was so much more than we used to need.\n\n**Off-heap memory**\n\nIt turns out that, besides the 1.2GB on-heap, we needed about another 1.3GB of off-heap memory. We use the native memory tracking to figure out how much was used (with -XX:NativeMemoryTracking=summary). We are already using jemalloc, which seemed to be a solution for many people online.\n\nIt turns out that we need 200MB for code cache, 210MB for metaspace, 300MB unreported and the rest a little smaller. Also very interesting is that spacse like \"Arena Chunk\" and \"Compiler\" could peak to 300MB. If that happened at the same time, it would need an additional 600MB. That is a big spike.\n\nSidenote: this doesn't seem to be related to moving to containers. Our VMs just had enough memory to spare for this to not be an issue.\n\n**What to do?**\n\nI don't know how we can actually improve something like this or how to analysis what the \"problem\" really is (if there even is one). Colleagues are only able to suggest improvements that reduce the on-heap memory (like a Redis cache for retrieved data from the database) which I think does not impact off-heap memory at all. However, I actually have no alternatives that I can suggest to actually reduce this. Java just seems to need it.\n\nDoes anybody have a good idea on how to reduce memory usage of Java? Or maybe some resources which I can use to educate myself to find a solution?",
    "created_utc": 1744289568.0,
    "url": "https://www.reddit.com/r/java/comments/1jvx5ob/how_do_you_generally_decrease_offheap_memory/",
    "score": 140,
    "num_comments": 50
  },
  {
    "subreddit": "java",
    "title": "Spring security vs JWT",
    "text": "Hey!\nI\u2019m working on a project that uses Angular for the frontend and Spring Boot for the backend, and I\u2019ve got a question that someone with more experience might be able to help with.\nIt\u2019s about security \u2014 I\u2019ve seen a bunch of tutorials showing how to use JWT stored in cookies with Spring Boot, but I was wondering if it\u2019d be better to just use @EnableWebSecurity and let Spring Boot handle sessions with cookies by itself? Or is it still better to go with JWT in cookies?",
    "created_utc": 1744058326.0,
    "url": "https://www.reddit.com/r/java/comments/1jtvob8/spring_security_vs_jwt/",
    "score": 36,
    "num_comments": 15
  },
  {
    "subreddit": "java",
    "title": "AOT-linking classes in JDK24 not supported with module access JVM arguments?",
    "text": "We are just starting out with porting our application over to 24, and we're also looking into project Leyden. I have used [https://openjdk.org/jeps/483](https://openjdk.org/jeps/483) as a reference for setting up the aot cache.\n\nIt works, but the -Xlog:cds output when the application starts tells me that there are no aot-linked classes. The AOT cache generation also warns that optimized module handling is disabled due to there being JVM arguments to allow reflection, stuff like --add-opens and --add-exports. When removing all --add-opens and --add-exports arguments from our application, the aot cache successfully links the classes as well.\n\nIf I see this correctly, an application can't use the new aot class linking features if any JVM arguments for module access are passed? Doesn't that exclude basically any real-world application that has to use these arguments to allow for some external reflection access? I haven't seen a larger application ever be able to live without some degree of external reflection access and --add-opens arguments to allow this. ",
    "created_utc": 1744029315.0,
    "url": "https://www.reddit.com/r/java/comments/1jtk60f/aotlinking_classes_in_jdk24_not_supported_with/",
    "score": 8,
    "num_comments": 29
  },
  {
    "subreddit": "cpp_questions",
    "title": "Using SFML 3.0 via vcpkg \u2014 Debug or Release DLLs?",
    "text": " guys thank you so much, my sfml is finally working!, using vcpkg and in vs code no less consume my so much time but i think it was worth learning cmake,json and .dll files,i just wanted to say thank you to the people  who helped me here, \n\n  \nfor some reason vcpkg only gave me Release dlls, so i just wanted to know if should i get Debug dlls too? does anything works or one is better than other?\n\n  \nI don\u2019t know if this is true but it\u2019s kinda dumb that vcpkg by default gives release dlls and cmake uses by default debug dlls?\n\n\n\nOkay i was wrong, vcpkg gave all the dlls needed but by default i used debug commands and cmake by default used release dlls\n\nI have got no reply but I\u2019m still writing it here that i was absolutely wrong again, i just didn\u2019t copied dlls correctly ",
    "created_utc": 1746516522.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kfymjp/using_sfml_30_via_vcpkg_debug_or_release_dlls/",
    "score": 2,
    "num_comments": 0
  },
  {
    "subreddit": "cpp_questions",
    "title": "A book that changed how I approach memory in C++",
    "text": "I recently had the chance to work closely with Patrice Roy \u2014 some of you might already know him from his talks or teaching \u2014 and during that time, I got to explore his book ***C++ Memory Management*** more thoroughly.\n\nWhat stood out to me wasn\u2019t just the technical depth (which is excellent), but how clearly he explains the trade-offs behind different strategies. It\u2019s not just about \"use smart pointers\" \u2014 he goes deeper into allocators, ownership models, custom memory handling, and the kind of thinking that helps when you're building performance-critical systems.\n\nIf you\u2019re at that point in your C++ journey where you want to go beyond language syntax and really understand how memory behavior affects design, it\u2019s a solid read. I took away a few patterns I hadn't used before and it's definitely shifted how I think about lifetime management.\n\nJust wanted to share in case anyone else is diving into this side of C++ \u2014 happy to chat more if you\u2019ve read it or have other good reads in the same space.",
    "created_utc": 1746513240.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kfxvap/a_book_that_changed_how_i_approach_memory_in_c/",
    "score": 63,
    "num_comments": 4
  },
  {
    "subreddit": "cpp_questions",
    "title": "Any help is appreciated",
    "text": "the truth I installed reditt just for this, I am relatively new in the world of programming, but I really want to learn, what I could learn about c++ so far has hooked me deeply, I am willing to do anything to learn more, this is going to sound like selling my soul but I can work for free if that guarantees me to learn, please any recommendation or help of what I can do or where I can look for more help is useful to me. \n",
    "created_utc": 1746488001.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kfqbmw/any_help_is_appreciated/",
    "score": 0,
    "num_comments": 2
  },
  {
    "subreddit": "cpp_questions",
    "title": "Are module partition implementations toolchain/build system dependent?",
    "text": "Hi, I have been following [this](https://learn.microsoft.com/en-us/cpp/cpp/tutorial-named-modules-cpp?view=msvc-170) guide from Microsoft on using named modules in C++. Specifically the part under `Create a module unit implementation file` where they suggest that you should create a regular .cpp file that includes the line `module BasicPlane.Figures:Rectangle;` Note: the inclusion of the module partition in the implementation file.\n\nBut I don't use Visual Studio so I have been trying to get the same setup in CLion with CMake. But no matter what I do I can't get the module implementation file to compile when using explicitly marking it as a partition. It works if I simply use `module BasicPlane.Figures` and it doesn't even pull in other classes/functions from other partitions like I would expect it to without the partition specifier. \n\nIs this something that is dependent on the build system/toolchain? I've been using CMake with Ninja (although still using MSVC as a toolchain)",
    "created_utc": 1746482041.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kfo4n0/are_module_partition_implementations/",
    "score": 0,
    "num_comments": 1
  },
  {
    "subreddit": "cpp_questions",
    "title": "NEED A HELP FROM THE C++ PROGRAMMERS",
    "text": "well listen, The task was:\n\nImplement a window application that will perform the following functions:\n\n1. Accepts text and saves it in two text files (1 - original, 2 - copy with the corresponding copy)\n2. Copies the selected file and creates a copy of it in the same folder with the name Doc\\_copy\n\nI have a problem with realizing what my second button does, so it should've created a copy of my file.txt and be named as \"Doc\\_copy\", but it doesn't work that way(it just doesn't) first button actually works and does what I need (creates fie.txt with the text I wrote and the copy of it), here is my code:\n\n    #include <windows.h>\n    #include <commdlg.h>\n    #include <fstream>\n    #include <string>\n    LRESULT CALLBACK WindowProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam);\n    void SaveTextToFile(const std::string& original, const std::string& copy);\n    void CopyFileWithRename(const std::string& filename);\n    std::string OpenFileDialog(HWND hwnd);\n    int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE, LPSTR, int nShowCmd) {\n    const char CLASS_NAME[] = \"Sample Window Class\";\n    WNDCLASS wc = {};\n    wc.lpfnWndProc = WindowProc;\n    wc.hInstance = hInstance;\n    wc.lpszClassName = CLASS_NAME;\n    RegisterClass(&wc);\n    HWND hwnd = CreateWindowEx(0, CLASS_NAME, \"File Management App\", WS_OVERLAPPEDWINDOW, CW_USEDEFAULT, CW_USEDEFAULT, 400, 300, NULL, NULL, hInstance, NULL);\n    ShowWindow(hwnd, nShowCmd);\n    MSG msg;\n    while (GetMessage(&msg, NULL, 0, 0)) {\n    TranslateMessage(&msg);\n    DispatchMessage(&msg);\n    }\n    return 0;\n    }\n    LRESULT CALLBACK WindowProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam) {\n    static HWND hEdit;\n    switch (uMsg) {\n    case WM_CREATE:\n    hEdit = CreateWindowEx(0, \"EDIT\", \"\", WS_CHILD | WS_VISIBLE | WS_BORDER | ES_MULTILINE, 10, 10, 360, 200, hwnd, NULL, NULL, NULL);\n    CreateWindow(\"BUTTON\", \"Save\", WS_VISIBLE | WS_CHILD, 10, 220, 80, 30, hwnd, (HMENU)1, NULL, NULL);\n    CreateWindow(\"BUTTON\", \"Copy File\", WS_VISIBLE | WS_CHILD, 100, 220, 100, 30, hwnd, (HMENU)2, NULL, NULL);\n    break;\n    case WM_COMMAND:\n    if (LOWORD(wParam) == 1) {\n    char text[1024];\n    GetWindowTextA(hEdit, text, sizeof(text));\n    SaveTextToFile(text, text);\n    }\n    else if (LOWORD(wParam) == 2) {\n    std::string filename = OpenFileDialog(hwnd);\n    if (!filename.empty()) {\n    CopyFileWithRename(filename);\n    }\n    }\n    break;\n    case WM_DESTROY:\n    PostQuitMessage(0);\n    break;\n    default:\n    return DefWindowProc(hwnd, uMsg, wParam, lParam);\n    }\n    return 0;\n    }\n    void SaveTextToFile(const std::string& original, const std::string& copy) {\n    std::ofstream origFile(\"original.txt\");\n    origFile << original;\n    origFile.close();\n    std::ofstream copyFile(\"copy.txt\");\n    copyFile << copy;\n    copyFile.close();\n    }\n    void CopyFileWithRename(const std::string& filename) {\n    std::string newFile = filename.substr(0, filename.find_last_of(\"\\\\\")) + \"\\\\Doc_copy\" + filename.substr(filename.find_last_of(\".\"));\n    CopyFileA(filename.c_str(), newFile.c_str(), FALSE);\n    }\n    std::string OpenFileDialog(HWND hwnd) {\n    OPENFILENAME ofn;\n    char szFile[260];\n    ZeroMemory(&ofn, sizeof(ofn));\n    ofn.lStructSize = sizeof(ofn);\n    ofn.hwndOwner = hwnd;\n    ofn.lpstrFile = szFile;\n    ofn.lpstrFile[0] = '\\0';\n    ofn.lpstrFilter = \"All Files\\0*.*\\0Text Files\\0*.TXT\\0\";\n    ofn.nMaxFile = sizeof(szFile);\n    ofn.lpstrTitle = \"Select a file\";\n    ofn.Flags = OFN_PATHMUSTEXIST | OFN_FILEMUSTEXIST;\n    if (GetOpenFileName(&ofn)) {\n    return std::string(ofn.lpstrFile);\n    }\n    return std::string();\n    }\n\nI KNOW IT'S BAD, I'M JUST LEARNING, PLS DON'T EAT ME\n\n\n\n  \nP.S. I made it work finally, thanks everyone for help!",
    "created_utc": 1746480009.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kfnbjq/need_a_help_from_the_c_programmers/",
    "score": 0,
    "num_comments": 5
  },
  {
    "subreddit": "cpp_questions",
    "title": "Unnamed class (struct) is apparently TU-local? Can someone please point me to where I can read more about this?",
    "text": "I just received an update to GCC from 14 to 15 and finally tried it on my modular project. I got:\n\n    /home/greg/projects/cpp/asmdiff/src/cadjit/options.xx:27:3: error: \u2018cadjit::options\u2019 exposes TU-local entity \u2018struct cadjit::<unnamed>\u2019\n       27 | } options {\n          |   ^~~~~~~\n    /home/greg/projects/cpp/asmdiff/src/cadjit/options.xx:25:28: note: \u2018cadjit::<unnamed struct>\u2019 has no name and is not defined within a class, function, or initializer\n       25 | export inline const struct {\n          |                            ^\n\non the following code:\n\n    export inline const struct {\n        int debug;\n    } options {\n        .debug = parse_env_int(\"CADJIT_DEBUG\"),\n    }; // <-- options\n\nApparently the type of the \\`options\\` variable (nevermind that I put it in a variable instead of a namespace for some reason) is treated as local to the translation unit (as if it was inside of an anonymous namespace?)\n\nCan someone please point me to where it is required by the standard? Or maybe a cppreference page? I've looked in both the standard and cppreference on the topic of unnamed classes and didn't find it. Have I looked over the answer, or is it just a quirk of GCC's implementation not required by the language?",
    "created_utc": 1746465557.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kfh8rf/unnamed_class_struct_is_apparently_tulocal_can/",
    "score": 6,
    "num_comments": 11
  },
  {
    "subreddit": "cpp_questions",
    "title": "Help me confirm a bug with GCC 15 std::expected",
    "text": "Does this work for you on your machine? It compiles in GCC 14.2 for me, but not 15.1?\n\n    #include <cstdio>\n    #include <map>\n    #include <expected>\n    #include <system_error>\n\n    template <class T>\n    struct Value {\n      int v;\n    };\n\n    int main() {\n      std::map<int, Value<void(std::expected<int, std::error_condition>)>> m;\n\n      auto it = m.find(3);\n\n      if (it == m.end()) {\n        printf(\"Not there!\\n\");\n      }\n    }\n\nCompiler flags: '-O3 -std=c++23`",
    "created_utc": 1746463960.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kfgk7a/help_me_confirm_a_bug_with_gcc_15_stdexpected/",
    "score": 14,
    "num_comments": 9
  },
  {
    "subreddit": "cpp_questions",
    "title": "need help, cannot use C++ <string> library",
    "text": "so I've been having this problem for quite sometime now. Whenever I code and I use a string variable in that code, it messes up the whole code. And this happens on EVERY code editor I use (vscode, codeblocks, sublime text)\n\nfor example:\n\n    #include <iostream>\n    #include <string>\n    #include <iomanip>\n    \n    int main() {\n    \u00a0 \u00a0 double name2 = 3.12656756765;\n    \n    \n    \u00a0 \u00a0 std::cout << std::setprecision(4) << name2;\n    \n    \n    \u00a0 \u00a0 return 0;\n    }\n    \n\nthis works just fine, the double got output-ed just fine. But when I add a declaration of string,\n\n    #include <iostream>\n    #include <string>\n    #include <iomanip>\n    \n    int main() {\n    \u00a0 \u00a0 double name2 = 3.12656756765;\n    \u00a0 \u00a0 std::string name3 = \"Hello\";\n    \n    \u00a0 \u00a0 std::cout << std::setprecision(4) << name2 << name3;\n    \n    \n    \u00a0 \u00a0 return 0;\n    }\n    \n\nthe code messes up entirely. The double doesn't get output-ed, and neither the string.\n\nThe thing is, if I run the same code at an online compiler like onlineGDB, it works perfectly fine.\n\n  \nAs you can see, I've also use other libraries like <iomanip> and a few more and they work just fine, so it really only has a problem with the string or the string library.\n\n  \nI have reinstalled my code editors, my gcc and clang compiler, and still to no avail.\n\n  \nAny suggestions, please?",
    "created_utc": 1746453839.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kfcf48/need_help_cannot_use_c_string_library/",
    "score": 3,
    "num_comments": 34
  },
  {
    "subreddit": "cpp_questions",
    "title": "I\u2019m so done with sfml installation process",
    "text": "I couldn\u2019t make it work even after wasting three days, people keep saying read documentation but there were process which weren\u2019t mentioned in them and i kept running into errors( people might disagree but chatgpt helped in that, because I didn\u2019t knew i had 2 compilers and sfml-compatible compiler was being not used and therefore couldn\u2019t search it up on google) \n\nSomehow i kept running into errors and errors, which had no solution in documentation and i got no one to ask to so had to ask AI ,i think it\u2019s wrong but i had no choice\n\nI\u2019ve already made post here before and i did apply dll links too but that doesn\u2019t seem to work either and there\u2019s no error either, the program just terminates, I don\u2019t what to do now\n\nSOURCE OF THE PROBLEM:MSYS2",
    "created_utc": 1746433585.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kf6il0/im_so_done_with_sfml_installation_process/",
    "score": 0,
    "num_comments": 49
  },
  {
    "subreddit": "cpp_questions",
    "title": "sfml window won't open??pls help",
    "text": "\ncode:\n\n   // library\n\n    #include <SFML/Graphics.hpp>\n\n\n// main program\n\n\nint main()\n\n{\n    // create window\n\n\n        sf::RenderWindow window(sf::VideoMode({800, 600}), \"Title\");\n\n    // while window is still open\n    while (window.isOpen())\n    {\n        // handle events\n        while (std::optional event = window.pollEvent())\n        {\n            // when close button is clicked\n            if (event->is<sf::Event::Closed>())\n            {\n                // close window\n                window.close();\n            }\n        }\n\n        // fill window with color\n        window.clear(sf::Color(127, 127, 127));\n\n        // display\n        window.display();\n    }\n\n    \n    // program end successfully\n    return 0;\n}\n\n\n    \n\nterminal: \n\nPS C:\\\\Users\\\\Dell\\\\Desktop\\\\SFML1> cmake --build build\n\n\\[ 50%\\] Building CXX object CMakeFiles/tutorial1.dir/main.cpp.obj\n\n\\[100%\\] Linking CXX executable tutorial1.exe\n\n\\[100%\\] Built target tutorial1\n\nPS C:\\\\Users\\\\Dell\\\\Desktop\\\\SFML1> cd build       \n\nPS C:\\\\Users\\\\Dell\\\\Desktop\\\\SFML1\\\\build> .\\\\tutorial1.exe\n\nPS C:\\\\Users\\\\Dell\\\\Desktop\\\\SFML1\\\\build> \n\n  \ncmake txt : \n\n    cmake_minimum_required(VERSION 3.20)\n    \n    project(MyExecutableWithVcpkg CXX)\n    \n    add_executable(tutorial1 main.cpp) \u00a0# Add all source files here\n    \n    # Compiler options and C++ standard\n    target_compile_options(tutorial1 PRIVATE -Wall -Wextra -Werror)\n    target_compile_features(tutorial1 PUBLIC cxx_std_17)\n    set_target_properties(tutorial1 PROPERTIES CXX_EXTENSIONS OFF)\n    set(SFML_DIR \"C:/Users/Dell/Desktop/SFML/vcpkg/installed/x64-mingw-dynamic/share/sfml\")\n    # Find SFML 3 and link required components\n    find_package(SFML 3 REQUIRED COMPONENTS Graphics Window System)\n    \n    # Link the found SFML components\n    target_link_libraries(tutorial1 PRIVATE SFML::Graphics SFML::Window SFML::System)\n    \n    \n    i'm using sfml 3.0 via vcpkg, like i get no response at all no matter what code sf::RenderWindow window(sf::VideoMode({800,     600}), \"Title\");\n\n    // while window is still open\n    while (window.isOpen())\n    {\n        // handle events\n        while (std::optional event = window.pollEvent())\n        {\n            // when close button is clicked\n            if (event->is<sf::Event::Closed>())\n            {\n                // close window\n                window.close();\n            }\n        }\n\n        // fill window with color\n        window.clear(sf::Color(127, 127, 127));\n\n        // display\n        window.display();\n    }\n\n    \n    // program end successfully\n    return 0;\n}\n\n\n    \n\nterminal: \n\nPS C:\\\\Users\\\\Dell\\\\Desktop\\\\SFML1> cmake --build build\n\n\\[ 50%\\] Building CXX object CMakeFiles/tutorial1.dir/main.cpp.obj\n\n\\[100%\\] Linking CXX executable tutorial1.exe\n\n\\[100%\\] Built target tutorial1\n\nPS C:\\\\Users\\\\Dell\\\\Desktop\\\\SFML1> cd build       \n\nPS C:\\\\Users\\\\Dell\\\\Desktop\\\\SFML1\\\\build> .\\\\tutorial1.exe\n\nPS C:\\\\Users\\\\Dell\\\\Desktop\\\\SFML1\\\\build> \n\n  \ncmake txt : \n\n    cmake_minimum_required(VERSION 3.20)\n    \n    project(MyExecutableWithVcpkg CXX)\n    \n    add_executable(tutorial1 main.cpp) \u00a0# Add all source files here\n    \n    # Compiler options and C++ standard\n    target_compile_options(tutorial1 PRIVATE -Wall -Wextra -Werror)\n    target_compile_features(tutorial1 PUBLIC cxx_std_17)\n    set_target_properties(tutorial1 PROPERTIES CXX_EXTENSIONS OFF)\n    set(SFML_DIR \"C:/Users/Dell/Desktop/SFML/vcpkg/installed/x64-mingw-dynamic/share/sfml\")\n    # Find SFML 3 and link required components\n    find_package(SFML 3 REQUIRED COMPONENTS Graphics Window System)\n    \n    # Link the found SFML components\n    target_link_libraries(tutorial1 PRIVATE SFML::Graphics SFML::Window SFML::System)\n    \n    \n    i'm using sfml 3.0 via vcpkg, like i get no response at all no matter what code\n\n// main program\nint main()\n{\n    // create window\n    sf::RenderWindow window(sf::VideoMode({800, 600}), \"Title\");\n\n    // while window is still open\n    while (window.isOpen())\n    {\n        // handle events\n        while (std::optional event = window.pollEvent())\n        {\n            // when close button is clicked\n            if (event->is<sf::Event::Closed>())\n            {\n                // close window\n                window.close();\n            }\n        }\n\n        // fill window with color\n        window.clear(sf::Color(127, 127, 127));\n\n        // display\n        window.display();\n    }\n\n    \n    // program end successfully\n    return 0;\n}\n\n\n    \n\nterminal: \n\nPS C:\\\\Users\\\\Dell\\\\Desktop\\\\SFML1> cmake --build build\n\n\\[ 50%\\] Building CXX object CMakeFiles/tutorial1.dir/main.cpp.obj\n\n\\[100%\\] Linking CXX executable tutorial1.exe\n\n\\[100%\\] Built target tutorial1\n\nPS C:\\\\Users\\\\Dell\\\\Desktop\\\\SFML1> cd build       \n\nPS C:\\\\Users\\\\Dell\\\\Desktop\\\\SFML1\\\\build> .\\\\tutorial1.exe\n\nPS C:\\\\Users\\\\Dell\\\\Desktop\\\\SFML1\\\\build> \n\n  \ncmake txt : \n\n    cmake_minimum_required(VERSION 3.20)\n    \n    project(MyExecutableWithVcpkg CXX)\n    \n    add_executable(tutorial1 main.cpp) \u00a0# Add all source files here\n    \n    # Compiler options and C++ standard\n    target_compile_options(tutorial1 PRIVATE -Wall -Wextra -Werror)\n    target_compile_features(tutorial1 PUBLIC cxx_std_17)\n    set_target_properties(tutorial1 PROPERTIES CXX_EXTENSIONS OFF)\n    set(SFML_DIR \"C:/Users/Dell/Desktop/SFML/vcpkg/installed/x64-mingw-dynamic/share/sfml\")\n    # Find SFML 3 and link required components\n    find_package(SFML 3 REQUIRED COMPONENTS Graphics Window System)\n    \n    # Link the found SFML components\n    target_link_libraries(tutorial1 PRIVATE SFML::Graphics SFML::Window SFML::System)\n    \n    \n    i'm using sfml 3.0 via vcpkg, like i get no response at all no matter what code",
    "created_utc": 1746375585.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kenoqn/sfml_window_wont_openpls_help/",
    "score": 0,
    "num_comments": 9
  },
  {
    "subreddit": "cpp_questions",
    "title": "[Probably Repeated question] How do I delete an item from a list while iterating over it",
    "text": "So I'm trying to improve my coding skills/knowledge by writing a small game using raylib, so I'm at the point where I want to delete bullets the moment they hit an enemy using the (list).remove(bullet) instruction, but at the next iteration, the for loop tries to access the next item (but, since it has been deleted, it's an invalid address and obviously I get a segmentation fault).\n\nSo the first attempt at fixing it, was to check whether the list is empty and (if true) break the loop, but the problem persists the moment there is more than one bullet and that tells me that not only I'm trying to access an invalid item, I'm \\*specifically\\* trying to access the one item (bullet) I've just deleted.\n\nNow I am at a stall, cause I don't know how to guarantee that the next iteration will pick up the correct item (bullet).\n\nFor clarity I'll post the code:\n\n     //I'm in a bigger for loop inside a class that holds the Game State\n     //e is the enemy that I'm looking at in a specific iteration\n     //plr is the player object\n     if(!plr->getActorPtr()->bList.empty()){ \n     //plr is a class which olds an Actor object \n          for(Bullet* b: plr->getActorPtr()->bList){ //bList is the Actor's List of bullets\n    \u00a0 \u00a0 \u00a0     if(CheckCollisionRecs(b->getCollider(), e->getActorPtr()->getRectangle())){\n    \u00a0 \u00a0\u00a0 \u00a0 \u00a0 \u00a0  e->getHit(*b); \n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 if(e->getActorPtr()->getHP() <= 0.0f) {\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 delEnemy(e);\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 b->setIsDestroyed(); //This sets just a flag, may be useless\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 plr->getActorPtr()->bList.remove(b); //I remove the bullet from the List\n                //By what I can read, it should also delete the object pointed to\n                //and resize the List accordingly\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n    \u00a0 \u00a0 \u00a0 }\n    \u00a0} \u00a0 \u00a0 \u00a0 \n\nI hope that I commented my code in a way that makes it clearer to read and, hopefully, easier to get where the bug is, but let me know if you need more information\n\nNote: I would prefer more to learn where my knowledge/understanding is lacking, rather than a quick solution to the problem at hand, if possible of course. Thank you all for reading and possibly replying",
    "created_utc": 1746355222.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kegvy5/probably_repeated_question_how_do_i_delete_an/",
    "score": 2,
    "num_comments": 48
  },
  {
    "subreddit": "cpp_questions",
    "title": "How to Set Up Raylibn or Other library in VSCode for C++",
    "text": "I'm a beginner learning C++ and I'm trying to set up Raylib (or any external library) in VSCode on Windows 10. I'm using MSYS2 MinGW-w64 as my compiler.\nI have watched lots of Tutorials None of them really  worked. Every time I do according to the Tutorial from YT VSCode shows ''No such file or Library found\". Idk what to do, can any one please help how to complie Raylib or similar Library like SFML and run a Program. \n(I'm sorry if my english is not good, It's not my Native language and I'm working on it) ",
    "created_utc": 1746350353.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kefpj3/how_to_set_up_raylibn_or_other_library_in_vscode/",
    "score": 2,
    "num_comments": 6
  },
  {
    "subreddit": "cpp_questions",
    "title": "Help me understand \"stack\" vs \"heap\" concept",
    "text": "Every time I try to learn about the \"stack vs heap\" concept I keep hearing the same nonsense:\n\n\"In stack there are only two options: push and pop. You can't access anything in between or from an arbitrary place\".\n\nBut this is not true! I can access anything from the stack: \"mov eax,\\[esp+13\\]\". Why do they keep saying that?",
    "created_utc": 1746350139.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kefnqm/help_me_understand_stack_vs_heap_concept/",
    "score": 0,
    "num_comments": 56
  },
  {
    "subreddit": "cpp_questions",
    "title": "Why doesn't the switch statement allow me to use a struct value?",
    "text": "I'm trying to combine a strategy pattern with a state machine so that I can have the input layout for a specific player and use that information to assign the correct keys to their associated input. However, for whatever reason it won't let me use it's data for the switch statement because:\n\n\"C++ expression must have a constant value, attempt to access run-time storage\"\n\nI've made everything related to the values constant yet I still have the issue. What's causing this error and is there a way I can fix it? If so, how do I fix it?\n\n[https://pastebin.com/QLEter3x](https://pastebin.com/QLEter3x) (Error is on line 161)",
    "created_utc": 1746348569.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kefag9/why_doesnt_the_switch_statement_allow_me_to_use_a/",
    "score": 5,
    "num_comments": 10
  },
  {
    "subreddit": "cpp_questions",
    "title": "cpp as a complete beginner guide",
    "text": "**help**\n\nso i just passed out of high school and i want to start cpp (i know that python is beginner friendly but still i want to start from cpp) and i am very confused on what channels or sites or books to follow i have **some websites** saved like\n\n  \n[Learn C++ \u2013 Skill up with our free tutorials](https://www.learncpp.com/)\n\n[cppreference.com](https://en.cppreference.com/w/)\n\n**or yt channels like**\n\n[ChiliTomatoNoodle](https://www.youtube.com/@ChiliTomatoNoodle)\n\n[ @derekbanas\u2022  ](https://www.youtube.com/@ChiliTomatoNoodle)\n\n[@CopperSpice\u2022](https://www.youtube.com/@ChiliTomatoNoodle)\n\n\\[@CodeForYourself\u2022\n\ncppweekly                     \n\n[@MikeShah\u2022](https://www.youtube.com/@ChiliTomatoNoodle)\n\nCppCon\n\nTheCherno\n\n*i dont know where to start* or which one would be better for me ",
    "created_utc": 1746338699.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kecyey/cpp_as_a_complete_beginner_guide/",
    "score": 7,
    "num_comments": 11
  },
  {
    "subreddit": "cpp_questions",
    "title": "i don't know what to do(sfml linking in cmake)",
    "text": "my txt file \n\n    cmake_minimum_required(VERSION 3.10)\n    project(tutorial1 VERSION 0.1.0 LANGUAGES CXX)\n    \n    # Set C++ standard\n    set(CMAKE_CXX_STANDARD 17)\n    set(CMAKE_CXX_STANDARD_REQUIRED ON)\n    \n    # Add your executable\n    add_executable(tutorial1 main.cpp)\n    set(SFML_DIR \"C:/Users/Dell/Desktop/SFML/vcpkg/installed/x64-mingw-dynamic/share/sfml\")\n    \n    # Find SFML (this works because your toolchain file is set in settings.json)\n    find_package(SFML 3 COMPONENTS graphics window system REQUIRED)\n    \n    # Link SFML to your executable\n    target_link_libraries(tutorial1 PRIVATE sfml-graphics sfml-window sfml-system)\n    \n    \n    ERROR : CMake Error at CMakeLists.txt:13 (find_package):Found package configuration file:\n    \n      C:/Users/Dell/Desktop/SFML/vcpkg/installed/x64-mingw-dynamic/share/sfml/SFMLConfig.cmake\n    \n    but it set SFML_FOUND to FALSE so package \"SFML\" is considered to be NOT\n    FOUND.  Reason given by package:\n    \n    Unsupported SFML component: graphicsCMake (find_package)\n\nbut i already installed it using -->vcpkg install sfml:x64-mingw-dynamic\n\n  \nand added this in settings.json - \n\n    \u00a0\"cmake.configureSettings\": {\n    \u00a0 \u00a0 \"CMAKE_TOOLCHAIN_FILE\": \"C:/Users/Dell/Desktop/SFML/vcpkg/scripts/buildsystems/vcpkg.cmake\",\n    }\n    \n    \n    i'm trying to use sfml  from since 12 hours please help, thanks",
    "created_utc": 1746337698.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kecpks/i_dont_know_what_to_dosfml_linking_in_cmake/",
    "score": 1,
    "num_comments": 7
  },
  {
    "subreddit": "cpp_questions",
    "title": "please help to download sfml",
    "text": "on thier website CC 14.2.0 MinGW (DW2) (UCRT) -\u00a0[Download | 35 MB](https://www.sfml-dev.org/files/SFML-3.0.0-windows-gcc-14.2.0-mingw-32-bit.zip),\n\nbut mine compiler is gcc (Rev1, Built by MSYS2 project) 15.1.0, so will it not for my compiler? what should i do",
    "created_utc": 1746289114.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kdwpmq/please_help_to_download_sfml/",
    "score": 0,
    "num_comments": 16
  },
  {
    "subreddit": "cpp_questions",
    "title": "cin giving unusual outputs after failbit error",
    "text": "    #include <bits/stdc++.h>\n    using namespace std; \n    \n    int main() { \n    \tint a;\n    \tint b;\n    \tcout << \"\\nenter a: \";\n    \tcin >> a;\n    \tcout << \"enter b: \";\n    \tcin >> b;\n    \tcout << \"\\na = \" << a << '\\n';\n    \tcout << \"b = \" << b << '\\n';\n    }\n\nthe above code gives this output on my PC (win 10,g++ version 15.1.0):\n\n    enter a: - 5\n    enter b: \n    a = 0    \n    b = 8    \n    \n\nsince \"-\" isn't a number the \\`>>\\` operator assigns \\`0\\` to \\`a\\` which makes sense. but isn't \" 5\" supposed to remain in the input buffer causing \\`>>\\` to assign the value \\`5\\` to \\`b\\`? why is b=8?\n\nI thought that maybe different errors had different numbers and that maybe failbit error had a value of 3 (turns out there's only bool functions to check for errors) so I added some extra code to check which errors I had: \n\n    #include <bits/stdc++.h>\n    using namespace std; \n    \n    int main() { \n        int a;\n        int b;\n        cout << \"\\nenter a: \";\n        cin >> a;\n    \n        cout << \"good: \" << cin.good() << endl;\n        cout << \"fail: \" << cin.fail() << endl;\n        cout << \"eof: \" << cin.eof() << endl;\n        cout << \"bad: \" << cin.bad() << endl;\n    \n        cout << \"\\nenter b: \";\n        cin >> b;\n    \n        cout << \"\\ngood: \" << cin.good() << endl;\n        cout << \"fail: \" << cin.fail() << endl;\n        cout << \"eof: \" << cin.eof() << endl;\n    \n        cout << \"\\na = \" << a << '\\n';\n        cout << \"b = \" << b << '\\n';\n    }\n\nthe above code gives the output:\n\n    enter a: - 5\n    good: 0  \n    fail: 1  \n    eof: 0   \n    bad: 0   \n    \n    enter b: \n    good: 0  \n    fail: 1  \n    eof: 0   \n    \n    a = 0    \n    b = 69   \n\nadding: \\`cin.clear()\\` before \\`cin >> b\\` cause \\`b\\` to have a value \\`5\\` as expected. but why is the error and checking for the error changing the value of what's in the input buffer?\n\nI've only ever used python and JS and have only started C++ a few days ago, so I'm sorry if it's a dumb question.",
    "created_utc": 1746271793.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kdqt13/cin_giving_unusual_outputs_after_failbit_error/",
    "score": 1,
    "num_comments": 17
  },
  {
    "subreddit": "cpp_questions",
    "title": "Making an http server from scrach.",
    "text": "Hi everyone,\n\nI have to make a basic http server and eventually a simple web framework. So from my limited understanding related to these types of projects i will need understanding of TCP/IP(have taken a 2 networking class in uni), c++ socket programming, handling concurrent clients, and reading data from sockets. \n\nThere is one constraint which is i can't use any third party libraries. At first i only need a server that accepts a connection on a port, and respond to a request. I have about 6 months to complete full this.\n\nI was trying to find some resources, and maybe an roadmap or an outline. Anything can help guides, tutorials, docs.",
    "created_utc": 1746268481.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kdpy26/making_an_http_server_from_scrach/",
    "score": 24,
    "num_comments": 26
  },
  {
    "subreddit": "cpp_questions",
    "title": "Help with macro expansion order in C/C++",
    "text": "    #define STRIP_PARENS(...) __VA_ARGS__\n    \n    #define L(X) \\\n    \u00a0 \u00a0 X((a, b)) \\\n    \u00a0 \u00a0 X((c, d))\n    \n    #define FIRST(x, ...) x\n    #define FA_INNER(...) FIRST(__VA_ARGS__)\n    #define FA(x, ...) FA_INNER(x)\n    #define FAL(args) FA(STRIP_PARENS args)\n    L(FAL)\n    \n    #define EVAL0(...) __VA_ARGS__\n    #define EVAL1(...) EVAL0(EVAL0(EVAL0(__VA_ARGS__)))\n    #define EVAL(...) \u00a0EVAL1(EVAL1(EVAL1(__VA_ARGS__)))\n    #define STRIP_PARENS(...) __VA_ARGS__\n    #define FIRST(x, ...) x\n    #define FAL(x) EVAL(FIRST(EVAL(STRIP_PARENS x)))\n    L(FAL)\n\nFirst gives `a c`, second gives `a, b c, d`\n\nMeaning somehow the parentheses are not stripping off in second.\n\nBut manual expansion makes the two appear exactly same!\n\n    // second\n    FAL((a, b))\n    -> EVAL(FIRST(EVAL(STRIP_PARENS (a, b))))\n    -> EVAL(FIRST(EVAL(a, b))) # am I wrong to expand STRIP_PARENS here?\n    -> EVAL(FIRST(a, b))\n    -> EVAL(a)\n    -> a\n\n",
    "created_utc": 1746268346.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kdpwv7/help_with_macro_expansion_order_in_cc/",
    "score": 3,
    "num_comments": 6
  },
  {
    "subreddit": "cpp_questions",
    "title": "Why does clang++ work, but clang doesn't (linker errors, etc), if clang++ is a symlink to clang?",
    "text": "",
    "created_utc": 1746247058.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kdkqav/why_does_clang_work_but_clang_doesnt_linker/",
    "score": 5,
    "num_comments": 4
  },
  {
    "subreddit": "cpp_questions",
    "title": "A Reliable Method for Fuzzing Using Complex File Types",
    "text": "I'm creating a C++ tool that handles multiple types of document formats, some of which share similarities but with varying specs and internal structures.\n\nIn short, the functionality involves reading from, parsing, manipulating, retrieving specific data and writing to said document types.\n\nFrom what I know, fuzzing is an effective way to catch bugs and security issues and ensure the software's reliability and robustness, and I'd like to utilize it as one of the testing strategies.\n\nIf I understand correctly, and I might be wrong or missing something, fuzzing is commonly done with randomized inputs, such as numbers, strings, text files and JSON.\n\nIn my case, however, the input I need to test with is document files, which are more complex in nature, and I'm trying to think of a way to constantly and automatically find file samples to feed the program. The program could also take multiple files with different options as input, so that also needs to be taken into consideration.\n\nAnother thing that comes to mind is that it might be easier to generate randomized input to test the internal parts of the software, but I don't know if fuzzing would be appropriate for this.\n\nAny tips and/or resource recommendations are highly appreciated!",
    "created_utc": 1746228649.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kdf2es/a_reliable_method_for_fuzzing_using_complex_file/",
    "score": 4,
    "num_comments": 2
  },
  {
    "subreddit": "cpp_questions",
    "title": "Learning Unicode in C++ \u2014 but it\u2019s all Chinese to me",
    "text": "# The Situation\n\nSorry for the dad joke title, but Unicode with C++ makes about as much sense to me as Mandarin at this point. Maybe it's because I've been approaching this whole topic from the wrong perspective, but I will explain what I've learned so far and maybe someone can help me understand what I'm getting wrong.\n\nOkay so for starters I am not using Unicode to solve a specific problem, I just want to understand it more deeply with C++. Also I am learning this using C++23 so I have all features available up to that standard.\n\n# Unicode Characters (and Strings)\n\nI started learning characters first such as:\n\n* **char8\\_t** (for UTF-8 code unit) -- 'u8' prefix\n* **char16\\_t** (for UTF-16 code unit) -- 'u' prefix\n* **char32\\_t** (for UTF-32 code unit / code point) -- 'U' prefix\n* also **wchar\\_t** but that seems to be universally hated for portability restrictions) -- 'L' prefix\n\nEach of these character types can hold different sized characters, but the thing that is confusing for me is that if I were to try to print any of these character type values, it gives me cryptic errors because it expects UTF-8 as char\\* (I think?). So what is the purpose of any of these types if the goal is to print them? char32\\_t is the only one that seems to be useful for storing in general cause it can hold any Unicode code point, but again, it can't easily be printed without workarounds, so these types are only for various memory benefits? \n\nI'm also finding this with the Unicode string types such as u8string, u16string, and u32string which store the appropriate Unicode character types I mentioned above. Again, this can't be printed without workarounds.\n\nIs this just user error on my part? Were these types never meant to be used to store Unicode characters/strings for printing out easily? I see a lot more of chat16\\_t usage than char32\\_t for the surrogate pairs but I also hear that char32\\_t is the fastest to access (?).\n\n# What IS working for me:\n\nI mentioned I am on C++23, and that is mainly because of <print> giving std::println and std::print, which has completely replaced std::cout for any C++23 (or higher) code I write. These functions have certainly helped with handling Unicode, but it also can't handle any of these other UTF types above by default (WTF), but it still adds improvements over std::cout.\n\nIf I set any Unicode currently, I use std::string:\n\n    #include <print>\n    \n    int main() {\n      std::string earth{\"\ud83c\udf0e\"};\n      std::println(\"Hello, {}\", earth);\n      \n      // Or my favorite way (Unicode Name - C++23)\n      std::string earth_new{\"\\N{EARTH GLOBE AMERICAS}\"};\n      std::println(\"Hello, {}\", earth_new);\n    }\n\nThose are two examples of how I set Unicode with strings, but I also can directly set a char array. Otherwise, print/println lets me just use the Unicode characters as string literals as an argument:\n\n    std::println(\"Hello, {}\", \"\ud83c\udf0e\");\n\n\n\n# What isn't working for me\n\nWhat Isn't working for me is trying to figure out why these other UTF character and string types really exist and how they are actually used in a real codebase or for printing to the console. Also codecvt is one method I see a lot in older tutorials, and that is apparently deprecated so there are things like that which I keep coming across which makes learning Unicode much more annoying and complex. Anyone have any experience with this and why it's so hard to deal with?\n\nShould I just stick with std::string for pretty much any text/Unicode that needs to be printed and just make sure UTF-8 is set universally? ",
    "created_utc": 1746210901.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kd8b8w/learning_unicode_in_c_but_its_all_chinese_to_me/",
    "score": 11,
    "num_comments": 31
  },
  {
    "subreddit": "cpp_questions",
    "title": "Clangd not recognising C++ libraries",
    "text": "I tried to setup Clangd in VS Code and Neovim but it doesn't recognise the native C++ libraries. For example:\n\n    // Example program for show the clangd warnings\n    #include <iostream>\n    \n    int main() {\n      std::cout << \"Hello world\";\n      return 0;\n    }    \nIt prompts two problems:\n\n* \"iostream\" file not found\n* Use of undeclared identifier \"std\"\n\nDon't get me wrong, my projects compile well anyways, it even recognises libraries with CMake, but it's a huge downer to not having them visible with Clangd.\n\nI have tried to dig up the problem in the LLVM docs, Stack Overflow and Reddit posts, but I can't solve it. The solution I've seen recommended the most is passing a 'compile_commands.json' through Clangd using CMake, but doesn't work for me.\n\nAnd that leads me here. Do you guys can help with this?",
    "created_utc": 1746208252.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kd794y/clangd_not_recognising_c_libraries/",
    "score": 1,
    "num_comments": 19
  },
  {
    "subreddit": "cpp_questions",
    "title": "Tips on learning DirectX",
    "text": "Hi. I am a 16 year old teen who has been coding in c++ for 2 years. Recently, low level graphics api dev caught my eye, so I studied the mathematical prerequisites for it(took me bout 6 months to learn Linear Algebra head to toe). I know very little about graphics api dev in general. The furthest I went was initializing a swap chain buffer. I am stuck in the position where there are no clear tutorials and lessons on how to do things like there are for c++ for instance. Any help would be greatrly appreciated!",
    "created_utc": 1746205234.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kd616o/tips_on_learning_directx/",
    "score": 16,
    "num_comments": 9
  },
  {
    "subreddit": "cpp_questions",
    "title": "Seeking Recommendations for C++ Learning Resources for a Python Programmer",
    "text": "Hello everyone!\n\nI'm looking to expand my programming skills and dive into C++. I have a solid foundation in programming basics and am quite familiar with Python. I would love to hear your recommendations for the best resources to learn C++.\n\nAre there any specific books, online courses, or tutorials that you found particularly helpfull I'm open to various learning styles, so feel free to suggest what worked best for you.\n\nThank you in advance for your help! I'm excited to start this new journey and appreciate any",
    "created_utc": 1746193180.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kd17gf/seeking_recommendations_for_c_learning_resources/",
    "score": 6,
    "num_comments": 23
  },
  {
    "subreddit": "cpp_questions",
    "title": "Self taught engineer wanting better CS foundation. C or Cpp ?",
    "text": "Hello, Im a self-taught web developer with 4 YOE who was recently laid off. I always wanted to learn how computers work and have a better understanding of computer science fundamentals. So topics like:\n\n* Computer Architecture + OS\n* Algorithms + Theory\n* Networks + Databases\n* Security + Systems Design\n* Programming + Data Structures\n\nI thought that means, I should learn C to understand how computers work at a low level and then C++ when I want to learn data structures and algorithms. I dont want to just breeze through and use Python until I have a deep understanding of things.\n\nAny advice or clarification would be great.\n\nThank you.\n\n  \nEDIT:\n\nChatGPT says:  \n\n\n# \ud83e\udde0 Recommendation: Start with C, then jump to C++\n\n# Why:\n\n* C **forces you** to learn what a pointer *really* is, how the stack and heap work, how function calls are made at the assembly level, and how memory layout works \u2014 foundational if you want to understand OS, compilers, memory bugs, etc.\n* Once you have that grasp, **C++ gives you tools** to build more complex things, especially useful for practicing algorithms, data structures, or building systems like databases or simple compilers.\n\n",
    "created_utc": 1746181447.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kcxjlb/self_taught_engineer_wanting_better_cs_foundation/",
    "score": 12,
    "num_comments": 47
  },
  {
    "subreddit": "cpp_questions",
    "title": "alternatives for const arrays in struct",
    "text": "I was making a struct of constants, including arrays of chars.\n\nI learned about initializer lists to make a constructor for my struct (also discovered that structs are basically classes) but found that arrays can't be initialized in this way.\n\n#What is the best alternative to a read-only array in a struct?\n\n- Private variables and getters are gonna be a lot of unnecessary lines and kinda break the purpose of a simple data container.  \n- non-const variables with warning comments is not safe.\n\n(I am a beginner; I am not used to the standard namespace and safe/dynamic data types)",
    "created_utc": 1746137942.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kclbr2/alternatives_for_const_arrays_in_struct/",
    "score": 7,
    "num_comments": 18
  },
  {
    "subreddit": "cpp_questions",
    "title": "import std with gcc 15.1?",
    "text": "How can I successfully compile this hello world that imports module std with gcc 15.1?\n\n    import std;\n \n    int main() {\n        std::println(\"Hello, World\");\n\n        return 0;\n    }\n\n&nbsp;\n\n    gcc -std=c++23 -fmodules main.cpp\n    In module imported at main.cpp:1:1:\n    std: error: failed to read compiled module: No such file or directory\n    std: note: compiled module file is \u2018gcm.cache/std.gcm\u2019\n    std: note: imports must be built before being imported\n    std: fatal error: returning to the gate for a mechanical issue\n    compilation terminated.\n\n&nbsp;\n\n    gcc --version\n    gcc (GCC) 15.1.1 20250425 (Red Hat 15.1.1-1)\n    Copyright (C) 2025 Free Software Foundation, Inc.\n    This is free software; see the source for copying conditions.  There is NO\n    warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.",
    "created_utc": 1746125441.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kcggb4/import_std_with_gcc_151/",
    "score": 9,
    "num_comments": 19
  },
  {
    "subreddit": "cpp_questions",
    "title": "Struct Member Holding Wrong Value",
    "text": "So for practicing c++ I have decided to go with game hacking. Currently doing a simple tp hack.\n\nteleport.cpp\n\n    void tpLocation(Pcoords& pLoc, bool& tpFlag, uintptr_t moduleBase)\n    {\n      uintptr_t yCoordAddr = mem::FindDMAAddy(moduleBase + 0x012822F8, yCoordOffsets);\n      uintptr_t xCoordAddr = mem::FindDMAAddy(moduleBase + 0x012822F8, xCoordOffsets);\n      uintptr_t zCoordAddr = mem::FindDMAAddy(moduleBase + 0x012822F8, zCoordOffsets);\n      float* yCoord = (float*)yCoordAddr;\n      float* xCoord = (float*)xCoordAddr;\n      float* zCoord = (float*)zCoordAddr;\n    \n      *yCoord = pLoc.x;\n      *xCoord = pLoc.y;\n      *zCoord = pLoc.z;\n    \n    \n      tpFlag = false;\n    }\n\nBasically all this is doing is setting my coord ptrs to the value I specified in the struct object and setting each ptr to the corresponding struct member value. Above I did the lazy fix of just using what is in x and storing it in the y Coord Ptr and vise versa putting the y mem var in the x Coord Ptr.\n\nteleport.h\n\n    struct Pcoords\n    {\n        float z{};\n        float y{};\n        float x{};\n    };\n\ndllmain.cpp\n\n    // struct objects for tp coords\n    Pcoords lifeguardTowerCoords{ 564.0266f, 41.6644f, 612.7239f };\n    Pcoords lightHouseCoords{ 583.3959f, 86.7757f, 245.7781f };\n    Pcoords hotelEntranceCoords{ 273.3636f, 56.6729f, 438.3223f };\n    Pcoords gs1Coords{ 466.7950f, 50.1314f, 374.0666f };\n    Pcoords gs2Coords{ 241.6491f, 31.3632f, 894.1751f };\n\nAlright so we can see above in the teleport.h file that the second member variable \"y\" is the second to be initialized. However its very weird, lets take gs1Coords (gas station 1 coords) for example, the \"x\" member variable is being set to 50.1314f and my \"y\" is being set to 374.0666f. This is obviously happening for not just that object but all of them. I could just leave the code as is since it works but I find it so weird that the struct isnt being initialized properly and could use some help. Thanks.\n\n  \n\n\nedit: forgot to mention but I made a simple tp hack before this that saves the players current coords with one hotkey and then can be loaded with another hotkey. That being said I obviously am using the same offsets and module base for that cheat as well so ik those are good.",
    "created_utc": 1746108788.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kc9qux/struct_member_holding_wrong_value/",
    "score": 4,
    "num_comments": 6
  },
  {
    "subreddit": "cpp_questions",
    "title": "Need help with BFS algorithms and Graphs in C++",
    "text": "Hey y'all, I'm trying to learn C++ and am a bit stuck on BFS and Graphs\n\nSo :\n\nI have this graph that is randomly generated, contains \"n\" nodes, each of them is linked to random other nodes\n\nI read things about BFS and algorithms examples of it\n\nI saw version of it with 1 queue, and 2 vectors for parents and \"visited\"\n\nI 100% understand the logic on paper but :\n\nBut I have troubles understanding the \"while\" function of it,\n\nThe exemple code I have is :\n\n    #include <iostream>\n    #include <vector>\n    #include <queue>\n\n    using namespace std;\n\n    // BFS function: calculates distance from 'start' to all reachable nodes\n    void BFS(int start, const vector<vector<int>>& graph, vector<int>& distance,     vector<int>& parent) {\n        int n = graph.size();\n        vector<bool> visited(n, false);\n        queue<int> q;\n\n    // Initialization\n    visited[start] = true;\n    distance[start] = 0;\n    parent[start] = -1;\n    q.push(start);  // enqueue the start node\n\n    while (!q.empty()) {\n        int current = q.front(); q.pop();  // dequeue\n\n        for (int neighbor : graph[current]) {\n            if (!visited[neighbor]) {\n                visited[neighbor] = true;\n                distance[neighbor] = distance[current] + 1;\n                parent[neighbor] = current;\n                q.push(neighbor);  // enqueue\n            }\n        }\n    }\n}\n\n\nI don't understand what we're doing with the \"parent\" vector, I understand pushing the current \"group\" into \"q\" and visiting one by one, deleting the one we visited along the way, but I don't understand how that goes through the whole graph with such little loops\n\nThere is a thing I cannot catch and I have troubles finding what it is\n\nIf anyone can explain to me the loop logic in simple terms I'd be super grateful because I don't know why but I can't grasp the full thing\n\nThank you for reading and have a nice day y'all :)\n\nEDIT : I don't know why the code is so unreadable here, I'm trying to fix it to put indentation in",
    "created_utc": 1746047882.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kbrog5/need_help_with_bfs_algorithms_and_graphs_in_c/",
    "score": 5,
    "num_comments": 2
  },
  {
    "subreddit": "cpp_questions",
    "title": "Looking for advice: How to enter the C++ job market without a CS degree?",
    "text": "Hi everyone!\n\nI'm a 21-year-old student from Austria, currently in my 4th semester of studying Management and Digital Business. Unfortunately, I realized back in February that I don't want to work in corporate management \u2014 I'm far more interested in programming.\n\nBecause of that, I decided to learn C++ intensively, aiming to become a software engineer after finishing my bachelor's degree. I've been studying C++ with [learncpp.com](http://learncpp.com) since February and completed the entire course two weeks ago. Over the past two weeks, I've been learning about data structures, STL algorithms, and have started solving problems on LeetCode.\n\nNow that I'm familiar with the basics of the most important data structures, I've started thinking about what kinds of projects I could build to create a portfolio. But before I begin working on those, I need to figure out which area of software development I want to focus on.\n\nAnd that's where I'm stuck \u2014 I\u2019m not sure which field would best match my interests or offer the best opportunities for someone who is self-taught and doesn't have a Computer Science degree.  \nIs it even possible to land a software development job without a CS degree?\n\nI'd really appreciate any advice or insights you might have. I\u2019m feeling a bit lost right now and unsure what the best next steps are to pursue a career in software development.\n\n**Thank you in advance, I truly appreciate your help!**",
    "created_utc": 1746028114.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kbjso1/looking_for_advice_how_to_enter_the_c_job_market/",
    "score": 13,
    "num_comments": 53
  },
  {
    "subreddit": "cpp_questions",
    "title": "Help trying to code an Event System",
    "text": "Hi, I'm building a Game Engine with some friends and we are figuring out the event system. We decided to go with a Listener based approach where a Listener subscribes to the events they want to receive. The data is stored like this: In the event struct (using CRTP) we have a list of the listeners ordered by priority subscribed to the event and on the Listener itself we have a `std::multimap<std::type_index, std::function<bool(IEvent*)>>`. This is done like this so you can have more than one function subscribed to the same event (if that case happens for some reason).\n\nThe problem with this is that you cannot use polymorphism on `std::function` so you cannot store a function that takes a DamageEvent. I know probably the easiest solution to this would be to just put IEvents on the function and cast it, but we are trying to make things as easy as possible for the end-user, so we were looking for an alternative to still store them on the same map.",
    "created_utc": 1746027929.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kbjq0b/help_trying_to_code_an_event_system/",
    "score": 8,
    "num_comments": 7
  },
  {
    "subreddit": "cpp_questions",
    "title": "Constexpre for fib",
    "text": "Hi\n\nI'm toying around with c++23 with gcc 15.   Pretty new to it so forgive my newbie questions.\n\nI kind of understand the benefit of using contsexpr for compile time expression evaluation.\n\nOf course it doesn't work for widely dynamic inputs. If we take example to calculate fibonacci.  A raw function with any range of inputs wouldn't be practical.  If that were needed, I guess we can unroll the function ourselves and not use constexpr or use manual caching - of course the code we write is dependent on requirements in the real world.\n\nIf I tweak requirements of handling values 1-50 - that changes the game somewhat. \n\nIs it a good practice to use a lookup table in this case?  \nWould you not use constexpr with no range checking?    \nDoes GCC compilation actually unroll the for loop with recursion?   \n\nDoes the lookup table automatically get disposed of, with the memory cleared when program ends?  \n\nI notice the function overflowed at run time when I used int, I had to change types to long.  \n\nDoes GCC optimse for that?  i.e. we only need long for a few values but in this example I'm using long for all,  \n\nI'm compiling with : g++ -o main main.cpp \n\n    #include <iostream>\n    #include <array>\n    \n    \n    // Compile-time computed Fibonacci table\n    constexpr std::array<long, 51> precomputeFibonacci() {\n        std::array<long, 51> fib{};\n        fib[0] = 0;\n        fib[1] = 1;\n        for (int i = 2; i <= 50; ++i) {\n            fib[i] = fib[i - 1] + fib[i - 2];\n        }\n        return fib;\n    }\n    \n    // Lookup table with precomputed values\n    constexpr std::array<long, 51> fibonacciTable = precomputeFibonacci();\n    \n    \n    long getFibonacci(long n) {\n        if (n < 1 || n > 50) {\n            std::cerr << \"Error: n must be between 1 and 50\\n\";\n            return -1;\n        }\n        return fibonacciTable[n];\n    }\n    \n    \n    int main() {\n        int input;\n        std::cout << \"Enter a number (1-50): \";\n        std::cin >> input;\n        std::cout << \"Fibonacci(\" << input << \") = \" << getFibonacci(input) << std::endl;\n    }\n    ",
    "created_utc": 1746011711.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kbdvci/constexpre_for_fib/",
    "score": 4,
    "num_comments": 43
  },
  {
    "subreddit": "cpp_questions",
    "title": "Any recommendations regarding multi-process application",
    "text": "I currently have a sigle process application that receives job requests (via `activemq-cpp`) and start these jobs on threads (using the `activemq-cpp` thread pool). Once the job is done, it sends back a message via the same `activemq` connexion. It was working really well until I encountered a case where the **thread would get stuck in a certain method and never come out of it**. My first though was to exit the thread if it was alive for more than x seconds. The problem is that the blocking function is **from another library I don't have control over**, meaning that once it gets stuck, the thread is basically a zombie that I can't stop nor kill.\n\nSome people recommended me to use a **multi-process application**. The idea would be to have a browser-like architecture. There would be a **master process** managing a set of **sub-processes**. Every x seconds the master would ask the subs if it is still alive. If no response is given by a sub for a certain amount of time, the master would simply restart the sub.\n\n**Has anyone ever created such application? Do you know if any library could simplify the work?**\n\nI will continue my researches in the meantime, might even update this thread with what I find. I acknowledge this is not a trivial question and I am not asking for an entire GitHub code base (if you have one though ...). It's just that the subject seems to be way more complex than what I'm guessing right now. Help is always welcome.\n\n**Edit 1:** The application will later run in a **Docker environnement** with an image based on Ubuntu. So the main platform targeted is **Unix**. However, I wonder if there is an **cross-OS solution** so that I can also start the app from my windows computer. ",
    "created_utc": 1746004040.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kbbzmu/any_recommendations_regarding_multiprocess/",
    "score": 8,
    "num_comments": 4
  },
  {
    "subreddit": "cpp_questions",
    "title": "How do I approach dsa (I only know the basics)",
    "text": "Can someone recommend a good yt channel or should I start leettcode or some shit and refer to a concept when i get stuck",
    "created_utc": 1746003309.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kbbtmv/how_do_i_approach_dsa_i_only_know_the_basics/",
    "score": 5,
    "num_comments": 10
  },
  {
    "subreddit": "cpp_questions",
    "title": "Declaration issues for brand new coder. Hello world pop up",
    "text": "I am trying to make a simple pop up window exe file that when clicked on simply says \"Hello World\" in the top bar and then more text in the actual window space that says \"hello\" or some other predetermined text (like and inside joke I can change and then recompile)\n\nThe issue lies in\n\n`Hello_World.cpp:(.text+0x1d): undefined reference to platform_creat_window(int, int, const char*)`\n\nFull code\n\n    // Globals\n    static bool running = true;\n    \n    \n    \n    //Platform Functions\n    bool platform_create_window(int width, int height, const char* helloWindow);\n    \n    \n    //Windows Platform\n    #ifdef _WIN32\n    #define WIN32_LEAN_AND_MEAN\n    #define NOMINAX\n    #include <windows.h>\n    \n    \n    //Mac Platform\n    \n    \n    //Linux Platform\n    \n    \n    //Windows Globals\n    \n    \n    //Platform Implementation (Windows)\n    bool platform_create_window(int width, int height, const char* helloWindow)\n    {\n        HINSTANCE instance = GetModuleHandleA(0);\n    \n        WNDCLASSA wc = {}\n        wc.hInstance = instance;\n        wc.hIcon = LoadIcon(instance, IDI_APPLICATION);\n        wc.hCursor = LoadCursor(NULL, IDC_ARROW);\n        wc.lpszClassName = helloWindow;\n        wc.lpfnWndProc = DefWindowProcA;\n    \n        if(!RegisterClassA(&wc))\n        {\n            return false;\n        }\n    \n        // WS_CAPTION | WS_SYSMENU | WS_THICKFRAME | WS_MINIMIZEBOX | WS_MAXIMIZEBOX\n        int dwStyle = WS_OVERLAPPEDWINDOW;\n    \n        HWND window = CreateWindowExA(0, helloWindow,\n                                title,\n                                dwStyle,\n                                100,\n                                100,\n                                width,\n                                height,\n                                NULL,\n                                NULL,\n                                instance,\n                                NULL);\n    \n        if(window == NULL);\n        {\n            return false;\n        }\n    \n        ShowWindow(window, SW_SHOW);\n    \n        return true;\n    \n    }\n    \n    #endif\n    \n    int main () \n    {\n        platform_create_window(700, 300, \"Hello_World\");\n    \n        while(running)\n        {\n            // Update\n        }\n    \n        return 0;\n    }\n\nCredit goes to the lesson [https://www.youtube.com/watch?v=j2Svodr-UKU&t=38s](https://www.youtube.com/watch?v=j2Svodr-UKU&t=38s), he just modifies his \"build.sh\" file to ignore compiler errors for this stuff and I don't want to do that. I've tried making changes using `const char*` inside of`bool platform_creat_window(int width, int height, char* helloWindow)` If changing the [build.sh](http://build.sh) file is what i should do then I am confused on where to find the [build.sh](http://build.sh) file.\n\nI know that I can fix the error either by making the proper declaration for `platform_create_window` or by putting a `const` at the end somewhere.",
    "created_utc": 1745982612.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kb6lzf/declaration_issues_for_brand_new_coder_hello/",
    "score": 1,
    "num_comments": 16
  },
  {
    "subreddit": "cpp_questions",
    "title": "Cache Friendly SIMD Organization",
    "text": "Hi all, this question requires some understanding of SIMD intrinsic types like SSE's \\_\\_m128 and \\_\\_m128i.\n\n  \nSo I've found myself trying to write a ray tracer procedure in SIMD. Why? Because I want to, it's fun, rewarding, and I have the time. My questions here can be answered with \"benchmark it, see what's faster.\" But I want to learn from folks with experience who may or may not have considered this before. I will probably end up benchmarking the difference eventually.\n\nMoving past that, I've read the Insomnia Games presentation, which goes over using SIMD as a throughput optimizer, not a single-problem optimizer. I'll explain my understanding of these.\n\nWhat I mean is that if I have 4 pixels, a single-problem optimizer might set a point as a single \\_\\_m128 vec4 of x, y, z, w, and use SIMD intrinsics to calculate a single pixel faster. A throughput optimizer instead treats each lane as one of the 4 pixels. So a \\_\\_m128 vec4 would be x1, x2, x3, x4, and there exists a y \\_\\_m128 and a z \\_\\_m128 to make up a point. This allows a dot product for example to be calculated 4 at a time rather than one at a time. I'm going with the throughput approach.\n\n  \nI have a basic understanding of some constraints (Correct me if I'm wrong, I very well could be):\n\n  \n1. \\_\\_m128 seems to be a loosey goosey type. it should live in a register ideally, but I've read that it can be pushed to the stack. In my mind, I know there are several 128-bit registers, but if I have more \\_\\_m128's than registers, that would force some of the data onto the stack. So there is a number-of-registers limit that could mess with cache stuff if i exceed it. i.e. what if the variable I pushed to the stack is the next one that I need.\n\n2. Intrinsic store operations and load operations are more costly than continuous math operations etc. So ideally, I want a program that loads constants once, and keeps them available, etc.\n\n  \nLet's just consider the case of a random number generator. I want to generate 4 random numbers at a time with xorshift, which requires a state. I am using a \\_\\_m128i for 4 separate states, each initialized to different values.\n\n  \nI have 2 approaches, one for each constraint above:\n\n1. I only want to load the state once, and I don't want to wrap it in a class or something because \\_\\_m128 seems weird to put as a member variable (being a register dweller (?)), so I will compute as many random numbers as I need all at once, and store them all to an array of integers, so that I can reference them in the next step. This approach does continuous streams of each step required to compute a pixel. So if my steps are 1, 2, 3, I will load inputs, compute every single step 1 for all pixels, store outputs. Load previous outputs, compute every single step 2, store outputs, load previous outputs, compute every single step 3, and store the color to every pixel. If you visualize steps 1 2 and 3 as going top-down, I'll call this a left to right approach. This obviously would incur much higher memory footprint, with many many reads and writes, and I'm assuming this would ultimately be slower for that reason alone.\n\n2. I want to avoid all of that loading and storing, so I'm going to compute steps 1 2 and 3 top-down, and store a batch of pixels before moving to the right for the next batch of pixels. Now I have an issue. For example, step 1 is my random number generator. I need to store a state for that. Step 2 is a different issue that needs constants h, i, j, and k to be preloaded into registers. Step 3 finally needs constants p, q, r, s to be preloaded into registers. I would like to load each of state, h, i, j, k, p, q, r, s only once, since their values will never change, except for state. Ideally, I load these upfront out of the loop of pixel batches, but now I have 9 whole registers occupied. If for example my machine has only 16 128 bit registers, that leaves 7 for actual computation. Lets say that step 1, 2, and 3 combined declare a total of 11 \\_\\_m128 types, now we have 20 different \\_\\_m128 types, and only 16 registers, so some have to be stored under the hood. This could result in the same loading and storing overhead, but I'm not familiar with cache preferences at this level.\n\n  \nMy intuition tells me 2 is faster, and my heard tells me it's better because it's simple to write, I dont need to create memory buffers to store tons of outputs for each step, I can just mimic an AOS ray tracer with some conditional branching removed. What are the thoughts you have on this? Does too many \\_\\_m128/\\_\\_m128i types scream cache indirection at you? I barely know what indirection means lol. This is all very new to me. This project is for fun, and for me that means the most needless optimization possible. What advice do you have?",
    "created_utc": 1745971355.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kb2x7k/cache_friendly_simd_organization/",
    "score": 4,
    "num_comments": 8
  },
  {
    "subreddit": "cpp_questions",
    "title": "HELP: How can I link C++ files using VSCode?",
    "text": "# TL;DR:\n\nI want to be able to **link** files and **build** C++ projects using Visual Studio Code.\n\n# Before anyting else:\n\nHi, before I say anything else, I want to tell you that I apologize for any wrong info in this post. I'm a bit of a beginner in this field and I wrote this post because I want to learn. Also, sorry for any bad English or spelling mistakes, English is not my native language.\n\n# A few notes to keep in mind:\n\nI mainly use VSCode (the **blue** one) for my IDE and I'd like to keep it that way, because I want all the programming languages \u200b\u200bI learn to be written using the same IDE (it's just a personal preference, don't judge me :P). But the problem is that (*as far as I know*) it wasn't designed for languages \u200b\u200bthat require **compiling** and the things you would normally want to do in C++ are not always as straightforeward as they should be.\n\nFrom what I understand, when you **build** a C++ project, the files are **compiled** and **linked** together, and then an executable file is generated containing your code (which may have been spread across multiple files, e.g. header files, source files, resource files, and all other that).\n\nI've also heard that sometimes you can **compile** one file without errors, but when you **link** it you get an error.\n\n# What I'm trying to achieve:\n\nI would really like to be able to **link** C++ files when **building** a project (if you can even make a project in VSCodem idk how), just like you can when using Visual Studio (the **purple** one) or Code::Blocks, and also enable all the \"**linking errors**\" to be seen in the terminal so I can debug the project.\n\nBasically, I want to be able to have all the important C++ features from Visual Studio (the **purple** one) in Visual Studio Code (the **blue** one) and be able to make C++ projects at their full potential using  the **VSCode IDE**.\n\n# Other notes:\n\nI have installed all the C++ extensions from Microsoft (C/C++ Extension Pack)\n\n* C/C++\n* C/C++ Themes\n* CMake Tools\n\nI am using GCC with MinGW\n\nThe debugging configuration I am using is \"C/C++: g++.exe\"\n\nAnd to run the files I am also using the default command \"Run C/C++ File\" from the Play Button on the top right (I also have a **question** related to this action: Does it just **compile** the file or does it **build** the project? It generates the \".exe\" file, but still does not do any **linking** and does not tell you whether the error you are getting is a **compiling** or a **linking** error).\n\n# Thank you all in advance for any help or future advice on how to solve my immense cluelessness.",
    "created_utc": 1745935665.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kaotxg/help_how_can_i_link_c_files_using_vscode/",
    "score": 1,
    "num_comments": 19
  },
  {
    "subreddit": "cpp_questions",
    "title": "How small (or not) should a library be",
    "text": "I'm working on a large old code base. Through time and refactors we got our current library layout we some library being really small (a couple of files) and some really big (200 files).\n\nSometimes looking at the code you can discern some \"nodes\", a subset of files and their content pertaining a specific domain. In some cases the node is quite big so it make sense to isolate it, but sometimes it's quite small, let's say less than 5 files.\n\nMy question is how small one should or should not go when creating libraries to isolate concerns or domains? Is there an issue with too much fragmentation? Of course I'm excluding the extreme case of having hundreds of 2-3 files libraries.",
    "created_utc": 1745930964.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kan46q/how_small_or_not_should_a_library_be/",
    "score": 0,
    "num_comments": 10
  },
  {
    "subreddit": "cpp_questions",
    "title": "std::is_invocable_r_v and templated lambda with non-type template argument",
    "text": "Any ideas why std::is\\_invocable\\_r\\_v evaluates to false?\n\n    // compiled with g++ -std=c++20\n    // gcc version 14.2.1\n    #include <type_traits>\n    #define bsizeof(T) (sizeof(T) * 8)\n    int main() {\n      auto func = []<int N, typename T>(T x) requires ((N > 0) && (N <= (bsizeof(T) / 2))) { return x | (x >> N); };\n      int x = func.template operator()<2>(8); // OK\n      static_assert(std::is_invocable_r_v<int, decltype(func.template operator()<2>(8)), int>); // error: static assertion failed\n    }",
    "created_utc": 1745909502.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kahnu3/stdis_invocable_r_v_and_templated_lambda_with/",
    "score": 7,
    "num_comments": 13
  },
  {
    "subreddit": "cpp_questions",
    "title": "How to install the latest cpp version?",
    "text": "i am new to the whole coding thing, i was reading about how to make a header file and it was yapping about how i should declare functions in header and define them in a different file bla bla bla\n\nanyways a note popped out when i was scrolling saying that cpp20 introduced modules which are lowk peak\n\nso i pressed on that thang and it led me to another microsoft page explaining to me how to use modules and i wanted to try it but it shows an error message below \"export module\" and \"import\" which i can only assume means my version is not up to date which is a bummer i think i would have had soooo much fun w modules.\n\nhow to update cpp on visual studio like the purple one",
    "created_utc": 1745909176.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1kahl7v/how_to_install_the_latest_cpp_version/",
    "score": 4,
    "num_comments": 9
  },
  {
    "subreddit": "cpp_questions",
    "title": "Okay, why is the interactive (default) constructor being called in this program?",
    "text": "I'm new to C++ coding, and I'm having trouble with program execution.\n\nSpecifically, I'm trying to create an Event in my code using a Datestuff object as a parameter.  However, instead of using the constructor (I think) I have created for this purpose, it launches the default (parameterless) constructor instead.\n\nI've tried debugging to trap the call but I can't seem to set the right breakpoint.  This was originally multiple cpp/h files but I skinnied it to a single cpp in the interests of simplicity.  Same problem with multiple files so that got ruled out.\n\nAny help is appreciated here.\n\n    #include <iostream>\n    #include <string>\n    #include <vector>\n    \n    class Datestuff{\n        public:\n            Datestuff();\n            Datestuff(std::string startDT, std::string endDT);\n            std::string getStartDt();\n            std::string getStartTm();\n            std::string getEndDt();\n            std::string getEndTm();\n            void setStartDt();\n            void setStartTm();\n            void setEndDt();\n            void setEndTm();\n            void setDateTimes();\n            bool conflictCheck(Datestuff inDateTime);\n        private:\n            std::string startDt;\n            std::string startTm;\n            std::string endDt;\n            std::string endTm;\n            std::string startDtTm;\n            std::string endDtTm;\n            std::string setDate();\n            std::string setTime();\n    };\n    \n    int setDate();\n    \n    class Participant{\n        public:\n            Participant(std::string inName);\n            int getParticipantID();\n            std::string getParticipantName();\n        private:\n            static int nextUniqueID; \n            int partID;\n            std::string name;\n    };\n    \n    class Event {\n        public:\n            Event(Datestuff inDt, std::string inDesc, int maxCount);\n            int getEventID();\n            int getCurrCNT();\n            int getMaxCNT();\n            int setCurrCNT();               //returns current count after increment; call get first and if same after set, then you are at max.\n            std::string getEventDescr();\n            std::string getEventStartDt();\n            std::string getEventEndDt();\n            void setEventDt(Datestuff inDt);\n        private:\n            static int nextUniqueID;\n            int eventID;    // need this to be global distinct\n            std::string description;\n            Datestuff eventDt;\n            int maxCount;\n            int currCount;\n    };\n    \n    int Participant::nextUniqueID {};\n    int Event::nextUniqueID {};\n    \n    void testDateConflict(); // run this in main() to test date conflict work\n    void testParticipantList();\n    \n    int main () {\n          \n        Datestuff d1(\"202412312355\", \"202503010005\");\n        std::cout << \"Date one has start: \" << d1.getStartDt() << \":\" << d1.getStartTm() << \" \";\n        std::cout << \"and end: \" << d1.getEndDt() << \":\" << d1.getEndTm() << std::endl;\n    \n        Event e1(d1, \"Super Mega Code-a-thon\",12);\n    \n        std::cout << \"The event is: \" << e1.getEventDescr() << std::endl;\n    \n        return 0;\n    }\n    \n    void testDateConflict(){\n        Datestuff d1(\"202412312355\", \"202503010005\");\n        Datestuff d2(\"202501020000\", \"202501150000\");\n    \n        std::cout << \"Date one has start: \" << d1.getStartDt() << \":\" << d1.getStartTm() << \" \";\n        std::cout << \"and end: \" << d1.getEndDt() << \":\" << d1.getEndTm() << std::endl;\n    \n        std::cout << \"Date two has start: \" << d2.getStartDt() << \":\" << d2.getStartTm() << \" \";\n        std::cout << \"and end: \" << d2.getEndDt() << \":\" << d2.getEndTm() << std::endl;\n    \n        std::cout << \"Does d1 conflict with d2? \" << std::boolalpha << d1.conflictCheck(d2);\n    }\n    \n    void testParticipantList(){\n        Participant p1(\"Dennis\");\n        Participant p2(\"Algo\");\n    \n        std::cout << \"This is p1: \" << p1.getParticipantName() << \" and the ID: \" << p1.getParticipantID() << std::endl;\n        std::cout << \"This is p2: \" << p2.getParticipantName() << \" and the ID: \" << p2.getParticipantID() << std::endl;\n    \n        std::vector<Participant> partyPeeps;\n    \n        partyPeeps.push_back(p1);\n        partyPeeps.push_back(p2);\n    \n        for(auto i : partyPeeps){\n            std::cout << \"Name: \" << i.getParticipantName() << \" and ID: \" << i.getParticipantID() << std::endl;\n        }\n    }\n    \n    Event::Event(Datestuff inDt, std::string inDesc, int num){\n        eventDt = inDt;\n        description = inDesc;\n        maxCount = num;\n        currCount = 0;\n    }\n    \n    int Event::getEventID(){\n        return eventID;\n    }\n    \n    std::string Event::getEventDescr(){\n        return description;\n    }\n    \n    std::string Event::getEventStartDt(){\n        std::string outStr {};\n        outStr = eventDt.getStartDt();\n        outStr += eventDt.getStartTm();\n        return outStr;\n    }\n    \n    std::string Event::getEventEndDt(){\n        std::string outStr {};\n        outStr = eventDt.getEndDt();\n        outStr += eventDt.getEndTm();\n        return outStr;\n    }\n    \n    void Event::setEventDt(Datestuff inDt){\n        eventDt.setStartDt();\n        eventDt.setStartTm();\n        eventDt.setEndDt();\n        eventDt.setEndTm();\n        eventDt.setDateTimes();\n    }\n    \n    int Event::getCurrCNT(){\n        return currCount;\n    }\n    \n    int Event::getMaxCNT(){\n        return maxCount;\n    }\n    \n    int Event::setCurrCNT(){\n        if(currCount < maxCount){\n            currCount++;\n        } else{\n            std::cout << \"You are at max capacity and cannot add this person.\" << std::endl;\n        }\n        return currCount;\n    }\n    \n    Datestuff::Datestuff(){\n        std::cout << \"Enter the start date and time.\\n\";\n        startDt = setDate();\n        startTm = setTime();\n        std::cout << \"Enter the end date and time.\\n\";\n        endDt = setDate();\n        endTm = setTime();\n        setDateTimes();\n    }\n    \n    Datestuff::Datestuff(std::string startDT, std::string endDT){\n        startDtTm = startDT;\n        startDt= startDT.substr(0,8);\n        startTm = startDT.substr(8,4);\n        endDtTm = endDT;\n        endDt = endDT.substr(0,8);\n        endTm = endDT.substr(8,4);\n    }\n    \n    std::string Datestuff::getStartDt(){\n        return startDt;\n    }\n    \n    std::string Datestuff::getStartTm(){\n        return startTm;\n    }\n    \n    std::string Datestuff::getEndDt(){\n        return endDt;\n    }\n    \n    std::string Datestuff::getEndTm(){\n        return endTm;\n    }\n    \n    void Datestuff::setStartDt(){\n        startDt = setDate();\n    }\n    \n    void Datestuff::setStartTm(){\n        startTm = setTime();\n    }\n    \n    void Datestuff::setEndDt(){\n        endDt = setDate();\n    }\n    \n    void Datestuff::setEndTm(){\n        endTm = setTime();\n    }\n    \n    bool Datestuff::conflictCheck(Datestuff inDateTime){\n        if (                                                                                        // testing date                       this object's date\n            ((startDtTm <= inDateTime.startDtTm) && (endDtTm >= inDateTime.startDtTm)) ||           //  20250401 - 20270101 has start in my range of 20250202 - 20250302\n        ((startDtTm <= inDateTime.endDtTm)   && (endDtTm >= inDateTime.endDtTm))   ||           //  20240101 - 20250102 has end in   my range of 20250202 - 20250302\n    ((inDateTime.startDtTm <= startDtTm) && (inDateTime.endDtTm >= endDtTm)) ) {            //  20250101 - 20260101 contains     my range of 20250202 - 20250302\n    //std::cout << \"Your trial IS in conflict with the dates!\" << std::endl;\n            return true;\n    } else {\n            //std::cout << \"Your trial is not in the window.\";\n            return false;\n        }\n    }\n    \n    std::string Datestuff::setDate(){\n        int tempInt {};\n        std::string workingVal {};\n        std::cout << \"Enter in the year between 1900 and 2099 using FOUR DIGITS: \"; std::cin >> tempInt;\n        while((tempInt > 2099) || (tempInt < 1900)){\n            std::cout << \"Unacceptable input\\n\";\n            std::cin >> tempInt;\n        }\n        workingVal = std::to_string(tempInt);\n    \n        std::cout << \"Enter in the month between 1 and 12: \"; std::cin >> tempInt;\n        while((tempInt > 12) || (tempInt < 1)){\n            std::cout << \"Unacceptable input\\n\";\n            std::cin >> tempInt;\n        }\n        if(tempInt < 10){\n            workingVal += \"0\" + std::to_string(tempInt);\n        } else{\n            workingVal += std::to_string(tempInt);\n        }\n        \n        std::cout << \"Enter in the day between 1 and 31: \"; std::cin >> tempInt;\n        while((tempInt > 31) || (tempInt < 1)){\n            std::cout << \"Unacceptable input\\n\";\n            std::cin >> tempInt;\n        }\n        if(tempInt < 10){\n            workingVal += \"0\" + std::to_string(tempInt);\n        } else{\n            workingVal += std::to_string(tempInt);\n        }\n        return workingVal;\n    }\n    \n    std::string Datestuff::setTime(){\n        int tempInt {};\n        std::string tempStr {};\n        std::string workingVal {};\n    \n        std::cout << \"Enter in the hour between 1 and 12: \"; std::cin >> tempInt;\n        while((tempInt > 12) || (tempInt < 1)){\n            std::cout << \"Unacceptable input\\n\";\n            std::cin >> tempInt;\n        }\n        std::cout << \"Enter AM or PM: \"; std::cin >> tempStr;\n        while((tempStr != \"AM\") && (tempStr!= \"PM\")){\n            std::cout << \"Unacceptable input\\n\";\n            std::cin >> tempStr;\n        }\n        if(tempStr == \"AM\"){\n            switch(tempInt){\n                case 12: workingVal = \"00\";\n                    break;\n                case 11:\n                case 10: workingVal = std::to_string(tempInt);\n                    break;\n                default: workingVal = \"0\" + std::to_string(tempInt);\n                    break;\n            }\n        } else {\n            if(tempInt == 12){\n                workingVal = std::to_string(tempInt);\n            } else{\n                workingVal = std::to_string(tempInt + 12);\n            }\n        }\n    \n        std::cout << \"Enter in the minutes between 0 and 59: \"; std::cin >> tempInt;\n        while((tempInt > 59) || (tempInt < 0)){\n            std::cout << \"Unacceptable input\\n\";\n            std::cin >> tempInt;\n        }\n        if(tempInt < 10){\n            workingVal += (\"0\" + std::to_string(tempInt));\n        } else {\n            workingVal += std::to_string(tempInt);\n        }\n        \n        return workingVal;\n    \n    }\n    \n    void Datestuff::setDateTimes(){\n        startDtTm = startDt + startTm;\n        endDtTm = endDt + endTm;\n    }\n    \n    Participant::Participant(std::string inName){\n        name = inName;\n        partID = ++nextUniqueID;\n    }\n    \n    int Participant::getParticipantID(){\n        return partID;\n    }\n    std::string Participant::getParticipantName(){\n        return name;\n    }\n    ",
    "created_utc": 1745873915.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1ka6f5z/okay_why_is_the_interactive_default_constructor/",
    "score": 0,
    "num_comments": 36
  },
  {
    "subreddit": "cpp_questions",
    "title": "GCC 15.1 arm-none-eabi can't import std",
    "text": "So, I've been excited to try GCC 15.1, primarily because of `import std;`. Could not find it packaged, so I decided to build it from source, poked around a little, and found [ARM's GCC build scripts](https://gitlab.arm.com/tooling/gnu-devtools-for-arm).\n\nAt the beginning it went quite smoothly - quickly figured out the spec file, set the build goin. A minor hiccup with running out of drive space and two hours later, I had working GCC 15.1.\n\nAnd... it doesn't work. Trying to `import std;`, GCC complains about `std` missing `jthread` and several other members. Which, to be fair, probably wouldn't work on my targets anyway.\n\nSPC file and error logs over here: https://gitlab.com/-/snippets/4838524\n\nI did change the ARM config script to enable both threading and TLS, which ARM originally disables, but I don't think it's all that's needed.\n\nEdit:\n\nSo, writing this question and replying to comments here made methink, I dug a little. Turns out, there's a global `--disable-threads`, and there's a libstdc++ specific `--disable-libstdcxx-threads`. Running another build with it now, it could help.\n\nEdit 2:\n\nNope, still doesn't work. \n\nEdit 3:\n\nMight have misread ARM's bash script and added `--disable-libstdcxx-threads` in the wrong place.",
    "created_utc": 1745857203.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1k9zmis/gcc_151_armnoneeabi_cant_import_std/",
    "score": 5,
    "num_comments": 29
  },
  {
    "subreddit": "cpp_questions",
    "title": "After LearnCPP",
    "text": "Hey all,\n\nI 'finished' learncpp, and was reading \"C.1 The End?\" (I did skip a few topics here and there -- I felt I could learn a few things as I built things myself).  \n  \nAfter completing LearnCPP, the author recommends learning data structures and algorithms.  \n  \nMy question is: do you have any resource recommendations that can help me learn these concepts?\n\nnote: I didn't realize how much I enjoyed the website layout of learncpp (I used to prefer physical books) -- if the resource followed this design, that would be awesome!\n\nThank you.",
    "created_utc": 1745843259.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1k9uaur/after_learncpp/",
    "score": 11,
    "num_comments": 8
  },
  {
    "subreddit": "cpp_questions",
    "title": "Need help with removing coordinates OOP",
    "text": "using fltk pppgui for oop\n\nI  have my code working like i want it to work but everytime i execute the file it runs coordinates in the console.\n\nI only want it to output the simple window and to only print if the error exception is valid how can i get rid of the coordinates ? i have no print statements in my code i am using msys2 bash shell. my main needs to remain unchanged.\n\nAny thoughts or help much appreciated\n\n  \nthe output i am getting is the window with the 3 chessboards and a console output with\n\n\n\n Square (1, 4) at (360, 280) Square (1, 5) at (360, 300) Square (2, 0) at (380, 200) Square (2, 1) at (380, 220) Square (2, 2) at (380, 240) Square (2, 3) at (380, 260) Square (2, 4) at (380, 280) Square (2, 5) at (380, 300) Square (3, 0) at (400, 200) Square (3, 1) at (400, 220) Square (3, 2) at (400, 240) Square (3, 3) at (400, 260) Square (3, 4) at (400, 280) Square (3, 5) at (400, 300) Square (4, 0) at (420, 200) Square (4, 1) at (420, 220) Square (4, 2) at (420, 240) Square (4, 3) at (420, 260) Square (4, 4) at (420, 280) Square (4, 5) at (420, 300) Square (5, 0) at (440, 200) Square (5, 1) at (440, 220) Square (5, 2) at (440, 240) Square (5, 3) at (440, 260) Square (5, 4) at (440, 280)\n\n    #include \"Simple_window.h\"\n    #include \"Graph.h\"\n    #include <iostream>\n    using namespace Graph_lib;\n    using namespace std;\n    // Custom exception for bad chessboards\n    struct BadChessboardException {};\n    // The Chessboard class\n    class Chessboard : public Shape {\n    public:\n    // Constructor accepts top-left point, width, height, number of squares\n    // Optionally accepts colors for black and white squares, defaults to black and white\n    Chessboard(Point tl, int w, int h, int sq, Color black = Color::black, Color white = Color::white)\n    : top_left(tl), width(w), height(h), squares(sq), color_black(black), color_white(white) {\n    // Check for invalid dimensions and throw exception if needed\n    if (width <= 0 || height <= 0 || squares <= 0) {\n    throw BadChessboardException(); // Simple exception thrown here\n    }\n    }\n    void draw_lines() const override;\n    private:\n    Point top_left;\n    int width;\n    int height;\n    int squares; // number of squares along a side\n    Color color_black;\n    Color color_white;\n    };\n    // Draw method to paint the chessboard\n    void Chessboard::draw_lines() const\n    {\n    int cell_width = width / squares;\n    int cell_height = height / squares;\n    // Loop through the rows and columns to draw the chessboard squares\n    for (int i = 0; i < squares; ++i) {\n    for (int j = 0; j < squares; ++j) {\n    // Determine the position of each square\n    int x = top_left.x + i * cell_width;\n    int y = top_left.y + j * cell_height;\n    Graph_lib::Rectangle r(Point(x, y), cell_width, cell_height);\n    // Alternate colors for the squares based on the sum of row and column indexes\n    r.set_fill_color((i + j) % 2 == 0 ? color_white : color_black);\n    r.draw(); // Draw the square\n    }\n    }\n    }\n    int main()\n    {\n    Simple_window win(Point(100, 100), 600, 400, \"Chessboard\");\n    try {\n    // Create chessboard instances with varying sizes and colors\n    Chessboard c1(Point(20, 20), 100, 100, 8); // Default black and white squares\n    win.attach(c1);\n    Chessboard c2(Point(140, 140), 160, 160, 10); // Default black and white squares\n    win.attach(c2);\n    Chessboard c3(Point(340, 200), 120, 120, 6, Color::red, Color::yellow); // Custom colors\n    win.attach(c3);\n    }\n    catch (BadChessboardException&) {\n    cerr << \"Bad chessboard dimensions.\\n\"; // Display error message for bad chessboard\n    }\n    win.wait_for_button(); // Wait for the user to close the window\n    }",
    "created_utc": 1745796811.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1k9hp0k/need_help_with_removing_coordinates_oop/",
    "score": 2,
    "num_comments": 7
  },
  {
    "subreddit": "cpp_questions",
    "title": "Can you represent Graphs in a simple way ?",
    "text": "Hey y'all\n\nI'm gonna learn classes and stuff to be able to represent a graph of connected dots in C++\n\nBut I was just thinking if there was a \"simple\" way to represent them using only vectors or something like that\n\nI was thinking of doing \"using Node = vector<variant<int, Node>>\" and some loops such that I have a \"n\" layers vector with basically all the nodes and the links represented\n\nBut the thing is, it's an O(n\\^n)) complexity program if I'm not mistaken because basically each element of my vector contains the whole graph inside it (a huge amount of repeated informations)\n\nAnd to be honest, I don't even know how to code a \"n\" amout of \"for\" loops or whatever (I'm relatively new to programming)\n\nI tryied looking internet already but what I find mostly is class related solutions and I was just thinking if it's possible to represent it in an other way that I didn't think of\n\nSorry if it is a silly question, I'm still learning as I'm writting and if I find the answer too easily I'll delete the post but I'd be up for some explanations\n\nThank you for reading and have a nice day y'all\n\nEDIT : And i want to know how stupid my idea is of representing \"layers\" of vectors to have the graph represented n\\^n times lmao\n\nAm I over estimating the amount of work it would require the computer to do if I asked it for exemple to go through that graph and find the shortest way between 2 nodes ? Is it even possible to code such a thing ?\n\n  \nEDIT 2 : \n\nI want to thank everyone for the thoughtful comments, it helped me a lot to see it another way and to lead me to where I need to go to learn how to manage those in the future\n\nThank you for the help y'all, appreciate it !",
    "created_utc": 1745770379.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1k97mve/can_you_represent_graphs_in_a_simple_way/",
    "score": 6,
    "num_comments": 23
  },
  {
    "subreddit": "cpp_questions",
    "title": "Need help understanding condition_variable.wait(lock, predicate)",
    "text": "    class pair_lock\n    {\n     public:\n      /*\n          Constructor.\n      */\n      pair_lock(void);\n    \n      /*\n          Lock, waits for exactly two threads.\n      */\n      void lock(void);\n    \n      /*\n          Unlock, waits for peer and then releases the `pair_lock` lock.\n      */\n      void release(void);\n    \n     private:\n      /* complete your code here */\n      std::mutex mtx1;\n      std::condition_variable release_cv;\n      std::condition_variable lock_cv;\n    \n    \n      int waiting_threads;\n      int inside_threads;\n      int releasing_threads;\n    };\n    \n    pair_lock::pair_lock(void)\n    {\n      /* complete your code here */\n      waiting_threads = 0;\n      releasing_threads = 0;\n      inside_threads = 0;\n    }\n    \n    void pair_lock::lock(void)\n    {\n      /* complete your code here */\n      std::unique_lock<std::mutex> lock(mtx1);\n    \n      while(inside_threads == 2 ){\n        release_cv.wait(lock);\n      }\n      waiting_threads++;\n    \n      if (waiting_threads < 2)\n      {\n        lock_cv.wait(lock, [this]() { return waiting_threads == 2; });\n      }\n      else\n      {\n        lock_cv.notify_one();\n      }\n      waiting_threads--;\n      inside_threads++;\n    \n    }\n    \n    void pair_lock::release(void)\n    {\n      /* complete your code here */\n      std::unique_lock<std::mutex> lock(mtx1);\n    \n      releasing_threads++;\n    \n      if (releasing_threads < 2)\n      {\n        lock_cv.wait(lock, [this]() { return releasing_threads == 2; });\n    \n      }\n      else\n      {\n        lock_cv.notify_one();\n      }\n    \n      releasing_threads--;\n      inside_threads--;\n    \n      if (inside_threads == 0)\n      {\n        release_cv.notify_all();\n      }\n    }\n\nI was given a task by my university to implement a pair\\_lock that lets pairs of threads enter and exit critical sections while other threads must wait. In the code above, i use the wait function but it seems like the thread doesn't get woken up when the predicate is true.   \n  \nThey gave us a test to see if our code works, if 10 ok's are printed it works(N=20). with the above code, the thread that waits in release() doesn't wake up and so only one OK is printed.  I even tried setting releasing\\_threads to 2 right before the notify all to see if it would work but no. If i change the predicate in both lock and relase to be !=2 instead of ==2, i get 10 ok's most of the time, occasionally getting a FAIL. This makes no sense to me and i would appreciate help.  \n  \n\n\n    void thread_func(pair_lock &pl, std::mutex &mtx, int &inside, int tid)\n    {\n      pl.lock();\n    \n      inside = 0;\n      usleep(300);\n      mtx.lock();\n      int t = inside++;\n      mtx.unlock();\n      usleep(300);\n      if(inside == 2)\n      {\n        if(t == 0) std::cout << \"OK\" << std::endl;\n      }\n      else\n      {\n        if(t == 0) std::cout << \"FAIL - there are \" << inside << \" threads inside the critical section\" << std::endl;\n      }\n    \n    \n      pl.release();\n    }\n    \n    int main(int argc, char *argv[])\n    {\n      pair_lock pl;\n      std::mutex mtx;\n    \n      std::jthread threads[N];\n    \n      int inside = 0;\n      for(int i = 0; i < N; i++)\n      {\n        threads[i] = std::jthread(thread_func, std::ref(pl), std::ref(mtx), std::ref(inside), i);\n      }\n      return 0;\n    ",
    "created_utc": 1745712003.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1k8qsys/need_help_understanding_condition/",
    "score": 3,
    "num_comments": 12
  },
  {
    "subreddit": "cpp_questions",
    "title": "One of my homework is doing a matrix calculator in c++, I did a code but I get werid long ass numbers at the end, anyone can help me?",
    "text": "using namespace std;\n\n\\#include <iostream>\n\nint f1=0;\n\nint c1=0;\n\nint f2=0;\n\nint c2=0;\n\nint sum=0;\n\nint function1(int, int, int, int);\n\nint main(){\n\nfunction1(f1, c1, f2, c2);\n\nreturn 0;\n\n}\n\n\n\nint funcion1(int, int, int, int){\n\ncout<<\"Matrix 1 size \"<<endl;\n\ncin>>f1;\n\ncin>>c1;\n\nint matriz1\\[f1\\]\\[c1\\];\n\ncout<<\"Matrix 2 size\"<<endl;\n\ncin>>f2;\n\ncin>>c2;\n\nint matriz2\\[f2\\]\\[c2\\];\n\nif(c1!=f2){\n\ncout<<\"Mutiplication not possible\"<<endl;\n\nreturn 0;\n\n} \n\nif(c1==f2){\n\nint matriz3\\[f1\\]\\[c2\\];\n\n}\n\ncout<<\"Type data of matrix 1\"<<endl;\n\nfor(int i=0; i<c1;i++){\n\nfor(int j=0; j<f1;j++){\n\ncin>>matriz1\\[f1\\]\\[c1\\];\n\n}\n\n}\n\ncout<<\"Type data of matrix 2\"<<endl;\n\nfor(int i=0; i<c2;i++){\n\nfor(int j=0; j<f2;j++){\n\ncin>>matriz2\\[f2\\]\\[c2\\];\n\n}\n\n}\n\ncout<<\"Result:\"<<endl; \n\nfor( int i = 0 ; i<f1; i++){  \n\nfor (int j = 0;j<c2; j++){ \n\nsum = 0;\n\nfor (int k = 0;k<c1;k++){  \n\nsum=sum + matriz1\\[i\\]\\[k\\] \\* matriz2\\[k\\]\\[j\\];\n\n}\n\ncout<<sum<<\"\\\\t\";  \n\n}\n\ncout<<endl;\n\n}\n\nreturn 0;\n\n}",
    "created_utc": 1745682510.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1k8g01s/one_of_my_homework_is_doing_a_matrix_calculator/",
    "score": 0,
    "num_comments": 17
  },
  {
    "subreddit": "cpp_questions",
    "title": "i hate asmjit pls help",
    "text": "Hey im trying to import some c++ polymorphic encryptions and etc to my main client.cpp  \nBut i always getting errors like `undefined reference to asmjit::...`. I've already tried adding `-lasmjit` to my compile command and made sure I have the `libasmjit.dll.a`, `libasmjit.dll`, and `libasmjit.a` files in my library path, but nothing seems to work.",
    "created_utc": 1745672496.0,
    "url": "https://www.reddit.com/r/cpp_questions/comments/1k8cfag/i_hate_asmjit_pls_help/",
    "score": 0,
    "num_comments": 12
  },
  {
    "subreddit": "programming",
    "title": "A simple project",
    "text": "Hey y'all.\n\nI recently implemented a MVP for a very small project of mine. It's a chrome extension which basically consists of cat (for now), your pet, and it basically integrates itself to Leetcode. When you solve a question, it makes the cat happier and then it naps (because why not). When you do not code for long or the health of the cat in decreased, there might be 50% chance that it might perish or become frail and beg you for some food. It's a 5-min project of mine but it seems fun because it could actually help people grind leetcode.   \n  \nI would love if y'all can contribute to this project. Thank you! ",
    "created_utc": 1746523724.0,
    "url": "https://github.com/ceazyy/coding-pet-extension",
    "score": 1,
    "num_comments": 1
  },
  {
    "subreddit": "programming",
    "title": "Mastering Kafka in .NET: Schema Registry, Error Handling & Multi-Message Topics",
    "text": "Hi everyone!\n\nCurious how to improve the reliability and scalability of your Kafka setup in .NET?\n\nHow do you handle evolving message schemas, multiple event types, and failures without bringing down your consumers?  \nAnd most importantly \u2014 how do you keep things running smoothly when things go wrong?\n\nI just published a blog post where I dig into some advanced Kafka techniques in .NET, including:\n\n* Using Confluent Schema Registry for schema management\n* Handling multiple message types in a single topic\n* Building resilient error handling with retries, backoff, and Dead Letter Queues (DLQ)\n* Best practices for production-ready Kafka consumers and producers\n\nFun fact: This post was inspired by a comment from u/Finickyflame on my previous Kafka blog \u2014 thanks for the nudge!\n\nWould love for you to check it out \u2014 happy to hear your thoughts or experiences!\n\nYou can read it here:  \n[https://hamedsalameh.com/mastering-kafka-in-net-schema-registry-amp-error-handling/](https://hamedsalameh.com/mastering-kafka-in-net-schema-registry-amp-error-handling/)\n\n",
    "created_utc": 1746521097.0,
    "url": "https://hamedsalameh.com/mastering-kafka-in-net-schema-registry-amp-error-handling/",
    "score": 2,
    "num_comments": 0
  },
  {
    "subreddit": "programming",
    "title": "What does this mean by memory-safe language? | namvdo's technical blog",
    "text": "\\- **90% of Android vulnerabilities are memory safety issues.**  \n  \n\\- **70% of all vulnerabilities in Microsoft products over the last decade were memory safety issues.**  \n  \n\\- What does this mean that a programming language is memory-safe? Let's find out in this blog post!",
    "created_utc": 1746516971.0,
    "url": "https://learntocodetogether.com/programming-language-memory-safety/",
    "score": 2,
    "num_comments": 8
  },
  {
    "subreddit": "programming",
    "title": "OneUptime: Open-Source Incident.io Alternative",
    "text": "OneUptime ([https://github.com/oneuptime/oneuptime](https://github.com/oneuptime/oneuptime)) is the open-source alternative to Incident.io + StausPage.io + UptimeRobot + Loggly + PagerDuty. It's 100% free and you can self-host it on your VM / server. OneUptime has Uptime Monitoring, Logs Management, Status Pages, Tracing, On Call Software, Incident Management and more all under one platform.\n\n**Updates:**\n\nNative integration with Slack: Now you can intergrate OneUptime with Slack natively (even if you're self-hosted!). OneUptime can create new channels when incidents happen, notify slack users who are on-call and even write up a draft postmortem for you based on slack channel conversation and more!\n\nDashboards (just like Datadog): Collect any metrics you like and build dashboard and share them with your team!\n\n**Roadmap:**\n\nMicrosoft Teams integration, terraform / infra as code support, fix your ops issues automatically in code with LLM of your choice and more.\n\nOPEN SOURCE COMMITMENT: Unlike other companies, we will always be FOSS under Apache License. We're 100% open-source and no part of OneUptime is behind the walled garden.",
    "created_utc": 1746455471.0,
    "url": "https://github.com/oneuptime/oneuptime",
    "score": 41,
    "num_comments": 7
  },
  {
    "subreddit": "programming",
    "title": "I Built an Open-Source Framework to Make LLM Data Extraction Dead Simple",
    "text": "After getting tired of writing endless boilerplate to extract structured data from documents with LLMs, I built\u00a0[ContextGem](https://github.com/shcherbak-ai/contextgem)\u00a0\\- a free, open-source framework that makes this radically easier.\n\n# What makes it different?\n\nUnlike other LLM frameworks that require dozens of lines of custom code to extract even basic information, ContextGem handles the complex, most time-consuming parts with powerful abstractions, eliminating boilerplate and reducing development overhead:\n\n\u2705 Automated dynamic prompts and data modeling  \n\u2705 Precise reference mapping to source content  \n\u2705 Built-in justifications for extractions  \n\u2705 Nested context extraction  \n\u2705 Works with any LLM provider  \nand more built-in abstractions that save developer time.\n\n# Simple LLM extraction in just a few lines:\n\n    from contextgem import Aspect, Document, DocumentLLM, StringConcept\n    \n    # Define what to extract\n    doc = Document(raw_text=\"<text of your document, e.g. a contract>\")\n    doc.aspects = [\n        Aspect(\n            name=\"Intellectual property\",\n            description=\"Clauses on intellectual property rights\",\n        )\n    ]\n    doc.concepts = [\n        StringConcept(\n            name=\"Anomalies\",  # in longer contexts, this concept is hard to capture with RAG\n            description=\"Anomalies in the document\",\n            add_references=True,\n            reference_depth=\"sentences\",\n            add_justifications=True,\n            justification_depth=\"brief\",\n        )\n    ]\n    \n    # Extract with any LLM\n    llm = DocumentLLM(model=\"<provider>/<model>\", api_key=\"<api_key>\")\n    doc = llm.extract_all(doc)\n    \n    # Get results\n    print(doc.aspects[0].extracted_items)\n    print(doc.concepts[0].extracted_items)\n\nContextGem leverages LLMs' expanding context windows for better extraction accuracy from complete documents. Unlike RAG approaches that often struggle\u00a0with complex concepts and nuanced insights, The framework enables direct information extraction from entire\u00a0documents, eliminating retrieval inconsistencies while\u00a0optimizing for in-depth\u00a0analysis.\n\nContextGem features a native DOCX converter, support for multiple LLMs, and full serialization - all under\u00a0*Apache 2.0*\u00a0permissive license.\n\n**The project is just getting started, and your early adoption\u00a0and feedback will help shape its future. If you find it\u00a0useful, the best way to support\u00a0is by sharing it and giving the project a star \u2b50!**\n\nView project on GitHub:\u00a0[https://github.com/shcherbak-ai/contextgem](https://github.com/shcherbak-ai/contextgem)\n\nTry it out and let me know your thoughts!",
    "created_utc": 1746391927.0,
    "url": "https://github.com/shcherbak-ai/contextgem",
    "score": 0,
    "num_comments": 0
  },
  {
    "subreddit": "programming",
    "title": "AWS Machine Learning Associate Exam Complete Study Guide! (MLA-C01)",
    "text": "Hi Everyone,\n\nI just wanted to share something I\u2019ve been working really hard on \u2013 my new book:\u00a0**\"AWS Certified Machine Learning Engineer Complete Study Guide: Associate (MLA-C01) Exam.\"**\n\nI put a ton of effort into making this the most helpful resource for anyone preparing for the MLA-C01 exam. It\u00a0***covers all the exam topics in detail***, with clear explanations,\u00a0***helpful images***, and\u00a0***very exam like practice tests***.\n\n[Click here to check out the study guide book!](https://www.amazon.com/Certified-Machine-Learning-Engineer-Complete-ebook/dp/B0F71MRNCL/ref=sr_1_6?dib=eyJ2IjoiMSJ9.nDG_3F1F6opqhd8Dysza5qeyXwYUng6CA35vPCR0YHn0nKh48wQqePh-u1jhj5cZxMLhfkxCHozkhN_16eI4TeGN2XWz9W7z_BjK1enij1CZIBrmXrDRYkKCaKrDvpdLbatgrKFcgj3xbVQ86ZEnEGc5HH1B8M7cCOwQWFER-69JhTJ-INkejIr6xTtp2tsHemwWCAaC5wsZm_iwoHl5SchrDTLu6rBj-Oquc2EUlrc.tTscu9hs5jwX70dPrUQDtXxOF-kp4szqbs4Yfnpj-3M&dib_tag=se&keywords=aws+machine+learning+associate&qid=1746182064&sr=8-6)\n\nIf you\u2019re studying for the exam or thinking about getting certified, I hope this guide can make your journey a little easier. Have any questions about the exam or the study guide? Feel free to reach out!\n\nThanks for your support!",
    "created_utc": 1746390848.0,
    "url": "https://www.amazon.com/Certified-Machine-Learning-Engineer-Complete/dp/B0F6YQQJ9Q/ref=sr_1_6?dib=eyJ2IjoiMSJ9.nDG_3F1F6opqhd8Dysza5q1ryQJ50eeHxaiWPMqqhCPZ8cwTTI7-JRm-36gv_dtihed0DHoHs_tF4cKBDzoWr5c-Pll4AN0W5_JAmXShF-Q6P3msPqQ9e799zhQ0iddiJsD4lIl4usYWx_vAS4WXRFFjTXVprDCjicLO-XXBXGrbn404o6gtGYmJa4qNimgulkyJDit1S8uNQHXEw59gROEVef91oXRozszu8E4coW8.CefezY0DXPfKmu-vd2VxZ7qwLovoM6SXfVwatmfKWPs&dib_tag=se&keywords=aws+machine+learning+associate&qid=1746390736&sr=8-6",
    "score": 0,
    "num_comments": 0
  },
  {
    "subreddit": "programming",
    "title": "Introducing Flux: A Universal, Cross-Platform Hot-Reload Manager for Any Language or Framework \ud83d\ude80",
    "text": "Hey everyone! I\u2019ve been working on an CLI tool called **flux-reload** that brings true \u201chot-reload\u201d to *any* language, framework, or shell command\u2014no more being stuck with nodemon for Node.js or ptw for Python.\n\n# What is Flux?\n\nFlux is a lightweight, cross-platform utility that watches your files (or folders) and automatically restarts **any** command when changes are detected. Think nodemon, watchexec, or entr\u2014but:\n\n* **Language-agnostic**: works with Python, Go, Rust, TypeScript, SASS, GCC, rsync\u2026 you name it.\n* **Zero-config defaults**: watch `./`, ignore `.git`/`venv`/`node_modules`, 200 ms debounce, all extensions.\n* **Optional config**: TOML or YAML file support for custom watch paths, ignores, extensions, debounce, and command.\n* **Debounced restarts**: coalesce rapid file saves into a single restart.\n\nI want you guys to use this and give me feedback and please tell me if anything can be improved, I am stuck at TUI part of this, stuck at few technical issues. Will try few more things next weekend.\n\n* \u2b50 Star the repo: [https://github.com/Ashutosh619-sudo/flux](https://github.com/Ashutosh619-sudo/flux)\n* \ud83d\udc1b Report issues or feature requests\n* \ud83d\udcbb Contribute code or docs\n* \ud83d\udce6 Try it out and let me know what you think!\n\nLooking forward to feedback, ideas, or any crazy edge-cases I haven\u2019t thought of yet. Let\u2019s make reloading code effortless\u2014regardless of your tech stack!",
    "created_utc": 1746389371.0,
    "url": "https://github.com/Ashutosh619-sudo/flux",
    "score": 0,
    "num_comments": 9
  },
  {
    "subreddit": "programming",
    "title": "I taught Copilot to analyze Windows Crash Dumps - it's amazing.",
    "text": "**TL;DR**\n\n**A Model Context Protocol Server to connect WinDBG with AI**\n\n* Repository: [svnscha/mcp-windbg](https://github.com/svnscha/mcp-windbg)\n* License: MIT\n\nEver felt like crash dump analysis is stuck in the past? While the rest of software development has embraced modern tools, we're still manually typing commands like `!analyze -v` in WinDbg.\n\nI decided to change that. Inspired by the capabilities of AI, I integrated GitHub Copilot with WinDbg, creating a tool that allows for conversational crash dump analysis.\n\nInstead of deciphering hex codes and stack traces, you can now ask, \"**Why did this application crash?**\" and receive a clear, contextual answer.\n\nCheck out the full write-up and demo videos here: [The Future of Crash Analysis: AI Meets WinDbg](https://svnscha.de/posts/ai-meets-windbg/)\n\nFeedback and thoughts are welcome!",
    "created_utc": 1746386799.0,
    "url": "https://svnscha.de/posts/ai-meets-windbg/",
    "score": 205,
    "num_comments": 29
  },
  {
    "subreddit": "programming",
    "title": "Radiation-Tolerant Machine Learning Framework - Progress Report and Current Limitations",
    "text": "\\[Project\\]\n\nI've been working on an experimental framework for radiation-tolerant machine learning, and I wanted to share my current progress. This is very much a work-in-progress with significant room for improvement, but I believe the approach has potential.\n\n# The Core Idea:\n\nThe goal is to create a software-based approach to radiation tolerance that could potentially allow more off-the-shelf hardware to operate in space environments. Traditional approaches rely heavily on expensive radiation-hardened components, which limits what's possible for smaller missions.\n\n# Current Implementation:\n\n* C++ framework with no dynamic memory allocation\n* Several TMR (Triple Modular Redundancy) implementations\n* Health-weighted voting system that tracks component reliability\n* Physics-based radiation simulation for testing\n* Selective hardening based on neural network component criticality\n\n# Honest Test Results:\n\nI've run simulations across several mission profiles with the following accuracy results:\n\n* ISS Mission: \\~30% accuracy\n* Artemis I (Lunar): \\~30% accuracy\n* Mars Science Lab: \\~20% accuracy (10.87W power usage)\n* Van Allen Probes: \\~30% accuracy\n* Europa Clipper: \\~28.3% accuracy\n\nThese numbers clearly show the framework is not yet production-ready, but they provide a baseline to improve upon. The simulation methodology is sound, but the protection mechanisms need significant enhancement.\n\n# Current Limitations:\n\n* Limited accuracy in the current implementation\n* Needs more sophisticated error correction\n* TMR implementation could be more robust, especially for multi-bit errors\n* Extreme radiation environments (like Jupiter) remain particularly challenging\n* Power/protection tradeoffs need optimization\n\nI'm planning to improve the error correction mechanisms and implement more intelligent bit-level protection. If you have experience with radiation effects in electronics or fault-tolerant computing, I'd genuinely appreciate your insights.\n\nRepository:\u00a0[https://github.com/r0nlt/Space-Radiation-Tolerant](https://github.com/r0nlt/Space-Radiation-Tolerant)\n\nThis is a personal learning project that I'm sharing for feedback, not claiming to have solved radiation tolerance for space. I'm open to constructive criticism and collaboration to make this approach viable.",
    "created_utc": 1746383456.0,
    "url": "https://github.com/r0nlt/Space-Radiation-Tolerant",
    "score": 10,
    "num_comments": 0
  },
  {
    "subreddit": "programming",
    "title": "Biometric issue",
    "text": "I'm working on a side project \u2013 a mobile clocking system for employees. A key feature I'd like to implement is using biometric authentication (fingerprint/face) for clocking in and out.\n\nHowever, I'm running into a conceptual challenge: Is it possible to use a standard Android or iOS phone's internal biometric scanner to store and differentiate the biometric data of multiple different employees for clocking in/out?                                                                                                                           For more indo on the projct posted the projct scope on my LinkIN see link any advice would be greatly appreciated \ud83d\udc4f\ud83c\udffb",
    "created_utc": 1746366973.0,
    "url": "https://www.linkedin.com/posts/raymond-van-wyk-3497b6268_paylocity-payrolltech-internshipapplication-activity-7324780941367762944-htO4?utm_source=social_share_send&utm_medium=android_app&rcm=ACoAAEGdOWkB0E3oFEcf8TlGt6oygIhq-DjIF1M&utm_campaign=copy_link",
    "score": 0,
    "num_comments": 6
  },
  {
    "subreddit": "programming",
    "title": "Happy Birthday Paradox",
    "text": "An article with an aim to help people develop a deeper intuition towards the famous \"birthday-problem\" and collections/sets in general. Basic familiarity of sets, probability and algabra is recommeded.",
    "created_utc": 1746359732.0,
    "url": "https://nyadgar.com/posts/happy-birthday-paradox/",
    "score": 0,
    "num_comments": 6
  },
  {
    "subreddit": "programming",
    "title": "Tolerant Machine Learning Framework for Space Applications",
    "text": "# I Built a Radiation-Tolerant Machine Learning Framework for Space Applications - Seeking Professional Advice [P]\n\nHey everyone,\n\nI wanted to share a project I've been developing: a C++ framework that enables machine learning systems to operate reliably in high-radiation environments like space. I'm also looking for professional guidance as I navigate next steps with this project.\n\nThe Problem:  \nRadiation in space causes bit flips and memory corruption that can compromise neural network computations. This creates a significant challenge for deploying ML on spacecraft, satellites, and deep space missions where radiation effects are unavoidable.\n\nMy Solution:  \nI've created a comprehensive framework that uses several techniques to ensure ML reliability:\n\n* Triple Modular Redundancy (TMR) with enhanced CRC checksums and health-weighted voting\n* Memory scrubbing to detect and correct radiation-induced bit flips\n* Fixed-point arithmetic for deterministic numerical computation\n* Branchless operations for predictable code paths\n* Physics-based radiation simulation for thorough testing\n* Mission-specific profiles (LEO, Mars, Jupiter, etc.) with adaptive protection levels\n\nTesting Results:  \nIn our stress testing with extreme radiation conditions (beyond Jupiter levels), the framework achieves significant error recovery. For practical space applications such as Mars missions, our testing showed over 94% recovery rates, which is excellent for critical systems in radiation environments.\n\nKey Applications:\n\n* Space-based image processing without requiring data downlink\n* Autonomous navigation with reliable onboard ML\n* Scientific data analysis directly on spacecraft\n* Radiation-tolerant inference for any neural network application\n\nThe framework is MIT-licensed, and I'm working on a comprehensive white paper that details the methodology and results.\n\nLooking for Advice:  \nAs someone relatively new to the aerospace industry, I'd appreciate guidance from professionals in this field. How do I connect with the right people at space agencies or satellite companies who might be interested in this technology? What steps should I take to validate this framework further? Are there professional organizations or conferences where I should present this work?\n\nI'm open to career advice too - would it be better to pursue this as an independent project, seek collaboration with research institutions, or look for roles at aerospace companies where this expertise would be valuable?\n\nTL;DR: I built a framework that makes neural networks radiation-resilient for space applications through multiple fault-tolerance techniques, and I'm seeking professional guidance on how to take this work to the next level and advance my career in this field.\n\nGithub:\n\n[https://github.com/r0nlt/Space-Radiation-Tolerant](https://github.com/r0nlt/Space-Radiation-Tolerant)",
    "created_utc": 1746242617.0,
    "url": "https://github.com/r0nlt/Space-Radiation-Tolerant",
    "score": 0,
    "num_comments": 10
  },
  {
    "subreddit": "AskProgramming",
    "title": "[Project] Building an AI note-taking app like Fathom/Otter: Speech-to-text, diarization, summarization pipeline?",
    "text": "Hi everyone,\n\nI\u2019m trying to understand the technical steps needed to build an AI note-taking app similar to Fathom or Otter. The goal is to capture high-quality meeting audio and generate accurate, structured meeting notes or summaries.\n\nI\u2019d appreciate guidance on the full pipeline, including:\n\n1. Audio capture: Best practices/tools for recording high-quality audio from Zoom, Google Meet, or browser-based meetings.\n2. Speech-to-text: What are the best speech-to-text engines for real-time transcription with high accuracy? (e.g., Whisper, Google, Deepgram?)\n3. Speaker diarization: How to accurately identify and separate different speakers?\n4. Text processing: Techniques for summarizing or extracting key action items, questions, decisions, etc.\n5. Data privacy: Any common considerations or libraries used to ensure secure and compliant data handling?\n\nI\u2019m comfortable with Python/JavaScript but would love a tech stack recommendation or open-source starting point.\n\nThanks in advance for any help or pointers!",
    "created_utc": 1746506243.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kfw4pz/project_building_an_ai_notetaking_app_like/",
    "score": 0,
    "num_comments": 0
  },
  {
    "subreddit": "AskProgramming",
    "title": "The more I use AI for coding, the more I realize I don\u2019t Google things anymore. Anyone else?",
    "text": "\nNot sure when it happened exactly, but I\u2019ve basically stopped Googling error messages, syntax questions, or random \u201chow do I\u2026\u201d issues. I just ask AI and move on.\n\nIt\u2019s faster, sure but it also makes me wonder how much I\u2019m missing by not browsing Stack Overflow threads or reading docs as much.\n",
    "created_utc": 1746489855.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kfqzac/the_more_i_use_ai_for_coding_the_more_i_realize_i/",
    "score": 17,
    "num_comments": 43
  },
  {
    "subreddit": "AskProgramming",
    "title": "Offline and OS tools used in development with AI - touching a grass",
    "text": "I\u2019m trying to comprehend the AI revolution and how it actually speeds up the development. After trying tools like Ollama with different models, integration with JetBrains (continue.dev/devoxx), I feel I\u2019m kind of missing point. Even tinkered around the HuggingFace and firing up python scripts straight from IDE, using or ChatGPT (sparingly). I often (if not mostly) ended up with the situation where it would be better to write stuff from scratch instead to adjust what was given. Only CodeRabbit was actually useful to me.\n\nAt this point it\u2019s super hard for me to believe in stories that guys make a workload for one year shortened to few weeks, or months of work reduced to mere few hours...\n\nI also notice a lot of buzzwords like Hive AI, Agentic development, RAG. I see some tools like n8n (community edition). It\u2019s conceptually... understandable to me at huge scale, but cannot find the real use for solo dev and a lot of hype around this makes me hard to figure it out or my viewpoint is too... narrow? - how do you use those tools for work solo/in company? Does it REALLY help you get job done or just gives some nuances to write stuffs by yourself anyway? Or is it just a lot of guys that never touched a code but finally can make their dream come true in regards of software development?\n\nReal development (solo) takes a time - planning features, implementation, testing all three stages - unit/integration/e2e, and would love to read your commens what do you use and how do you setup your AI in VSCode/Jetbrains (preferably) or use external OS tools if there are any, to speed the stuffs up (so, no cursors/windsurfs etc).\n\nCheers!\u00a0",
    "created_utc": 1746467887.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kfi89u/offline_and_os_tools_used_in_development_with_ai/",
    "score": 1,
    "num_comments": 2
  },
  {
    "subreddit": "AskProgramming",
    "title": "Feeling disappointed to create my projects",
    "text": "Hey guys, I'm trying to get an internship but I don't have many projects to put on my resume. Recently I was thinking about how I could help small bookstores and I got the idea of making a website/inventory duo which would allow small bookstores to simultaneously update their websites and inventory. I was looking online and I saw small bookstores around me having websites and everything. This disappointed me and now I don't want to make this project at all since it already exists. This is the first project in a while that I had some motivation to create. Should I go ahead and make the project I wanted to? Is there any use in it? or should I just scrap it and find something else?",
    "created_utc": 1746467741.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kfi65z/feeling_disappointed_to_create_my_projects/",
    "score": 1,
    "num_comments": 8
  },
  {
    "subreddit": "AskProgramming",
    "title": "Looking to Volunteer at a Startup (CS Grad, No Experience)",
    "text": "Hi everyone,  \nI just graduated with a degree in Computer Science and, like many new grads, Im stuck in the \u201cno experience = no job\u201d loop. I\u2019m currently looking to volunteer my time and skills ideally at a startup or early-stage project so I can gain real-world experience and have something I can confidently list on my resume.\n\nI'm open to working for free, remotely and I'm mainly looking for projects where I can take ownership of tasks and grow as a developer. If anyone knows of founders, teams, or small startups who could use an extra pair of hands, please let me know .. or point me in the right direction.\n\nThanks so much in advance!",
    "created_utc": 1746467545.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kfi36u/looking_to_volunteer_at_a_startup_cs_grad_no/",
    "score": 1,
    "num_comments": 2
  },
  {
    "subreddit": "AskProgramming",
    "title": "Just got my first project at work and I\u2019m lost.",
    "text": "Hi,\n\nI made a post a couple of weeks ago regarding I how I felt towards getting a job with no experience in their tech stack. I just got a new project that revolves around remaking a old project that is not working properly. But it\u2019s written in JavaScript/Firebase. I have no idea how to approach this issue since I\u2019m used to coding pure backend using C#/.Net framework. \n\nDoes anybody have some tips on how I should approach this projekt or some kind of book/guide to learn how to understand JavaScript/firebase ?",
    "created_utc": 1746449043.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kfaosf/just_got_my_first_project_at_work_and_im_lost/",
    "score": 16,
    "num_comments": 28
  },
  {
    "subreddit": "AskProgramming",
    "title": "Turn python/database programme into an app",
    "text": "Let me preface with explaining I am not a dev, mostly a dba. I've made made a small console python + postgres tool to help me learn spanish. it just runs in terminal for now, i call a function and it gives me an exercise. works great on pc, but i'd love to have it on phone too, with some basic gui \u2013 typing in terminal on touchscreen sounds like nightmare.\n\nso now i wonder how to turn it into some kind of app. did some googling and saw react is popular, but i really cant stand html/js/css. Flutter looks cool but feels like it might be overkill to learn it only for one hobby idea. Ideally i'd like something .net-based, since I work with Microsoft tech at work, but seems like ms frontend tech has no future.\n\nany idea what tech stack would be easy for me to build a simple gui for this and have it work on both pc and phone?",
    "created_utc": 1746434757.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kf6ryq/turn_pythondatabase_programme_into_an_app/",
    "score": 0,
    "num_comments": 3
  },
  {
    "subreddit": "AskProgramming",
    "title": "Problem using protoc.exe...",
    "text": "I've been encountering persistent issues using `protoc.exe` on Windows to generate C# files from Dialogflow `.proto` files. The core problem is that `protoc` repeatedly throws \"File not found\" errors for imported `.proto` files (like those in `google/protobuf`, `google/api`, and `google/cloud/dialogflow`), along with warnings that specified directories for import paths (`-I` or `--proto_path`) \"do not exist,\" even when those directories have been verified to exist.",
    "created_utc": 1746401631.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kexn06/problem_using_protocexe/",
    "score": 1,
    "num_comments": 3
  },
  {
    "subreddit": "AskProgramming",
    "title": "How do I complie Conan with Cmake in VSCode ?",
    "text": "Can someone provide step by step guide to Compile Conan or Vcpkg with Cmake. \nI'm using MSYS2 Mingw64 and  VSCode as my text editor. I have installed gcc and Cmake via Msys2 (i asked chat gpt how to compile Conan ) but it's ended up bad. I'm always getting some error which I don't even know what is that. Some one Really help me . \n(Sorry if my english is bad, English is not my native language. I'm working on it ) ",
    "created_utc": 1746376225.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kenxri/how_do_i_complie_conan_with_cmake_in_vscode/",
    "score": 0,
    "num_comments": 0
  },
  {
    "subreddit": "AskProgramming",
    "title": "Please help me in usage of pump.fun API",
    "text": "I wanna get social links(website, twitter, telegram) from [pump.fun](http://pump.fun) using token symbol.\n\nplz help me how to get these infos using typescript and [pump.fun](http://pump.fun) api.",
    "created_utc": 1746374502.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1ken9db/please_help_me_in_usage_of_pumpfun_api/",
    "score": 0,
    "num_comments": 1
  },
  {
    "subreddit": "AskProgramming",
    "title": "Help passing data between C# and C++ in a WinUI 3 app (same process)",
    "text": "**Hi! I'm working on a WinUI 3 desktop application where I have two separate projects in the same solution:**\n\n* A\u00a0**C# WinUI3 project**\u00a0that handles the UI logic\n* A\u00a0**C++/WinRT project**\u00a0that handles some plugin architecture logic\n\nBoth projects are running in the same app and the same process - so I don\u2019t want to use IPC or named pipes. I just need to\u00a0**pass variable data back and forth between the two projects**.\n\n# \ud83d\udd0d Here's what I've tried:\n\n* I started with a\u00a0**C# Class Library**\u00a0using\u00a0`<CsWinRTComponent>true</CsWinRTComponent>`, but it failed to generate WinRT projections properly every time.\n* I switched to using a\u00a0**C++/WinRT Runtime Component**\u00a0instead. While this works for C#, it\u00a0**fails when trying to reference this component from another C++ Runtime Component.**\n\n# \u2757 My current issue:\n\n* **I want a clean and maintainable way to pass data between C# and C++ in the same process without creating circular dependencies.**\n* It seems that C#/WinRT and multiple C++ Runtime Components don't play well together.\n* Even generated projection files sometimes don\u2019t update correctly after rebuilds.\n\n# \ud83d\udca1 Things I\u2019m avoiding:\n\n* IPC, named pipes, serialization hacks - everything runs in the same process\n* I want to\u00a0**minimize how much C++ I write**\n\nHow should I fix this, or what should I do?  \nThanks!!",
    "created_utc": 1746359893.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kei4cf/help_passing_data_between_c_and_c_in_a_winui_3/",
    "score": 0,
    "num_comments": 3
  },
  {
    "subreddit": "AskProgramming",
    "title": "What programming languages should one learn while pursuing degree in ECE??",
    "text": "I am going to pursue my degree in ECE. What are some programming languages I should learn which will help me in future??",
    "created_utc": 1746359857.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kei40w/what_programming_languages_should_one_learn_while/",
    "score": 0,
    "num_comments": 6
  },
  {
    "subreddit": "AskProgramming",
    "title": "How do you approach understanding a massively undocumented code base?",
    "text": "I recently inherited a code base (400k+ loc) of a game, in a language I'm not familiar with. There are no docs for the game, and the only debugger available is an in-editor debugging window that shows the current line number being executed and all variables in scope. To add to the mess, the debugging window is written in a language I don't speak or know how to read, making it a nightmare to use. The code for the game is fully English however, so I am able to read it. The code uses goto everywhere, making control flow very difficult to follow, and everything is a tangled mess. Any change to the code in one place breaks ten things behind the scenes, so it's really really fragile and all the systems are complex. The language is written in a games programming language popular in Asia, but not Europe or America. There is an English reference of the language available however. The only benefit to all of this is that there is no deadline, so I am able to take my time and try any approach. If anyone has had any experience with anything even remotely similar, please share it.\n\nAny tips or war stories would help. Thank you.\n\nEdit:  \nThank you to all the people who gave suggestions, I'll write a summary of what I've learnt and am planning on doing to help familiarise myself with the code base. Also I'll try using OCR and a translator to try and understand the debugger, because it will be incredibly useful.\n\n1. Start by stepping into the entry point of the application and finding any procedures it calls, any key words that stand out should be noted, e.g. \"input\\_handling\\_init\"\n2. Using the list of keyword, search through the code base (either by using grep or another tool) to find instances of where that keyword comes up, and searching through it to find what you're interested in. Only focus on one part of the system, don't overwhelm yourself with the entire complexity of the game.\n3. Add logs to each procedure you're interested in (or use a script or AI to generate logs for every procedure) that contain variable names and values, file name and line number, and the name of the procedure.\n4. Then run certain parts of the game (like picking up an item), noting down which procedures get called.\n5. Using this information generate a graph, with each procedure as a node, and the edges between nodes representing a callee/caller relationship\n6. Using the graph, you can understand the relationship of different procedures in a system. You could also get a procedure and it's related procedures, and query AI into why they interact with each other the way they do.\n7. If debugger access is available, use it (by setting breakpoints, and stepping into/over procedures) to also understand how a system works.\n8. Using the information you get from the debugger, create a timeline of what procedures get called throughout the runtime of the program, to get a better idea of how the game runs overall.\n9. Using the logging step, you can also use a performance profiler (use \"Performance Monitor\" on windows if your tooling doesn't have a dedicated one) to find out \"hot\" code that's being ran. Hot can mean many things, depending on what you want to profile (e.g. amount of RAM being consumed, Processor Information, etc.)\n10. Bookmarking important bits of code for later, because this is a long term process.",
    "created_utc": 1746352421.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1keg6r2/how_do_you_approach_understanding_a_massively/",
    "score": 18,
    "num_comments": 66
  },
  {
    "subreddit": "AskProgramming",
    "title": "Flutter project problem",
    "text": "guys i have a problem with my flutter project i wanted to connect it with a database created from wamps and for backend its php if anyone intrested in helping dm me\nThe project is about shopping app ",
    "created_utc": 1746294418.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kdypr9/flutter_project_problem/",
    "score": 1,
    "num_comments": 3
  },
  {
    "subreddit": "AskProgramming",
    "title": "Anyone successfully integrated Firebase with an MCP agent (like Windsurf)? Keep hitting security issues",
    "text": "I\u2019m using Windsurf (AI agent) and trying to connect it to Firebase through MCP (Model Context Protocol). I\u2019ve set up the Firebase MCP server using an Admin SDK key in mcp.config.json, but I keep running into access and permission errors \u2014 usually around Firestore and Auth.\n\nThis seems to happen every time I try Firebase + MCP, no matter the project. Either something\u2019s off with the service account permissions or Firebase just doesn\u2019t play well with this kind of setup.\n\nHas anyone gotten this working reliably? Are there best practices for connecting Firebase securely to AI agents or automation tools using MCP or similar?\n\nAppreciate any tips \u2014 just trying to get it working, not a dev but building real stuff.",
    "created_utc": 1746293793.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kdyh41/anyone_successfully_integrated_firebase_with_an/",
    "score": 2,
    "num_comments": 0
  },
  {
    "subreddit": "AskProgramming",
    "title": "The worst developer onboarding experience I\u2019ve had (and why it still sucks in 2025)",
    "text": "Hey everyone,  \njust wanted to share a recent onboarding disaster I went through, and honestly, I am curious if others here have had similar experiences.\n\nI recently joined a mid-sized software company. Everything seemed fine during the interviews. But once I actually started... it was a mess.\n\n* No central documentation.\n* Tasks scattered across random repos.\n* Setting up my dev environment took 3 full days because the instructions were outdated and everyone had their own version.\n* No onboarding checklist, no real plan \u2014 just \"talk to X and figure it out.\"\n\nThe worst part was that HR considered the onboarding \"done\" after paperwork was signed, and the team lead clearly had no bandwidth to properly onboard new devs.\n\nAfter two weeks, I still had no idea:\n\n* What the priorities were,\n* How the workflow was supposed to look,\n* Who to reach out to when something broke.\n\nIt really feels like in most companies, onboarding is still pure chaos. Either completely ad-hoc or hidden behind some outdated PDFs that no one updates.\n\nSo I am wondering:\n\n* Have you gone through something like this?\n* What was your worst (or best) dev onboarding experience?\n* Are the current onboarding tools actually helping, or are they just making the chaos look prettier?\n\nCurious to hear your stories.  \nMaybe there\u2019s a better way out there.",
    "created_utc": 1746287644.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kdw5k0/the_worst_developer_onboarding_experience_ive_had/",
    "score": 46,
    "num_comments": 38
  },
  {
    "subreddit": "AskProgramming",
    "title": "Can I run a virtual machine on an early 2015 Intel Mac running OS 12 to use Visual Studio 2022 for .NET MAUI development?",
    "text": "Hi all,  \nI\u2019m working on a university project that requires me to use .NET MAUI for the frontend, but my current Mac setup (Early 2015 Intel-based MacBook pro running macOS 12) is not able to run or debug .NET MAUI projects.\n\nI'm considering installing a **virtual machine** to run **Windows**, and then install **Visual Studio 2022**, which I know supports .NET MAUI. My main questions:\n\n* Is this feasible on an with my setup, performance-wise and compatibility-wise?\n* Has anyone done MAUI development in this kind of VM setup (on macOS)?\n* Which VM software would you recommend?\n* Any potential issues I should be aware of (emulation problems, performance bottlenecks, debugging issues)?\n\nI have limited time, so I'm looking for the fastest stable setup to **test and debug** my MAUI app. Maybe you guys have different ideas other than a VM?\n\nThanks a lot!",
    "created_utc": 1746276868.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kdsak6/can_i_run_a_virtual_machine_on_an_early_2015/",
    "score": 0,
    "num_comments": 8
  },
  {
    "subreddit": "AskProgramming",
    "title": "Where does AI coding stop working",
    "text": "Hey, I'm trying to get a sense of where AI coding tools currently stand: What tasks they can and what they cannot take on. There must still be a lot that AI coding tools like Devin, Cursor or Windsurf cannot take on because there are still millions of developers getting paid each month.\n\nI would be really interested in hearing some experiences from anyone regularly using on where exactly tasks cross over from something the AI can handle with minimal to no supervision to something where you have to take over yourself. Some cues/guesses on issues where you have to step in to solve the task from my own (limited) experience:\n\n* Novel solution/leap in logic required\n* Context too big, Agent/model fails to find or reason with appropriate resources\n* Explaining it would take longer than implementing it (Same problems that you would have with a Junior dev but at least the junior dev learns over time)\n* Missing interfaces e.g. agent cannot interact with web interface\n\nDo you feel these apply and do you have other issues where you have to take over? I would be interested in any stories/experiences.",
    "created_utc": 1746227764.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kderat/where_does_ai_coding_stop_working/",
    "score": 0,
    "num_comments": 45
  },
  {
    "subreddit": "AskProgramming",
    "title": "Website monitoring program",
    "text": "\nHi all, \nI needed a website monitoring setup that is \n\n> self hosted on a cloud\n\n> uses proxy\n\n> has a visual change threshold regulator(like only alert when change of specified are/region is over 20%)\n\n> notifies via telegram with the screenshot of the cropped region we are monitoring. \n\n> ah yes, a couple browser steps like click a button, wait for some seconds before monitoring \n\nI tried changedetection(dot)io setup but have been experiencing issues like random errors as shown in the attached image, unable to get alerts for cropped region only, etc \n\nI want to know what\u2019s my best way out now, I have invested many hrs into this and want to achieve the aim fast, \n\n> shall I have someone code a program specifically for this? \n\n> is there some way to fix my existing changedetection setup? \n\n> are there other options than changedetection that could be better? \n\n> maybe some other option that I don\u2019t know exists ",
    "created_utc": 1746223945.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kdddim/website_monitoring_program/",
    "score": 1,
    "num_comments": 4
  },
  {
    "subreddit": "AskProgramming",
    "title": "video to binary code",
    "text": "hello guys i don't know if the idea i want to tell is crazy or stupid or just not possible since i don't know the p of programming and the c of coding(i am not familiar with coding). it's long please read patiently.\n\ni wanted unlimited storage space without paying a penny. this strange idea came to mind that youtube provide practically unlimited storage with decent speeds too. i basically want to upload pirated movies but you know the copyright , even if i want the video just for myself and set it to private. so why not convert the video file into textual binary code form .\n\nthen take screenshots of the binary codes scren by screen. then assembling all screenshots as frames of a video.( all above works should be automated ofcourse using coding. no one is free to take thousands of screenshots)\n\nthen the video whoose frames are typically screenshots get uploaded to youtube. youtube can't catch me because the original code is never imprinted the code of the video file i uploaded. it will look like random numbers just appearing in a video.\n\nthen to retreive the movie just download the youtube video extract all frames as .png . then use text recognition to easily get the code in text form and bang you get the video.\n\ni think it may have many problems or just it can't be automated. or it may be a hell lot of work and take a lot of time to not be feasible. i don't know anything about coding please enlighten me i i made a completely stupid statement.\n\nthanks please share your thoughts. again i'm a total newbie and don't know anything\n\nedit: thankyou everyone who provided valuable suggestions i will look into it. also thank you to those guys who pointed towards the risks and legal consequences i'm not doing this idea cause i don't want cops on my door. someone suggested a method to create a lot of gmail account and use their drive space, well i'm already doing it. i will probably look for other free cloud storages. if anyone in the future come up with a good idea please comment i will be active in this discussion p:)",
    "created_utc": 1746208282.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kd79jx/video_to_binary_code/",
    "score": 0,
    "num_comments": 58
  },
  {
    "subreddit": "AskProgramming",
    "title": "Hi programmers / veterans!",
    "text": "Hi everyone or anyone who is reading this! I really need your support or advice! My boyfriend is currently self training himself to learn programming/coding. He\u2019s been learning to do pythons have learned Java script and is currently stuck wanting to be a bug bounty. He had a breakdown last night because he believes he will waste his life not being able to achieve anything and I don\u2019t want him to give up on his dream, is there any programming/coding work that he could achieve or do? He\u2019s spent his entire life wanting to do this and I don\u2019t want him to give up!! Any advice will be heavily appreciated!",
    "created_utc": 1746206329.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kd6h8w/hi_programmers_veterans/",
    "score": 2,
    "num_comments": 8
  },
  {
    "subreddit": "AskProgramming",
    "title": "Choosing a language that would make it easier to host web apps in the most popular computing resources",
    "text": "I'm not a professional developer, but I like to create small web apps and websites, using PHP in the backend. I love PHP, but I would like to switch to a model where I could start to use serverless resources such as Cloudflare Workers, AWS Lambda, Azure Functions etc..., learning a language that would also let me use my own webserver as well (so far I use Apache), but then also being able to start to create executable apps, compiled.\n\nIs there a single language that would help me make the best of it all? My first thought was leaning how to use things like Node.js and JavaScript, but then I found out that Python is supported by all those resources I mentioned, I can use it with Apache, and I guess it can be compiled although I don't know if it would be optimal for this. And what about C#: would it be too hard, or rather, would the learning curve be a lot larger?\n\nOr maybe I should forget about having one single language? In this case, and focusing on web apps that would have basically all the logic on the server side: should I pick JavaScript or Python to the backend, or any other one? One thing I like about PHP is that you can have a lot of HTML in the source with bits of PHP code, if I want: would I find this in any other possibility?",
    "created_utc": 1746194108.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kd1jvs/choosing_a_language_that_would_make_it_easier_to/",
    "score": 0,
    "num_comments": 22
  },
  {
    "subreddit": "AskProgramming",
    "title": "Programmers where do you get cool shirts?",
    "text": "My partner is into programming and 3D printing. He loves shirts with science stuff, robots, space, video games. Please tell me where you guys get cool t shirts. \n\nYes I tried Google, but what I come up with is a bit too corny or on the nose. Can you guys help? \n\nMy partner is a practical guy and clothes are the last thing on his mind. The beloved Samus shirt is see through. Holes are appearing on the rest. \n\nHe doesn't care if i help him shop, but the fabric has to be \"good.\" I take that to mean the softer, stretchy t shirts and not the starchy cotton ones.\n\nDoes anybody have a website store they really like?",
    "created_utc": 1746192302.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kd0vwp/programmers_where_do_you_get_cool_shirts/",
    "score": 10,
    "num_comments": 48
  },
  {
    "subreddit": "AskProgramming",
    "title": "What design pattern should I use to pass data between a C# and a C++ WinUI 3 project (both ways)?",
    "text": "I'm building a WinUI 3 app where I have two separate projects \u2014 one in **C#** and one in **C++/WinRT**. I need to enable **two-way communication** between them.\n\nNot just triggering events \u2014 I want to **pass variable data** or structured objects between the two. For example, C++ might generate some data that C# needs to process, and C# might hold UI state that C++ needs to reference.\n\nI know about the WinRT interop path \u2014 like making a project a WinRT component by adding this to the `.csproj` file:\n\n    <CsWinRTComponent>true</CsWinRTComponent>\n\nThat allows me to expose public types from C# to C++ via the generated `.winmd`. So technically I can share a \u201cbridge\u201d class between both sides.\n\nBut now I\u2019m wondering:\n\n**What\u2019s the best design pattern to structure this communication?**  \nI\u2019ve looked into things like the Mediator pattern, but I\u2019m not set on anything yet.\n\nMy main goals:\n\n* Clean separation between C# and C++\n* Ability to send/receive both **events** and **data**\n* Avoid overcomplicating the architecture if a simpler pattern works\n\nAny recommendations on what pattern or approach fits this kind of setup?\n\nThanks!\n\nEdit: I forgot to mention the project is public on GitHub, so it's much helpful to share the link - [https://github.com/KrishBaidya/LlamaRun/](https://github.com/KrishBaidya/LlamaRun/)",
    "created_utc": 1746176186.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kcwawt/what_design_pattern_should_i_use_to_pass_data/",
    "score": 4,
    "num_comments": 17
  },
  {
    "subreddit": "AskProgramming",
    "title": "Python script for renaming files and copying them",
    "text": "I have a large directory with many subfolders in which pictures are laying all around. I want to collect them all in one folder without any subfolders. Some pictures have the same name, so I thought there could be a method using python to rename them with an i++ to rising numbers to make sure they are all named differently. I tried around yesterday but couldn't figure out how to go trough all folders and rename all the files. Can anyone help me with this please? \ud83d\ude4f\ud83d\ude07\nBonus points if you add a function which copies the files to one combined folder after renaming them. ",
    "created_utc": 1746171570.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kcv9ka/python_script_for_renaming_files_and_copying_them/",
    "score": 1,
    "num_comments": 1
  },
  {
    "subreddit": "AskProgramming",
    "title": "My Challenging Probation Period at a New Job",
    "text": "I recently started a job as a backend developer at a fintech company, and my probation period has been unexpectedly difficult. I'm looking for advice on how to navigate this situation.\n\n# The Issues I've Been Facing:\n\n* **No onboarding process** despite my multiple requests. Eventually, we agreed that a senior dev would write some documentation about the project architecture and show examples of business processes in the code. Still no docs\n* **Our team lead quit just 4 days after I started**, and I inherited many of his responsibilities without any proper handover. I was managing by consulting with another senior developer.\n* **Three weeks later, that senior developer also became unavailable** (for personal reasons, not fired but completely unavailable).\n* Now it's just me and one mid-level developer handling the backend. The other dev has always worked on different microservices, so I have nobody to ask questions or get guidance from.\n* **Nobody has reviewed my code for the last 10 days**, and I'm concerned that when we use what I've built, we'll discover many issues (previously we had regular code reviews).\n\n# The Frustrating Part:\n\nI was actually starting to get comfortable with the project (it's been about a month now). I think I could have been fully comfortable by the end of my probation period, but everything went sideways. Now we're supposed to push to production.\n\nThe company is looking for a new team lead and backend developer for this project, but they haven't found anyone yet. It feels like I just had bad timing joining when I did.\n\nI don't dislike the company and would like to stay, but I'm worried about being fired simply because I joined during a difficult transition period.\n\n# My Background:\n\nDuring the interview, I was completely honest. I told them I was junior+ with a couple years of experience on smaller projects (the current one is fintech at a large company), not yet mid-level. They hired me as a mid-level developer anyway but didn't provide the support I would have expected given the circumstances.\n\n# Question:\n\nWhat can I do to minimize my chances of being fired? How should I approach this situation professionally?\n\nAny advice would be greatly appreciated!",
    "created_utc": 1746165797.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kctx0j/my_challenging_probation_period_at_a_new_job/",
    "score": 7,
    "num_comments": 11
  },
  {
    "subreddit": "AskProgramming",
    "title": "What\u2019s One Programming Habit You\u2019ve Dropped Thanks to AI ?",
    "text": "With AI getting better at catching errors, generating boilerplate, or even suggesting logic, I\u2019ve noticed I no longer obsess over things like function naming or retyping the same patterns. Just what habits have you ditched (good or bad) now that if you rely on AI for programming?",
    "created_utc": 1746158250.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kcrxe7/whats_one_programming_habit_youve_dropped_thanks/",
    "score": 0,
    "num_comments": 29
  },
  {
    "subreddit": "AskProgramming",
    "title": "What should I learn next for backend in Spring/Java?",
    "text": "I am in backend. I understand some concepts but when senior developers talk anything deep (security/networking/production issues), I find it hard to follow. Is it possible to upskill by reading books(and implementing concepts)/GitHub code etc? I will eventually learn by experience. But want to fast track. I like diving deep into tech. Books I've read so far:\n\n1. Spring Start Here\n2. Spring In Action\n3. Core Java vol 1 and 2 by Cay horstmann\n4. Kafka the definitive guide\n5. Mastering Kafka streams and KsqlDB\n6. Clean Code, Clean Architecture by Uncle Bob\n7. Mongodb the definitive guide\n8. Docker deep dive and Kubernetes book by Nigel Poulton\n9. Currently reading head first design patterns and building microservices.\n\nCan anyone please suggest more resources? Will be ever grateful. For reference I'm a fresher",
    "created_utc": 1746155481.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kcr4ow/what_should_i_learn_next_for_backend_in_springjava/",
    "score": 1,
    "num_comments": 6
  },
  {
    "subreddit": "AskProgramming",
    "title": "Help learning Typescript for Next.js and React",
    "text": "Next week I'll start applying to jobs, I'm a fullstack with frontend focus and main stacks are Next.js and MERN, I've been studying, developing projects and working for the past 3 years but I've never used Typescript always JSX, because it seemed dumb.\n\nNow because I need an enterprise job it a good plus to have that, I've been practicing TS for the past 2 weeks but I find it hard practicing fucking basic exercises that have no real use case.\n\nAny resources for learning this ASAP are appreciated as well as any tips you may have. ",
    "created_utc": 1746133539.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kcjn0s/help_learning_typescript_for_nextjs_and_react/",
    "score": 1,
    "num_comments": 16
  },
  {
    "subreddit": "AskProgramming",
    "title": "Professional dev looking for some guidance on how to get started in the mobile/cross-platform world",
    "text": "Hello! So, I have an idea for an application that I would like to make that will be cross-platform. Primarily, this app will need to be able to work on any device you are on, including locally as a desktop app. It will have the following very broad specs:\n\n1. Central server for syncing and storing data.\n2. Offline mode where server sync happens once online.\n3. Offline-only mode (local storage).\n4. Useable on iOS and Android.\n5. Useable on the web.\n6. Useable on the desktop (electron or native desktop app, not sure which).\n\nThe core of this project will be the backend. In its most essential form, this application should be useable from the linux terminal, where all the rest of the functionality is just giving a good face to it. That is, I want the back-end to be entirely divorced from the front-end, so that the front-end technologies can vary freely from the back-end.\n\nThe programming languages that I am best at are C#, Python, and C (in that order), but at this point in my career the language doesn't really matter. I just want to be setting myself up for success with such a highly cross-platform application.\n\nMy current experience has been pretty much limited to desktop and web development so I haven't had any experience with doing something so cross-platform before, and looking at information online, I don't know what decision I should be making here, or what direction to go in. I've seen Flutter and Dart recommended, but if I go that route, does the backend have to be in Dart? Could I still do the backend in C#, writing it as an API, and then just compile it targetting the specific systems, and then have my front-end interact with this API? Or if I go the C# route, am I absolutely locked in to having to use MAUI/Xamarin/Blazor Hybrid? What about if I go the Python route? I just fundamentally don't know if I can use these languages raw and have them be executing as an application on mobile devices.\n\nIn general, I am very new to this and I am looking to get some information from people with experience building real applications that have targetted mobile as part of a cross-platform approach, and if you have any advice on what technologies to use, if my existing experience in especially .NET can be leveraged, or if it's best to switch to a more mobile-friendly back-end language even if I'm also targetting desktop (again, possibly with electron), and, in its simplest form, the linux terminal.\n\nAny and all information would be very valuable, as well as any experience you have with this and any hiccoughs you think I should be watching out for. Ideally I'll find a front-end dev to help with this project at some point as though I am a full-stack dev, my skillset is heavily in the back-end as I suck at art.\n\nThank you!",
    "created_utc": 1746101196.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kc731s/professional_dev_looking_for_some_guidance_on_how/",
    "score": 2,
    "num_comments": 8
  },
  {
    "subreddit": "AskProgramming",
    "title": "Should I specialize in video game development in university ? Will it ruin my job prospects ?",
    "text": "I'm a 22 year old computer science student. I'm on my 3rd year of a 5 year master's degree. Unfortunately my university doesn't offer the option of a bachelor's degree. Only a master's degree. I'm planning on immigrating after graduation.\n\nIn my university the first 3 years are spent learning common computer science stuff: some web development, some software engineering and many different programming languages. The next 2 years you specialize in a specific field of computer science like mobile apps, data science, software engineering, web development etc etc. I'm thinking of specializing in either software engineering or video game development.\n\nThe thing is I'm not passionate about computer science. I'm only doing it because it's the best path for immigration. i don't like it because It has a very low margin of error. It's stressful and I'm not passionate about the final product (software/websites). Although I know some people are passionate about it and I definetly respect that!\n\nSo I'm thinking about video game development because I might be into the product that I'm developing. But on the other hand software engineering opens up more job opportunities. But on the other hand, again, I already studied it during the first 3 years and many people who graduate from my university can get jobs in different fields than the one they specialized in, so even if I specialize in video game development I might get a software engineering job.\n\nMy biggest priority is immigrating and I hope to do that by being able to land a job abroad.\n\nAny advice is welcome!",
    "created_utc": 1746101116.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kc724x/should_i_specialize_in_video_game_development_in/",
    "score": 0,
    "num_comments": 6
  },
  {
    "subreddit": "AskProgramming",
    "title": "Why is \"Consistency\" part of ACID if the schema already enforces constraints?",
    "text": "Hey folks,\n\nWe know that in ACID, the \"C\" stands for Consistency meaning that a transaction should move the database from one valid state to another, preserving all rules, constraints, and invariants.\n\nBut here's the thing:\u00a0**don\u2019t schemas already enforce those rules?**\u00a0For example, constraints like\u00a0`NOT NULL`,\u00a0`UNIQUE`,\u00a0`CHECK`, and\u00a0`FOREIGN KEY`\u00a0are all defined at the schema level. So even if I insert data outside of a transaction, the DB will still throw an error if the data violates the schema.\n\nSo I asked myself:\u00a0**Why is Consistency even part of ACID if schema constraints already guarantee it? Isn\u2019t that redundant?**",
    "created_utc": 1746093314.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kc4xqi/why_is_consistency_part_of_acid_if_the_schema/",
    "score": 1,
    "num_comments": 7
  },
  {
    "subreddit": "AskProgramming",
    "title": "Should I quit Programming?",
    "text": "Bad question I know, but I just feel so defeated. \n\nI'm 26 soon to be 27. Since I was a kid I thought I wanted to make video games, I took 3 computer science classes in highschool, and some basic ones in community college. After I got a general associates I stopped going to school for 5 ish years cause of my bad grades and I joined the military. I studied a little bit of computer science stuff before trying to go back to it. Right now I'm taking a singular coding class and I feel like I can do well creating the programs asked of me but it's been taking me longer and longer to complete asignments and I find I'm getting more frustrated hitting these walls, this most recent project I've spent around 30 hours for such minimal progress and yet so much frustration. I spent all this time creating a binary tree for this given example just to realize I'm not even using it correctly which was the entire point of the assignment, and so now I have to rethink my whole program and rewrite so much, it's all just so demoralizing. I can't help but feel like if it frustrates me this much do I even want to really be studying this? What else would I even do? I know this is mostly just me venting sorry, it just feels terrible.\n\nTLDR; I've spent my whole life saying I wanted to be a programmer but if it's so frustrating that I can't finish my assignments is it even worth pursuing?\n\nEdit: It's the next day, and I'm at my public library working again on this project. Thank you all for your kind words, I've read all of them, and I'll respond to them once I can. While this project IS frustrating it was definitely more than just coding, it was \"This project is late and I haven't even started the project that was due yesterday and if I don't get a B in this class I\u2019ll have to retake it which means my university might dismiss me or I'll get my bachelor's after i turn 30 and...\" You get the idea. I have a bad habit of overthinking and connecting potential bad consequences and my sense of worth to things I care about so if it wasn't coding it'd be something else, and I know I've enjoyed parts of coding before. This is just a feeling I have to learn to navigate. Your messages helped me feel a lot better and understand better, and even the negative ones helped me feel justified/heard in the moment. I still feel kinda bad, I have to accept that life is hard, and it'll always be hard. I'll be alright, though. Thank you all again.",
    "created_utc": 1746061591.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kbwku4/should_i_quit_programming/",
    "score": 22,
    "num_comments": 48
  },
  {
    "subreddit": "AskProgramming",
    "title": "Freelance programmers: how do you price your work?",
    "text": "Do you do it by the job, by the hour, or some other metric?\n\nI ask because I just got back into coding, and a friend of mine asked me to write some software for his store. It is for FinCEN compliance, and I have to take the store's data and convert it into an XML document.\n\nI'm almost to the deployment stage, and I'm not sure what I should consider in the price I quote him. Any help would be appreciated. Thank you!",
    "created_utc": 1746051645.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kbt54c/freelance_programmers_how_do_you_price_your_work/",
    "score": 9,
    "num_comments": 26
  },
  {
    "subreddit": "AskProgramming",
    "title": "Fuzzy String Matching",
    "text": "Hi, I currently have the following problem which I have problems with solving in Python. \n\n[Problem] \nAssume you have a string A, and a very long string (let's say a book), B. We want to find string A inside B, BUT! A is not inside B with a 100% accuracy; hence fuzzy string search. \n\nHave anyone been dealing with an issue similar to this who would like to share their experience? Maybe there is an entirely different approach I'm not seeing? \n\nThank you so much in advance! ",
    "created_utc": 1746047735.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kbrmex/fuzzy_string_matching/",
    "score": 0,
    "num_comments": 26
  },
  {
    "subreddit": "AskProgramming",
    "title": "Any library on python can handle dwg files",
    "text": "Hi I want to build an application use architecture plans as an input and with the help of ai extract data from that plans any idea",
    "created_utc": 1746034978.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kbmkk9/any_library_on_python_can_handle_dwg_files/",
    "score": 1,
    "num_comments": 2
  },
  {
    "subreddit": "AskProgramming",
    "title": "Largest Square in Histogram",
    "text": "I came across the question largest rectangle in a histogram ([leetcode](https://leetcode.com/problems/largest-rectangle-in-histogram/description/)). I was wondering what if we were asked to find the largest square. I came across this [article](https://stackoverflow.com/questions/63427391/find-the-largest-square-in-a-histogram) on stackoverflow. But i am not able to even understand the brute force way to solve this. Can anyone please help?",
    "created_utc": 1746032479.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kblk1p/largest_square_in_histogram/",
    "score": 1,
    "num_comments": 1
  },
  {
    "subreddit": "AskProgramming",
    "title": "Question about making web viewing application for andorid (c++)",
    "text": "Hello I am an university student from japan. I am currently working on a project of making a website viewer application for our university because our unversity dosen't have a great website for mobile environments and I wanted to help our university students in need.I currently have an major problem of adding a feature for the application. I'm using c++(visual studio) and the other plugin/addons I am using is Qt creator and android studio.  \nI want to add a feature that saves the id and password while logging in like other browsers like chorme do. So when we log in after we can easily log in with a click of a button but sadly the university website dosen't support any thing similar to that so I have a hard time making it from scratch.  \nI tried checking the diffrent html elements after logging in making a pop up screen come up if you want to save the id/password but I don't think it works properly.Can you help me where I can find how to save the id and password inside the mobile application without using a database (sorry for my bad english)",
    "created_utc": 1746018716.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kbg4ux/question_about_making_web_viewing_application_for/",
    "score": 1,
    "num_comments": 9
  },
  {
    "subreddit": "AskProgramming",
    "title": "Ideas for Final Year Project (Need Advice)",
    "text": "Hi Everyone,\n\nI hope you're doing well! I\u2019m currently looking for advice and suggestions for my Final Year Project (FYP) as part of my BSCS degree. We are a team of two and are hoping to work on a project that is:\n\n\u2022 Feasible within our timeline and skill level,\n\n\u2022 Complex enough to justify the contribution of two people,\n\n\u2022 And ideally, something that offers practical value\u2014whether as a usable product, a helpful tool, or something with real-world impact.\n\n\u2022 Total 8 modules are required with atleast one AI module. UI is also a mandatory one. We can also incorporate cloud (AWS) as we have some experience with it. Please give us some robust idea with a little bit of roadmap to accomplish this task.",
    "created_utc": 1746000557.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kbb833/ideas_for_final_year_project_need_advice/",
    "score": 3,
    "num_comments": 3
  },
  {
    "subreddit": "AskProgramming",
    "title": "Are tables frequently used in html?",
    "text": "Hello, I've been studying html and css for almost a month, and I remember having studied tables in html, but a friend of mine, who works as a full stack web developer, told me that I could leave that subject behind because they're rarely used and I could learn it at the moment if I needed to. Right now though, there's a video in the css course that I'm watching that it's talking about tables, specifically how to personalize their style and make them \"look good\". What I've been wondering is: Are tables actually used enough to be considered important to learn?  \nThank you early for your help.",
    "created_utc": 1745992522.0,
    "url": "https://www.reddit.com/r/AskProgramming/comments/1kb9cav/are_tables_frequently_used_in_html/",
    "score": 2,
    "num_comments": 52
  },
  {
    "subreddit": "machinelearning",
    "title": "Extract participant names from a Google Meet screen recording[P]",
    "text": "I'm working on a project to extract participant names from Google Meet screen recordings.\u00a0So far, I've successfully cropped each participant's video tile and applied EasyOCR to the bottom-left corner where names typically appear.\u00a0While this approach yields correct results about 80% of the time, I'm encountering inconsistencies due to OCR errors.\n\n**Example:**\n\n* **Frame 1:**\u00a0Ali Veliyev\n* **Frame 2:**\u00a0Ali Veliye\n* **Frame 3:**\u00a0Ali Velyev\n\nThese minor variations are affecting the reliability of the extracted data.\n\n**My Questions:**\n\n1. **Alternative OCR Tools:**\u00a0Are there more robust open-source OCR tools that offer better accuracy than EasyOCR and can run efficiently on a CPU?\n2. **Probabilistic Approaches:**\u00a0Is there a method to leverage the similarity of text across consecutive frames to improve accuracy? For instance, implementing a probabilistic model that considers temporal consistency.\n3. **Preprocessing Techniques:**\u00a0What image preprocessing steps (e.g., denoising, contrast adjustment) could enhance OCR performance on video frames?\n4. **Post-processing Strategies:**\u00a0Are there effective post-processing techniques to correct OCR errors, such as using language models or dictionaries to validate and fix recognized names?\n\n**Constraints:**\n\n* The solution must operate on CPU-only systems.\n* Real-time processing is not required; batch processing is acceptable.\n* The recordings vary in resolution and quality.\n\nAny suggestions or guidance on improving the accuracy and reliability of name extraction from these recordings would be greatly appreciated.",
    "created_utc": 1746472878.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kfkch5/extract_participant_names_from_a_google_meet/",
    "score": 1,
    "num_comments": 0
  },
  {
    "subreddit": "machinelearning",
    "title": "[Project] Building a tool to generate synthetic datasets",
    "text": "Hey everyone, I\u2019m a college student working on a side project that lets users generate synthetic datasets, either from their own materials or from scratch through deep research and modeling. The idea is to help with things like fine-tuning models, testing out ideas, building prototypes, or really any task where you need data but can\u2019t find exactly what you\u2019re looking for.\n\nIt started as something I needed for my own work, but now I\u2019m building it into a more usable tool. I\u2019m planning to share a prototype here in a day or two, and I\u2019m also thinking of open-sourcing it so others can build on top of it or use it in their own projects.\n\nWould love to hear what you think. Has this been a problem you\u2019ve run into before? What would you want a tool like this to handle well?",
    "created_utc": 1746500459.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kfugcz/project_building_a_tool_to_generate_synthetic/",
    "score": 0,
    "num_comments": 0
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] Top AI Research Tools",
    "text": "|Tool|Description|\n|:-|:-|\n|[NotebookLM](https://notebooklm.google.com/)|NotebookLM is an AI-powered research and note-taking tool developed by Google, designed to assist users in summarizing and organizing information effectively. NotebookLM leverages Google Gemini to provide quick insights and streamline content workflows for various purposes, including the creation of podcasts and mind-maps.|\n|[Macro](https://macro.com/)|Macro is an AI-powered workspace that allows you to chat, collaborate, and edit PDFs, documents, notes, code, and diagrams in one place. The platform offers built-in editors, AI chat with access to the top LLMs (including Claude 3.7), instant contextual understanding via highlighting, and secure document management, making it optimal for both individuals and enterprises.|\n|[Notion](https://www.notion.com/)|Notion is a productivity and collaboration tool that combines note-taking, task management, and database features into a single platform. Notion allows teams and individuals to capture ideas, manage projects, and customize workflows (or automations), including integration with Notion AI.|\n|[Perplexity](https://www.perplexity.ai/)|Perplexity AI is an advanced AI-driven platform designed to provide accurate and relevant search results through natural language queries. Perplexity combines machine learning and natural language processing to deliver real-time, reliable information with citations.|\n|[Elicit](https://elicit.com/)|Elicit is an AI-enabled tool designed to automate time-consuming research tasks such as summarizing papers, extracting data, and synthesizing findings. The platform significantly reduces the time required for systematic reviews, enabling researchers to analyze more evidence accurately and efficiently.|\n|[Paperpal](https://paperpal.com/)|Paperpal offers a suite of AI-powered tools designed to improve academic writing. The research and grammar tool provides features such as real-time grammar and language checks, plagiarism detection, contextual writing suggestions, and citation management, helping researchers and students produce high-quality manuscripts efficiently.|\n|[SciSpace](https://scispace.com/)|SciSpace is an AI-powered platform that helps users find, understand, and learn research papers quickly and efficiently. The tool provides simple explanations and instant answers for every paper read.|\n|[Recall](https://www.getrecall.ai/)|Recall is a tool that transforms scattered content into a self-organizing knowledge base that grows smarter the more you use it. The features include instant summaries, interactive chat, augmented browsing, and secure storage, making information management efficient and effective.|\n|[Semantic Scholar](https://www.semanticscholar.org/)|Semantic Scholar is a free, AI-powered research tool for scientific literature. It helps scholars to efficiently navigate through vast amounts of academic papers, enhancing accessibility and providing contextual insights.|\n|[Consensus](https://consensus.app/)|Consensus is an AI-powered search engine designed to help users find and understand scientific research papers quickly and efficiently. The tool offers features such as Pro Analysis and Consensus Meter, which provide insights and summaries to streamline the research process.|\n|[Humata](https://www.humata.ai/)|Humata is an advanced artificial intelligence tool that specializes in document analysis, particularly for PDFs. The tool allows users to efficiently explore, summarize, and extract insights from complex documents, offering features like citation highlights and natural language processing for enhanced usability.|\n|[Ai2 Scholar QA](https://scholarqa.allen.ai/chat)|Ai2 ScholarQA is an innovative application designed to assist researchers in conducting literature reviews by providing comprehensive answers derived from scientific literature. It leverages advanced AI techniques to synthesize information from over eight million open access papers, thereby facilitating efficient and accurate academic research.|",
    "created_utc": 1746518234.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kfyzzz/d_top_ai_research_tools/",
    "score": 5,
    "num_comments": 1
  },
  {
    "subreddit": "machinelearning",
    "title": "[P] Human Pose Detection Project (MediaPipe + YOLO)",
    "text": "Hey everyone,  \nI\u2019m working on a project with my teammates under a professor in our college. The project is about\u00a0**human pose detection**, and the goal is to not just detect poses, but also\u00a0**predict what a player might do next**\u00a0in games like basketball or football \u2014 for example, whether they\u2019re going to pass, shoot, or run.\n\nSo far, we\u2019ve chosen\u00a0**MediaPipe**\u00a0because it was easy to implement and gives a good number of body landmark points. We\u2019ve managed to label basic poses like\u00a0**sitting**\u00a0and\u00a0**standing**, and it\u2019s working. But then we hit a limitation \u2014 MediaPipe works well only for a\u00a0**single person at a time**, and in sports, obviously there are\u00a0**multiple players**.\n\nTo solve that, we integrated\u00a0**YOLO**\u00a0to detect multiple people first. Then we pass each detected person through MediaPipe for pose detection.\n\nWe\u2019ve gotten till this point, but now we\u2019re a bit stuck on how to go further.  \nWe\u2019re looking for help with:\n\n* How to\u00a0**properly integrate YOLO and MediaPipe**\u00a0together, especially for real-time usage\n* How to use our\u00a0**custom dataset**\u00a0(based on extracted keypoints) to train a model that can\u00a0**classify or predict actions**\n* Any advice on tools, libraries, or examples to follow\n\nIf anyone has worked on something similar or has any tips, we\u2019d really appreciate it. Thanks in advance for any help or suggestions",
    "created_utc": 1746516650.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kfynlg/p_human_pose_detection_project_mediapipe_yolo/",
    "score": 0,
    "num_comments": 0
  },
  {
    "subreddit": "machinelearning",
    "title": "[R] Hybrid AI for Generating Programs: a Survey",
    "text": "*Computer programming is a specialized activity that requires long training and experience to match productivity, precision and integration. It hasn\u2019t been a secret for AI practitioners to ultimately create software tools that can facilitate the role of programmers. The branch of AI dedicated to automatically generate programs from examples or some sort of specification is called program synthesis. In this dissertation, I\u2019ll explore different methods to combine symbolic AI and neural networks (like large language models) for automatically create programs. The posed question is:*\u00a0***How AI methods can be integrated for helping to synthesize programs for a wide range of applications?***\n\n[https://gfrison.com/2025/hybrid-ai-for-generating-programs](https://gfrison.com/2025/hybrid-ai-for-generating-programs)  \n",
    "created_utc": 1746510719.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kfx9hw/r_hybrid_ai_for_generating_programs_a_survey/",
    "score": 1,
    "num_comments": 0
  },
  {
    "subreddit": "machinelearning",
    "title": "[Project] Overfitting in Encoder-Decoder Seq2Seq.",
    "text": "Hello guys! I am currently working on a project to predict Leaf Area Index (LAI), a continuous value that ranges from 0 to 7. The prediction is carried out backwards, since the interest is to get data from the era when satellites couldn't gather this information. To do so, for each location (data point), the target are the 12 values of LAI  (a value per month), and the predictor variables are the 12 values of LAI of the next year (remember we predict backwards) and 27 static yearly variables. So the architecture being used is an encoder decoder, where the encoder receives the 12 months of the next year in reversed order Dec -> Jan (each month is a time step) and the decoder receives as input at each time step the prediction of the last time step (autoregressive) and the static yearly variables as input. At each time step of the decoder, a Fully Connected is used to transform the hidden state into the prediction of the month (also in reverse order). A dot product attention mechanism is also implemented, where the attention scores are also concatenated to the input of the decoder. I attach a diagram (no attention in the diagram):\n\nhttps://preview.redd.it/kxa5ankhswye1.png?width=3656&format=png&auto=webp&s=369290f134ea2612bad4e839a1903e58eefa47f0\n\nImportant: the data used to predict has to remain unchanged, because at the moment I won't have time to play with that, but any suggestions will be considered for the future work chapter.\n\nTo train the model, the globe is divided into regions to avoid memory issues. Each region has around 15 million data points per year (before filtering out ocean locations), and at the moment I am using 4 years of training 1 validation and 1 test.\n\nThe problem is that LAI is naturally very skewed towards 0 values in land locations. For instance, this is the an example of distribution for region 25:\n\nhttps://preview.redd.it/sgfxaqsvswye1.png?width=1000&format=png&auto=webp&s=2fd9fa226be1c9fd954aec0fa1d933d9786df45d\n\nAnd the results of training for this region always look similar to this:\n\nhttps://preview.redd.it/39g7aof7twye1.png?width=1000&format=png&auto=webp&s=c389eedf02e605fd294dc1a3d60b211bf53b1daa\n\nIn this case, I think the problem is pretty clear since data is \"unbalanced\".\n\nThe distribution of region 11, which belongs to a part of the Amazon Rainforest, looks like this:\n\nhttps://preview.redd.it/udy59lhitwye1.png?width=1000&format=png&auto=webp&s=f5b607b3b00bb8f4576debb8daea8efb2524dff5\n\nWhich is a bit better, but again, training looks the following for this region in the best cases so far:\n\nhttps://preview.redd.it/28fckw2ytwye1.png?width=1000&format=png&auto=webp&s=9f53831a2c795c89affb4474c76570c22739b790\n\nAlthough this is not overfitting, the Validation loss barely improves.\n\nFor region 12, with the following distribution:\n\nhttps://preview.redd.it/r6ouxapcuwye1.png?width=1000&format=png&auto=webp&s=8b0f91eae152282d0615717c1a1c6eb27bbf3427\n\nThe results are pretty similar:\n\nhttps://preview.redd.it/epyu8378uwye1.png?width=1000&format=png&auto=webp&s=dbaf8ef7153f43397a499036202fdd0bfc1cba32\n\nWhen training over the 3 regions data at the same time, the distribution looks like this (region 25 dominates here because it has more than double the land points of the other two regions):\n\nhttps://preview.redd.it/a3vuuc7huwye1.png?width=1000&format=png&auto=webp&s=0ab839c8d13a28f759cf46d04d2d20b37da85176\n\nAnd same problem with training:\n\nhttps://preview.redd.it/ulmnz3ccvwye1.png?width=1000&format=png&auto=webp&s=b92498fc213ce7f0b7c94884307038ccfc87f762\n\nAt the moment I am using this parameters for the network:\n\n    BackwardLAIPredictor(\n      (dropout): Dropout(p=0.3, inplace=False)\n      (encoder_rnn): LSTM(1, 32, batch_first=True)\n      (decoder_rnn): LSTM(60, 32, batch_first=True)\n      (fc): Linear(in_features=32, out_features=1, bias=True)\n    )\n\nThe implementation also supports using vanilla RNN and GRU, and I have tried several dropout and weight decay values (L2 regularization for ADAM optimizer, which I am using with learning rate 1e-3), also using several teacher forcing rations and early stopping patience epochs. Results barely change (or are worse), this plots are of the \"best\" configurations I found so far. I also tried increasing hidden size to 64 and 128 but 32 seemed to give consistently the best results. Since there is so much training data (4 years per 11 milion per year in some cases), I am also using a pretty big batch size (16384) to have at least fast trainings, since with this it takes around a minute per epoch. My idea to better evaluate the performance of the network was to select a region or a mix of regions that combined have a fairly balanced distribution of values, and see how it goes training there.\n\nAn important detail is that I am doing this to benchmark performance of this deep learning network with the baseline approach which is XGBoost. At the moment performance is extremely similar in test set, for region 25 XGBoost has slightly better metrics and for rgion 11 the encoder-decoder has slightly better ones.\n\nI haven tried using more layers or a more complex architecture since overfitting seems to be a problem with this already \"simple\" architecture.\n\nI would appreciate any insights, suggestions or comments in general that you might have to help me guys.\n\nThank you and sorry for this long explanation.",
    "created_utc": 1746438654.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kf7ok9/project_overfitting_in_encoderdecoder_seq2seq/",
    "score": 4,
    "num_comments": 3
  },
  {
    "subreddit": "machinelearning",
    "title": "[P] An Enterprise-level Retrieval-Augmented Generation System (full code open-sourced and explained)",
    "text": "How can we search the wanted key information from **10,000+ pages of PDFs** within **2.5 hours**? For fact check, how do we implement it so that answers are backed by **page-level references**, minimizing hallucinations?\n\n[RAG-Challenge-2](https://github.com/IlyaRice/RAG-Challenge-2/tree/main) is a great open-source project by Ilya Rice that ranked 1st at the [Enterprise RAG Challenge](https://abdullin.com/erc/), which has 4500+ lines of code for implementing a high-performing RAG system. It might seem overwhelming to newcomers who are just beginning to learn this technology. Therefore, to help you get started quickly\u2014and to motivate myself to learn its ins and outs\u2014I\u2019ve created a complete tutorial on this.\n\nLet's start by outlining its workflow\n\n[Workflow](https://preview.redd.it/w1arnhus6uye1.png?width=528&format=png&auto=webp&s=8094b34fb621bd783ddfffe07352392f553b2e22)\n\nIt's quite easy to follow each step in the above workflow, where multiple tools are used: Docling for parsing PDFs, LangChain for chunking text, faiss for vectorization and similarity searching, and chatgpt for LLMs.\n\nBesides, I also outline the codeflow, demonstrating the running logic involving multiple python files where starters can easily get lost. Different files are colored differently.\n\nhttps://preview.redd.it/94di2cjk7uye1.png?width=393&format=png&auto=webp&s=4b66db4aa1086e26652a7eebf9989e48b3c0aac2\n\nThe codeflow can be seen like this. The purpose of showing this is not letting you memorize all of these file relationships. It works better for you to check the source code yourself and use this as a reference if you find yourself lost in the code.\n\nhttps://preview.redd.it/vyzz29pu7uye1.png?width=684&format=png&auto=webp&s=06b36a55a19b88a2590d795ecdad3b187098c06e\n\nNext, we can customize the prompts for our own needs. In this tutorial, I saved all web pages from this [website](https://comfyai.app/about) into PDFs as technical notes. Then modify the prompts to adapt to this case. For example, we use few-shot learning to help the LLMs better understand what questions to expect and what format the response should be. Below is the prompts **RephrasedQuestionsPrompt** for rephrasing comparative question into subquestions:\n\n    Example:\n    Input:\n    Original comparative question: 'Which chapter had content about positional encoding, \"LLM components\" or \"LLM post-training\"?'\n    Chapters mentioned: \"LLM components\", \"LLM post-training\"\n    \n    Output:\n    {\n        \"questions\": [\n            {\n                \"chapter_name\": \"LLM components\",\n                \"question\": \"What contents does LLM components have?\"\n            },\n            {\n                \"chapter_name\": \"LLM post-training\", \n                \"question\": \"What contents does LLM post-training have?\"\n            }\n        ]\n    }\n\n  \nThe original project of Ilya Rice design its RAG system for answering questions of annual reports from companies, so he only designed three types of question response format for that challenge: a `name`, a `number`, or a `boolean`. But to ask questions about technical stuff, we absolutely ask general questions like **How does RoPE work?** to know about some concepts and the like\n\nTherefore, I further modify the system logic to fit this need by customizing an **AnswerWithRAGContextExplanationPrompt** class and automatically matching the most related chapter and corresponding pages via searching through all faiss databases (only retrieve the top-1)\n\nThe final performance is demonstrated below (not cherry-picked, only tested once).\n\n* **How does RoPE work?**\n\n&#8203;\n\n    {\n      \"question_text\": \"How does RoPE work?\",\n      \"kind\": \"explanation\",\n      \"value\": \"RoPE, or Rotary Positional Embedding, operates by applying position-dependent rotations to token embeddings. Specifically, it splits each embedding into two parts, treats these as the real and imaginary components of a complex number, and multiplies them by a complex rotation factor derived from sine and cosine functions with frequencies that vary by dimension. This rotation integrates positional information directly into the embeddings so that when the dot product between queries and keys is computed during attention, the resulting scores naturally reflect the relative position of tokens.\",\n      \"references\": [\n        {\n          \"pdf_sha1\": \"LLM_roadmap_1\",\n          \"page_index\": 84\n        },\n        {\n          \"pdf_sha1\": \"LLM_roadmap_1\",\n          \"page_index\": 50\n        }\n      ],\n      \"reasoning_process\": \"1. The question asks for an explanation of how RoPE (Rotary Positional Embedding) works. This requires us to describe its underlying mechanism. \\n2. We start by noting that RoPE assigns a unique rotation\u2014using sine and cosine functions\u2014to each token\u2019s embedding based on its position. \\n3. The context from page 85 shows that RoPE implements positional encoding by splitting the embedding into two halves that can be viewed as the real and imaginary parts of a complex number, then applying a rotation by multiplying these with a complex number constructed from cosine and sine values. \\n4. This approach allows the model to incorporate position information directly into the embedding by rotating the query and key vectors before the attention calculation. The rotation angles vary with token positions and are computed using different frequencies for each embedding dimension. \\n5. As a result, when the dot product between query and key is computed, it inherently captures the relative positional differences between tokens. \\n6. Furthermore, because the transformation is multiplicative and phase-based, the relative distances between tokens are encoded in a smooth, continuous manner that allows the downstream attention mechanism to be sensitive to the ordering of tokens.\"\n    }\n\nThe **LLM\\_roadmap\\_1** is the correct chapter where the RoPE is been talked about on that [website](https://comfyai.app/article/llm-components/positional-encoding#1d726e5a7de0805ab1a0c880d9378ff7). Also the referenced page is correct as well.\n\nhttps://preview.redd.it/xp56oz4qauye1.png?width=1096&format=png&auto=webp&s=7a978d24b886c3ed33bda45249991fdf07559e2a\n\n*  **What's the steps to train a nanoGPT from scratch?**\n\nLet's directly see the answers, which is also reasonable\n\n>Training nanoGPT from scratch involves several clearly defined steps. **First, set up the environment** by installing necessary libraries, using either Anaconda or Google Colab, and then **download the dataset** (e.g., tinyShakespeare). **Next, tokenize the text** into numerical representations and **split the data** into training and validation sets. **Define the model architecture** including token/positional embeddings, transformer blocks with multi-head self-attention and feed-forward networks, and layer normalization. **Configure training hyperparameters** and set up an optimizer (such as AdamW). **Proceed with a training loop** that performs forward passes, computes loss, backpropagates, and updates parameters, while **periodically evaluating performance** on both training and validation data. Finally, **use the trained model to generate new text** from a given context.\n\nAll code are provided [on Colab](https://colab.research.google.com/drive/17h602NiAsGrN7NH_yFuOPNBVTBPnFXzz?usp=sharing) and the tutorial is referenced [here](https://comfyai.app/article/llm-applications/enterprise-level-rag-hands-on-practice-II). Hope this helps!",
    "created_utc": 1746397177.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kew2j5/p_an_enterpriselevel_retrievalaugmented/",
    "score": 24,
    "num_comments": 2
  },
  {
    "subreddit": "machinelearning",
    "title": "[R] LLM vs Diffusion Models for Image Generation / Multi-Modality",
    "text": "Hi all,\n\nAs a very crude simplification, let us say that LLMs are the preferred methods for generating discrete data, and diffusion models are the preferred methods for continuous data types, like images. Of course, there is quite some hype today about discrete diffusion, but performance is still lagging behind classical autoregressive LLM (Llada, block diffusion etc.)\n\nHowever it seems that even for image generation LLM can be a serious contender, and it seems Google Gemini and OpenAI\u2019s ChatGPT are both using some LLM-based method for image generation, as they can more benefit from multi-modal properties when associated with their text generator.\n\nThus, this leads me to two questions where I hope the community will help:\n\n- Is it really true diffusion models are still state of the art for pure image generation? I know some of the best publicly available models like Stable Diffusion are diffusion-based, but I suspect there has been some bias in focusing on diffusion (historical anchor, with very good performing models obtained first, and conceptual bias because of a pleasant, principled associated mathematical framework). Is there some recent benchmark we could refer to? Is there some survey elucidating the advantages and drawbacks of LLM based image generation? Wasn\u2019t there recent work showing excellent results for a multi-scale LLM-based image generator?\n\n- What is exactly the state of multi-modal diffusion based generative models as compared to LLM based ones ? Are there existing work merging an LLM (text) and a diffusion model (image), either training them jointly, or one after the other ? Where can I find some work implementing text/image multi-modal LLM? I know of \u201cGenerative Flows\u201d by Campbell (2024) doing this with diffusion, but are there existing benchmarks comparing both approaches?\n\n\nI would greatly appreciate enlightening remarks about the existing research landscape on this subject!\n",
    "created_utc": 1746375808.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kenrvr/r_llm_vs_diffusion_models_for_image_generation/",
    "score": 4,
    "num_comments": 6
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] Unstable training curves for transformers?",
    "text": "I'm training a llama transformer (using huggingface library) model on a synthetic task:\n\ngiven a sequence of permutations on 5 elements, calculate the sequence of compositions of permutations. so if the input is (p\\_1,p\\_2,p\\_3) the output should be (p\\_1, p\\_1\\*p\\_2, p\\_1\\*p\\_2\\*p\\_3). I manually assigned indices to each permutation, so I don't use a tokenizer.\n\n  \nI'm training my model, and when the performance is starting to saturate, sometimes the training accuracy collapses, but it recovers back to the previous level in 1 epoch (I train for a total of 30-40 epochs). Has anyone else experienced something similar? I decreased the learning rate and that seemed to help.\n\n  \nAnother issue I noticed: If I generate a fresh synthetic training set and train on that, the initial training accuracy is a lot lower than before. It quickly converges to the previous accuracy and continues to improve. Maybe that is a sign of overfitting to the old training set? The strange thing is, the accuracy on a validation set is stable, so why would training accuracy drop on the new training set?\n\nMore generally, are there any resources that describe debugging tricks and heuristics when training neural networks?",
    "created_utc": 1746368464.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kekxqg/d_unstable_training_curves_for_transformers/",
    "score": 0,
    "num_comments": 2
  },
  {
    "subreddit": "machinelearning",
    "title": "[Discussion] Conditional Time Series GAN Training Stalls - Generator & Discriminator Not Improving",
    "text": "Hi everyone,\n\nI'm working on a conditional time series GAN model to generate sequences of normalized 1D time series data, conditioned on binary class labels (\"bullish\" or \"bearish\").  \nThe model consists of:\n\n* Embedder + Recovery (autoencoder pair)\n* Generator (takes noise + label as input, generates latent sequences)\n* Discriminator (distinguishes between real/fake latents, conditioned on the label)\n\nThe autoencoder portion and data preprocessing work well, but during adversarial training, the Generator and Discriminator losses don't improve. \n\nI've tried varying learning rates and adjusting training step ratios between the Generator and Discriminator. However, the adversarial training seems frozen, with no meaningful progress. Has anyone faced similar issues with conditional time series GANs? Any tips for adversarial training in such setups?\n\nThanks in advance for any help!",
    "created_utc": 1746346243.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1keer3h/discussion_conditional_time_series_gan_training/",
    "score": 0,
    "num_comments": 4
  },
  {
    "subreddit": "machinelearning",
    "title": "[P] Muyan-TTS: We built an open-source, low-latency, highly customizable TTS model for developers",
    "text": "Hi everyone,I'm a developer from the ChatPods team. Over the past year working on audio applications, we often ran into the same problem: open-source TTS models were either low quality or not fully open, making it hard to retrain and adapt. So we built [Muyan-TTS](https://github.com/MYZY-AI/Muyan-TTS), a fully open-source, low-cost model designed for easy fine-tuning and secondary development.The current version supports English best, as the training data is still relatively small. But we have open-sourced the entire training and data processing pipeline, so teams can easily adapt or expand it based on their needs. We also welcome feedback, discussions, and contributions.\n\n# You can find the project here:\n\n* arXiv paper:\u00a0[https://arxiv.org/abs/2504.19146](https://arxiv.org/abs/2504.19146)\n* GitHub:\u00a0[https://github.com/MYZY-AI/Muyan-TTS](https://github.com/MYZY-AI/Muyan-TTS)\n* HuggingFace weights:\n   * [https://huggingface.co/MYZY-AI/Muyan-TTS](https://huggingface.co/MYZY-AI/Muyan-TTS)\n   * [https://huggingface.co/MYZY-AI/Muyan-TTS-SFT](https://huggingface.co/MYZY-AI/Muyan-TTS-SFT)\n\nMuyan-TTS provides full access to model weights, training scripts, and data workflows. There are two model versions: a Base model trained on multi-speaker audio data for zero-shot TTS, and an SFT model fine-tuned on single-speaker data for better voice cloning. We also release the training code from the base model to the SFT model for speaker adaptation. It runs efficiently, generating one second of audio in about 0.33 seconds on standard GPUs, and supports lightweight fine-tuning without needing large compute resources.\n\nWe focused on solving practical issues like long-form stability, easy retrainability, and efficient deployment. The model uses a fine-tuned LLaMA-3.2-3B as the semantic encoder and an optimized SoVITS-based decoder. Data cleaning is handled through pipelines built on Whisper, FunASR, and NISQA filtering.\n\nhttps://preview.redd.it/faoiqeab3lye1.png?width=2670&format=png&auto=webp&s=667d18fd3d728ecee739f5c9924a7eb58940ccea\n\nhttps://preview.redd.it/7k786csb3lye1.png?width=5490&format=png&auto=webp&s=ce0093368c8eae06756cd57bfe516ad659bc7217\n\nFull code for each component is available in the [GitHub repo](https://github.com/MYZY-AI/Muyan-TTS).\n\n# Performance Metrics\n\nWe benchmarked Muyan-TTS against popular open-source models on standard datasets (LibriSpeech, SEED):\n\nhttps://preview.redd.it/k081cm3e3lye1.png?width=1280&format=png&auto=webp&s=2bb9e6dfdf2579c145fda4ea408f7a2fc5ce14c3\n\n# Why Open-source This?\n\nWe believe that, just like Samantha in *Her*, voice will become a core way for humans to interact with AI \u2014 making it possible for everyone to have an AI companion they can talk to anytime. Muyan-TTS is only a small step in that direction. There's still a lot of room for improvement in model design, data preparation, and training methods. We hope that others who are passionate about speech technology, TTS, or real-time voice interaction will join us on this journey.\n\n  \nWe\u2019re looking forward to your feedback, ideas, and contributions. Feel free to open an issue, send a PR, or simply leave a comment.Why Open-source This?",
    "created_utc": 1746285524.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kdvcy6/p_muyantts_we_built_an_opensource_lowlatency/",
    "score": 42,
    "num_comments": 10
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] Need Advice on Efficiently Handling and Training Large Speech Detection Dataset (150 GB WAV Files)",
    "text": "Hello everyone,\n\nI\u2019m currently training a speech detection model using PyTorch Lightning, and I have a dataset of around 150 GB of WAV audio files. Initially, I tried storing the data on Google Drive, but faced significant bottlenecks. Now, the data is stored on a hot Azure Blob storage, but I\u2019m still encountering very slow loading times, which significantly delays training.\n\nI\u2019ve tried both Google Colab and AWS environments, yet each epoch seems excessively long. Here are my specific concerns and questions:\n\nWhat are the recommended best practices for handling and efficiently loading large audio datasets (~150 GB)?\n\nHow can I precisely determine if the long epoch times are due to data loading or actual model training?\n\nAre there profiling tools or PyTorch Lightning utilities that clearly separate and highlight data loading time vs. model training time?\n\nDoes using checkpointing in PyTorch Lightning mean that the dataset is entirely reloaded for every epoch, or is there a caching mechanism?\n\nWill the subsequent epochs typically take significantly less time compared to the initial epoch (e.g., first epoch taking 39 hours, subsequent epochs being faster)?\n\nAny suggestions, tools, best practices, or personal experiences would be greatly appreciated! I know I asked like 10 questions but any advice will help I am going crazy.\n\nThanks!",
    "created_utc": 1746277093.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kdsd1e/d_need_advice_on_efficiently_handling_and/",
    "score": 13,
    "num_comments": 13
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] The leaderboard illusion paper is misleading and there are a lot of bad takes because of it",
    "text": "Recently this paper came out with the title \"The Leaderboard Illusion\". The paper critiques the lmsys leaderboard. While the contents of the paper appear to be solid and reasonable critiques, the title is clickbaity and drastically overstates the impact of the findings.\n\nThe reality is that the lmsys leaderboard remains the single best single benchmark to understand the capabilities of LLMs. You shouldn't be using a single leaderboard to dictate which large language model you use. Combine the evidence from the various public benchmarks based on your use. Then build evaluations for your specific workloads.\n\nWhat the lmsys leaderboard does is help as a first pass filter of what models to consider. If you use it for that understanding the limitations, it gives you more useful information than any other public benchmark.\n\nthe paper - [https://arxiv.org/abs/2504.20879](https://arxiv.org/abs/2504.20879)",
    "created_utc": 1746229158.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kdf8jw/d_the_leaderboard_illusion_paper_is_misleading/",
    "score": 0,
    "num_comments": 5
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] Papers/ tips for creating an activation-atlas like this google/open-ai one?",
    "text": "I want to create an activation atlas like the one made by Google and OpenAI in 2019 (https://distill.pub/2019/activation-atlas/ ). However the \"lucid\" package they used is not up-to-date.\n\nI've found some more recent feature vis packages like [https://arxiv.org/abs/2503.22399](https://arxiv.org/abs/2503.22399)  [https://adagorgun.github.io/VITAL-Project/](https://adagorgun.github.io/VITAL-Project/) but I have not found anything that could create an \"atlas\" of many classes.\n\nAnyone have any packages/ tips for creating a activation atlas? I could use an older version of tensorflow to use lucid, but I was wondering if there were any other up-to-date alternatives. Any help would be appreciated!\n\n",
    "created_utc": 1746227945.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kdetk9/d_papers_tips_for_creating_an_activationatlas/",
    "score": 7,
    "num_comments": 3
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] Don't remember the name of ML paper about how research done, maybe you know it?",
    "text": "Hi, I remember once I stumbled upon second meaning of SGD acronym, about professor sending their graduate students to keep trying everything till get something, and once they get better result - try to reason the gains and publish. There was even a paper about it on arXiv, but can't remember the name. Do you people know it?",
    "created_utc": 1746192857.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kd1399/d_dont_remember_the_name_of_ml_paper_about_how/",
    "score": 38,
    "num_comments": 6
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] Are weight offloading / weight streaming approaches like in Deepseek Zero used frequently in practice? (For enabling inference on disproportionately undersized GPUs)",
    "text": "EDIT: Deepspeed Zero, error in title\n\nAs someone from a developing nation which simply cannot afford to keep up GPU purchases with LLM scaling trends, I'm invested in the question of LLM inference in disproportionately low-VRAM environments. For example, would it be possible -- even if with low throughput -- to perform inference on a 100+ billion parameter model, on a device with only 16GB VRAM?\n\nI have looked at doing concurrent computation and host-to-device transfer using parallel CUDA streams, in a different context. The idea of streaming the weights across one by one seems interesting.\n\nI notice most, if not all, of this is available within Deepseek's libraries. \n\nHow does it work out in practice? Is there anyone here who uses Deepspeed Zero or other tools for this? Is it realistic? Is it frequently done?\n\nEdit: dammit the coffee hasn't hit yet. I meant Deepspeed ",
    "created_utc": 1746163562.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kctclw/d_are_weight_offloading_weight_streaming/",
    "score": 10,
    "num_comments": 3
  },
  {
    "subreddit": "machinelearning",
    "title": "SEFA: A Self-Calibrating Framework for Detecting Structure in Complex Data [Code Included] [R]",
    "text": "I've developed Symbolic Emergence Field Analysis (SEFA), a computational framework that bridges signal processing with information theory to identify emergent patterns in complex data. I'm sharing it here because I believe it offers a novel approach to feature extraction that could complement traditional ML methods.\n\n# Technical Approach\n\nSEFA operates through four key steps:\n\n* **Spectral Field Construction**: Starting with frequency or eigenvalue components, we construct a continuous field through weighted superposition: where `w(\u03b3\u2096) = 1/(1+\u03b3\u2096\u00b2)` provides natural regularization.`V\u2080(y) = \u2211w(\u03b3\u2096)cos(\u03b3\u2096y)`\n\n\n\n* **Multi-dimensional Feature Extraction**: We extract four complementary local features using signal processing techniques:\n\n   * **Amplitude (A)**: Envelope of analytic signal via Hilbert transform\n   * **Curvature (C)**: Second derivative of amplitude envelope\n   * **Frequency (F)**: Instantaneous frequency from phase gradient\n   * **Entropy Alignment (E)**: Local entropy in sliding windows\n\n\n\n* **Information-Theoretic Self-Calibration**: Rather than manual hyperparameter tuning, exponents \u03b1 are derived from the global information content of each feature: \n   * where `w_X = max(0, ln(B) - I_X)` is the information deficit.`\u03b1_X = p * w_X / W_total`\n\n\n\n* **Geometric Fusion**: Features combine through a generalized weighted geometric mean:`SEFA(y) = exp(\u2211\u03b1_X\u00b7ln(|X'(y)|))`\n\nThis produces a composite score field that highlights regions where multiple structural indicators align.\n\n# Exploration: Mathematical Spectra\n\nAs an intriguing test case, I applied SEFA to the non-trivial zeros of the Riemann zeta function, examining whether the resulting field might correlate with prime number locations. Results show:\n\n* AUROC \u2248 0.98 on training range \\[2,1000\\]\n* AUROC \u2248 0.83 on holdout range \\[1000,10000\\]\n* Near-random performance (AUROC \u2248 0.5) for control experiments with shuffled zeros, GUE random matrices, and synthetic targets\n\nThis suggests the framework can extract meaningful correlations that are specific to the data structure, not artifacts of the method.\n\n# Machine Learning Integration\n\nFor ML practitioners, SEFA offers several integration points:\n\n1. **Feature Engineering**: The `sefa_ml_model.py` provides scikit-learn compatible transformers that can feed into standard ML pipelines.\n2. **Anomaly Detection**: The self-calibrating nature makes SEFA potentially useful for unsupervised anomaly detection in time series or spatial data.\n3. **Model Interpretability**: The geometric and information-theoretic features provide an interpretable basis for understanding what makes certain data regions structurally distinct.\n4. **Semi-supervised Learning**: SEFA scores can help identify regions of interest in partially labeled datasets.\n\n# Important Methodological Notes\n\n* This is an exploratory computational framework, not a theoretical proof or conventional ML algorithm\n* All parameters are derived from the data itself without human tuning\n* Results should be interpreted as hypotheses for further investigation\n* The approach is domain-agnostic and could potentially apply to various pattern detection problems\n\n# Code and Experimentation\n\nThe [GitHub repository](https://github.com/severian42/Symbolic-Emergence-Field-Analysis) contains a full implementation with examples. The framework is built with NumPy/SciPy and includes scikit-learn integration.\n\nI welcome feedback from the ML community - particularly on:\n\n1. Potential applications to traditional ML problems\n2. Improvements to the mathematical foundations\n3. Ideas for extending the framework to higher-dimensional or more complex data\n\nHas anyone worked with similar approaches that bridge signal processing and information theory for feature extraction? I'd be interested in comparing methodologies and results.",
    "created_utc": 1746106710.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kc8yeh/sefa_a_selfcalibrating_framework_for_detecting/",
    "score": 13,
    "num_comments": 10
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] WGAN-GP loss stuck and not converging.",
    "text": "I implemented a wgan-gp from scratch in pytorch and the loss is not convering. The generator loss rises to 120 and the critic loss drops to -100 and both stops there and the images generated are some nonsense noise-like image.\n\nI tried different optimizers like adam and rmsprop , and tried different normalization but it doidnt change anything. the current setup is batch norm in generator, layer norm in critic. adam optimizer with 0.0,0.9 betas, 5 critic step for 1 generator step, lambda = 10 and lr = 0.0001.\n\nThis is the full code:\n\n[https://paste.pythondiscord.com/WU4X4HLTDV3HVPTBKJA4W3PO5A](https://paste.pythondiscord.com/WU4X4HLTDV3HVPTBKJA4W3PO5A)\n\nThanks in advance!",
    "created_utc": 1746051114.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kbsxyu/d_wgangp_loss_stuck_and_not_converging/",
    "score": 0,
    "num_comments": 8
  },
  {
    "subreddit": "machinelearning",
    "title": "How to handle imbalanced output scales in PINN/PI-DeepONet loss function? [R]",
    "text": "Hi everyone,\nI\u2019m working on PINNs and PI-DeepONet with multiple outputs, and my loss function only includes residuals. No data loss. The issue is that one of the outputs is much smaller in magnitude than the others. For example, in one test case, y3 is 100x smaller than y1 and y2. In another test case, y1 is 1000x smaller.\n\nI tried assigning different weights to each residual in the loss function, it didn\u2019t help. Also tried normalizing by dividing each residual by its largest value, again, too specific and doesn\u2019t generalize well across cases.\n\nAny ideas on how to handle this more generally? Would appreciate any advice. \n",
    "created_utc": 1746040229.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kboofc/how_to_handle_imbalanced_output_scales_in/",
    "score": 7,
    "num_comments": 1
  },
  {
    "subreddit": "machinelearning",
    "title": "Suggestions on stockout & aging inventory probability prediction [D]",
    "text": "TL;DR:\nWorking on a retail project for a grocery supply chain with 10+ distribution centers and 1M+ SKUs per DC. Need advice on how to build a training dataset to predict probability of stockout and aging inventory over the next N days (where N is variable). Considering a multi-step binary classification approach. Looking for ideas, methodologies, or resources.\n\n\u2e3b\n\nPost:\nWe\u2019re currently developing a machine learning solution for a retail supply chain project. The business setup is that of a typical grocery wholesaler\u2014products are bought in bulk from manufacturers and sold to various retail stores. There are over 10 distribution centers (DCs), and each DC holds over 1 million SKUs.\n\nAn important detail: the same product can have different item codes across DCs. So, the unique identifier we use is a composite key\u2014DC-SKU.\n\nBuyers in the procurement department place orders based on demand forecasts and make manual adjustments for seasonality, holidays, or promotions.\n\nGoal:\nPredict the probability of stockouts and aging inventory (slow-moving stock) over the next N days, where N is a configurable time window (e.g., 7, 14, 30 days, etc.).\n\nI\u2019m exploring whether this can be modeled as a multi-step binary classification problem\u2014i.e., predict a binary outcome (stockout  or not stockout) for each day in the horizon. Also a separate model on aging inventory. Would love feedback on:\n\t\u2022\tHow to structure and engineer the training dataset\n\t\u2022\tSuitable modeling approaches (especially around multi-step classification)\n\t\u2022\tAny recommended frameworks, papers, or repos that could help\n\nThanks in advance!\n",
    "created_utc": 1745977793.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kb52du/suggestions_on_stockout_aging_inventory/",
    "score": 2,
    "num_comments": 2
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] Divergence in a NN, Reinforcement Learning",
    "text": "I have trained this network for a long time, but it always diverges and I really don't know why. It's analogous to a lab in a course. But in that course, the gradients are calculated manually. Here I want to use PyTorch, but there seems to be some bug that I can't find. I made sure the gradients are taken only by the current state, like semi-gradient TD from Sutton and Barto's RL book, and I believe that I calculate the TD target and error in a good way. Can someone take a look please? Basically, the net never learns and I get mostly high negative rewards.\n\nHere the link to the colab:\n\n[https://colab.research.google.com/drive/1lGSbIdaVIApieeBptNMkEwXpOxXZVlM0?usp=sharing](https://colab.research.google.com/drive/1lGSbIdaVIApieeBptNMkEwXpOxXZVlM0?usp=sharing)",
    "created_utc": 1745965936.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kb0zqa/d_divergence_in_a_nn_reinforcement_learning/",
    "score": 4,
    "num_comments": 2
  },
  {
    "subreddit": "machinelearning",
    "title": "[P] I Used My Medical Note AI to Digitize Handwritten Chess Scoresheets",
    "text": "I built\u00a0[http://chess-notation.com](http://chess-notation.com/), a free web app that turns handwritten chess scoresheets into PGN files you can instantly import into Lichess or\u00a0[Chess.com](https://chess.com/).\n\nI'm a professor at UTSW Medical Center working on AI agents for digitizing handwritten medical records using Vision Transformers. I realized the same tech could solve another problem: messy, error-prone chess notation sheets from my son\u2019s tournaments.\n\nSo I adapted the same model architecture \u2014 with custom tuning and an auto-fix layer powered by the PyChess PGN library \u2014 to build a tool that is more accurate and robust than any existing OCR solution for chess.\n\nKey features:\n\nUpload a photo of a handwritten chess scoresheet.\n\nThe AI extracts moves, validates legality, and corrects errors.\n\nPlay back the game on an interactive board.\n\nExport PGN and import with one click to Lichess or\u00a0[Chess.com](https://chess.com/).\n\nThis came from a real need \u2014 we had a pile of paper notations, some half-legible from my son, and manual entry was painful. Now it\u2019s seconds.\n\nWould love feedback on the UX, accuracy, and how to improve it further. Open to collaborations, too!",
    "created_utc": 1745951487.0,
    "url": "https://www.reddit.com/gallery/1kav9ga",
    "score": 5,
    "num_comments": 4
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] Is My Model Actually Learning?\u201d How did you learn to tell when training is helping vs. hurting?",
    "text": "I\u2019m muddling through my first few end-to-end projects and keep hitting the same wall: I\u2019ll start training, watch the loss curve wobble around for a while, and then just guess when it\u2019s time to stop. Sometimes the model gets better; sometimes I discover later it memorized the training set .\nMy Question is \n* What specific signal finally convinced you that your model was \u201clearning the right thing\u201d instead of overfitting or underfitting?\n\n* Was it a validation curve, a simple scatter plot, a sanity-check on held-out samples, or something else entirely?\n\nThanks ",
    "created_utc": 1745941605.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kar6ro/d_is_my_model_actually_learning_how_did_you_learn/",
    "score": 11,
    "num_comments": 12
  },
  {
    "subreddit": "machinelearning",
    "title": "[P] hacking on graph-grounded retrieval for SEC filings + an AI \u201clegal pen-tester\u201d\u2014looking for feedback & maybe collaborators",
    "text": "Hey ML friends,\n\nQuick intro: I\u2019m an ex-BigLaw attorney turned founder. For the past few months I\u2019ve been teaching myself anything AI/ML, and prototyping two related ideas and would love your thoughts (or a sanity check):\n\n1. **Graph-first ingestion & retrieval**\n   * Take 300-page SEC filings \u2192 normalise tables, footnotes, exhibits \u2192 emit embedding JSON-L/markdown representations .\n   * Goal: 50 ms query latency over the whole doc with traceable citations.\n   * Current status: building a patent-pending pipeline\n2. **Legal pen-testing RAG loop**\n   * Corpus: 40 yrs of SEC enforcement actions + 400 class-action complaints.\n   * Potential work thrusts: For any draft disclosure, rank sentences by estimated Rule 10b-5 litigation lift and suggest rewrites with supporting precedent.\n\nAll in all, we are playing with long-context retrieval. Need to push a retrieval encoder beyond today's oken window so an entire listing document fits in a single pass. This might include extending the LoCo/M2-BERT playbook potentially to pull the right spans from full-length filings (tens-of-thousands of tokens) without brittle chunking. We are also experimenting with some scaffolding techniques to approximate infinite context window. Not an expert in this so would love to hear your thoughts on best long context retrieval methods.\n\n**Open questions / cries for help**\n\n* Best ways you\u2019ve seen to marry graph grounding with long-context models (BM25-on-triples? hybrid rerankers? something else?).\n* Anyone play with causal risk scoring on legal text? Keen to swap notes.\n* Am I nuts for trying to productionise this with a tiny team?\n\nIf this sounds fun, or you\u2019ve tackled similar retrieval/RAG headaches, drop a comment or DM me. I\u2019m in SF but remote is cool, and there\u2019s equity on the table if we really click. Mostly just want smart brains to poke holes in the approach.\n\nNot a trained engineer or technologist so excuse me for any mistakes I might have made. Thanks for reading!\u00a0",
    "created_utc": 1745903720.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kag8w2/p_hacking_on_graphgrounded_retrieval_for_sec/",
    "score": 11,
    "num_comments": 7
  },
  {
    "subreddit": "machinelearning",
    "title": "[P] Training F5 TTS Model in Kannada and Voice Cloning \u2013 DM Me!",
    "text": "Hi all,\nI\u2019m currently training the F5 TTS model using a Kannada dataset (~80k samples) and trying to create a voice clone of my own voice in Kannada. However, I\u2019m facing issues with the output quality \u2013 the voice clone isn\u2019t coming out accurately.\n\nIf anyone has experience with F5 TTS, voice cloning, or training models in low-resource languages like Kannada, I\u2019d really appreciate your support or guidance. Please DM me if you\u2019re open to connecting out!",
    "created_utc": 1745899233.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1kaf15w/p_training_f5_tts_model_in_kannada_and_voice/",
    "score": 9,
    "num_comments": 4
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] ML approaches for structured data modeling with interaction and interpretability?",
    "text": "Hey everyone,\n\nI'm working with a modeling problem and looking for some advice from the ML/Stats community. I have a dataset where I want to predict a response variable (y) based on two main types of factors: intrinsic characteristics of individual 'objects', and characteristics of the 'environment' these objects are in.\n\nSpecifically, for each observation of an object within an environment, I have:\n\n1. A set of many features describing the 'object' itself (let's call these **Object Features**). We have data for n distinct objects. These features are specific to each object and aim to capture its inherent properties.\n2. A set of features describing the 'environment' (let's call these **Environmental Features**). Importantly, these environmental features are the *same* for all objects measured within the same environment.\n\nConceptually, we believe the response y is influenced by:\n\n* The main effects of the **Object Features**.\n* More complex or non-linear effects related to the **Object Features** themselves (beyond simple additive contributions) (Lack of Fit term in LMM context).\n* The main effects of the **Environmental Features**.\n* More complex or non-linear effects related to the **Environmental Features** themselves (Lack of Fit term).\n* **Crucially, the interaction between the Object Features and the Environmental Features.** We expect objects to respond differently depending on the environment, and this interaction might be related to the similarity between objects (based on their features) and the similarity between environments (based on *their* features).\n* Plus, the usual residual error.\n\nA standard linear modeling approach with terms for these components, possibly incorporating correlation structures based on object/environment similarity based on the features, captures the underlying structure we're interested in modeling. However, for modelling these interaction the the increasing memory requirements makes it harder to scale with increaseing dataset size.\n\nSo, I'm looking for suggestions for machine learning approaches that can handle this type of structured data (object features, environmental features, interactions) in a high-dimensional setting. A key requirement is maintaining a degree of interpretability while being easy to run. While pure black-box models might predict well, ability to seperate main object effects, main environmental effects, and the object-environment interactions, perhaps similar to how effects are interpreted in a traditional regression or mixed model context where we can see the contribution of different terms or groups of variables.\n\nAny thoughts on suitable algorithms, modeling strategies, ways to incorporate similarity structures, or resources would be greatly appreciated! Thanks in advance!",
    "created_utc": 1745852544.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1k9xpro/d_ml_approaches_for_structured_data_modeling_with/",
    "score": 1,
    "num_comments": 5
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] How could a MLP replicate the operations of an attention head?",
    "text": "So in an attention head the QK circuit allows to multiply projected tokens, so chunks of the input sequence. For example it could multiply token x with token y.\n\nHow could this be done with multiple fully connected layers? I'm not even sure how to start thinking about this...\n\nMaybe a first layer can map chunks of the input to features that recognize the tokens\u2014so one token x feature and one token y feature? And then it a later layer it could combine these into a token x + token y feature, which in turn could activate a lookup for the value of x multiplied by y? \n\nSo it would learn to recognize x and y and then learn a lookup table (simply the weight matrices) where it stores possible values of x times y. Seems very complicated but I guess something along those lines might work.\n\nAny help is welcome here !\n\n",
    "created_utc": 1745851330.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1k9x817/d_how_could_a_mlp_replicate_the_operations_of_an/",
    "score": 30,
    "num_comments": 14
  },
  {
    "subreddit": "machinelearning",
    "title": "[P]Test KavachAI: Ethical Guardrails for Your ML Models",
    "text": "Disclosure: I\u2019m the founder of Project KavachAI. \nEthical AI is critical as machine learning powers more applications. Project KavachAI is an open-source framework that adds ethical guardrails to your ML models, ensuring transparency, fairness, and compliance with regulations like the EU AI Act. Key features include: \u2022  Real-time Bias Detection: Identifies and mitigates bias during inference. \u2022  Explainable AI Tools: Enhances model interpretability. \u2022  Compliance Support: Aligns with global ethical standards. Our MVP is available on GitHub (https://github.com/sidharthsajith/KAVACHAI), and we\u2019re looking for developers to test it. How do you handle ethical concerns in your ML projects? Are there tools you wish existed for bias mitigation? \n\nYour feedback can help shape KavachAI\u2019s future. Let\u2019s make ethical ML the norm! \nCheers, \nS Sidharth Founder, \nProject KavachAI",
    "created_utc": 1745763929.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1k955nq/ptest_kavachai_ethical_guardrails_for_your_ml/",
    "score": 7,
    "num_comments": 0
  },
  {
    "subreddit": "machinelearning",
    "title": "[P] Does Anyone Need Fine-Grained Access Control for LLMs?",
    "text": "Hey everyone,\n\nAs LLMs (like GPT-4) are getting integrated into more company workflows (knowledge assistants, copilots, SaaS apps), I\u2019m noticing a big **pain point** around **access control**.\n\nToday, once you give someone access to a chatbot or an AI search tool, it\u2019s very hard to:\n\n* Restrict what *types* of questions they can ask\n* Control *which data* they are allowed to query\n* Ensure *safe and appropriate* responses are given back\n* Prevent *leaks of sensitive information* through the model\n\nTraditional role-based access controls (RBAC) exist for databases and APIs, but **not really for LLMs**.\n\n**I'm exploring a solution** that helps:\n\n* Define what different users/roles are allowed to *ask*.\n* Make sure responses stay *within authorized domains*.\n* Add an extra *security and compliance layer* between users and LLMs.\n\n\n\n**Question for you all:**\n\n* If you are building LLM-based apps or internal AI tools, **would you want this kind of access control?**\n* What would be your top priorities: Ease of setup? Customizable policies? Analytics? Auditing? Something else?\n* Would you prefer **open-source tools** you can host yourself or **a hosted managed service**?\n\nWould love to hear honest feedback \u2014 even a \"not needed\" is super valuable!\n\nThanks!\n\n",
    "created_utc": 1745773211.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1k98q65/p_does_anyone_need_finegrained_access_control_for/",
    "score": 0,
    "num_comments": 3
  },
  {
    "subreddit": "machinelearning",
    "title": "[P] VideOCR - Extract hardcoded subtitles out of videos via a simple to use GUI",
    "text": "Hi everyone! \ud83d\udc4b\n\nI\u2019m excited to share a project I\u2019ve been working on: VideOCR.\n\nMy program alllows you to extract hardcoded subtitles out of any video file with just a few clicks. It utilizes PaddleOCR under the hood to identify text in images. PaddleOCR supports up to 80 languages so this could be helpful for a lot of people.\n\nI've created a CPU and GPU version and also an easy to follow setup wizard for both of them to make the usage even easier.\n\nIf anyone of you is interested, you can find my project here:\n\n[https://github.com/timminator/VideOCR](https://github.com/timminator/VideOCR)\n\nI am aware of Video Subtitle Extractor, a similar tool that is around for quite some time, but I had a few issues with it. It takes a different approach than my project to identify subtitles. It utilizes VideoSubFinder under the hood to find the right spots in the video. VideoSubFinder is a great tool, but when not fine tuned explicitly for the specific video it misses quite a few subtitles. My program is only built around PaddleOCR and tries to mitigate these problems.",
    "created_utc": 1745782156.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1k9c9cn/p_videocr_extract_hardcoded_subtitles_out_of/",
    "score": 3,
    "num_comments": 0
  },
  {
    "subreddit": "machinelearning",
    "title": "[P] Looking for advice: Best AI approach to automatically predict task dependencies and optimize industrial project schedules?",
    "text": "Hello everyone,\n\nI'm trying to optimize project schedules that involve hundreds to thousands of maintenance tasks. Each project is divided into \"work packages\"  associated with specific types of equipment.\n\nI would like to automate task dependencies with AI by providing a list of tasks (with activity ID, name, equipment type, duration if available), and letting the AI predict the correct sequence and dependencies automatically.\n\nI have historical data:\n\n\\- Around 16 past projects (some with 300 tasks, some with up to 35,000 tasks).\n\n\\- For each task: ID, name, type of equipment, duration, start and end dates (sometimes missing values).\n\n\\- Historical dependencies between tasks (links between task IDs).\n\n  \nFor example, i have this file : \n\n|ID |NAME|EQUIPMENT TYPE|DURATION|\n|:-|:-|:-|:-|\n|J2M BALLON 001.C1.10|\t\u00a4\u00a4 TRAVAUX A REALISER AVANT ARRET \u00a4\u00a4|Ballon|0|\n|J2M BALLON 001.C1.20|Pose \u00e9chafaudage(s)|Ballon|8|\n|J2M BALLON 001.C1.30|R\u00e9ception \u00e9chafaudage(s)|Ballon|2|\n|J2M BALLON 001.C1.40|D\u00e9pose calorifuge comple|Ballon|4|\n|J2M BALLON 001.C1.50|Cr\u00e9ation puits de mesure|Ballon|0|\n\n  \nAnd the AI should be returning me this : \n\n\n\n|ID|NAME|NAME SUCCESSOR 1|NAME SUCCESSOR 2|\n|:-|:-|:-|:-|\n|J2M BALLON 001.C1.10|\u00a4\u00a4 TRAVAUX A REALISER AVANT ARRET \u00a4\u00a4\t|Pose \u00e9chafaudage(s||\n|J2M BALLON 001.C1.20|Pose \u00e9chafaudage(s)|R\u00e9ception \u00e9chafaudage(s)\t||\n|J2M BALLON 001.C1.30|R\u00e9ception \u00e9chafaudage(s)|D\u00e9pose calorifuge complet|Cr\u00e9ation puits de mesure|\n|J2M BALLON 001.C1.40|D\u00e9pose calorifuge complet|\u00a4\u00a4 TRAVAUX A REALISER PENDANT ARRET \u00a4\u00a4||\n|J2M BALLON 001.C1.50|Cr\u00e9ation puits de mesure|\u00a4\u00a4 TRAVAUX A REALISER PENDANT ARRET \u00a4\u00a4||\n\n\n\nSo far, I have tried building models (random forest, gnn), but I\u2019m still stuck after two months. I was suggested to explore \\*\\*sequential models\\*\\*.\n\nMy questions:\n\n\\- Would an LSTM, GRU, or Transformer-based model be suitable for this type of sequence + multi-label prediction problem (predicting 1 or more successors)?\n\n\\- Should I think about this more as a sequence-to-sequence problem, or as graph prediction? (I tried the graph aproach but was stopped as i couldnt do the inference on new graph without edges)\n\n\\- Are there existing models or papers closer to workflow/task dependency prediction that you would recommend?\n\n\n\nAny advice, pointers, or examples would be hugely appreciated!  \n\n(Also, if you know any open-source projects or codebases close to this, I'd love to hear about them.)\n\n\n\nThank you so much in advance!\n\n\n\n",
    "created_utc": 1745834121.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1k9rqr4/p_looking_for_advice_best_ai_approach_to/",
    "score": 0,
    "num_comments": 4
  },
  {
    "subreddit": "machinelearning",
    "title": "[P] plan-lint - Open source project to verify plans generated by LLMs",
    "text": "Hey folks,\n\nI\u2019ve just shipped **plan-lint**, a tiny OSS tool that inspects machine-readable \"plans\" agents spit out **before** any tool call runs. It spots the easy-to-miss stuff\u2014loops, over-broad SQL, raw secrets, crazy refund values\u2014then returns *pass / fail* plus a risk score, so your orchestrator can replan or use HITL instead of nuking prod.\n\n**Quick specs**\n\n* JSONSchema / Pydantic validation\n* YAML / OPA allow/deny rules & bounds\n* Data-flow checks for PII / secrets\n* Cycle detection on the step graph\n* Runs in <50 ms for \ud83d\udcaf steps, zero tokens\n\nRepo link in comment\n\nHow to :  \n`pip install plan-lint`\n\n`plan-lint examples/price_drop.json --policy policy.yaml --fail-risk 0.8`\n\nApache-2.0, plugins welcome. Would love feedback, bug reports, or war-stories about plans that went sideways in prod!",
    "created_utc": 1745824290.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1k9pkd0/p_planlint_open_source_project_to_verify_plans/",
    "score": 5,
    "num_comments": 1
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] A reactive computation library for Python that might be helpful for data science workflows - thoughts from experts?",
    "text": "Hey!\n\nI recently built a Python library called [reaktiv](https://github.com/buiapp/reaktiv) that implements reactive computation graphs with automatic dependency tracking. I come from IoT and web dev (worked with Angular), so I'm definitely not an expert in data science workflows.\n\nThis is my first attempt at creating something that might be useful outside my specific domain, and I'm genuinely not sure if it solves real problems for folks in your field. I'd love some honest feedback - even if that's \"this doesn't solve any problem I actually have.\"\n\nThe library creates a computation graph that:\n\n* Only recalculates values when dependencies actually change\n* Automatically detects dependencies at runtime\n* Caches computed values until invalidated\n* Handles asynchronous operations (built for asyncio)\n\nWhile it seems useful to me, I might be missing the mark completely for actual data science work. If you have a moment, I'd appreciate your perspective.\n\nHere's a simple example with pandas and numpy that might resonate better with data science folks:\n\n    import pandas as pd\n    import numpy as np\n    from reaktiv import signal, computed, effect\n    \n    # Base data as signals\n    df = signal(pd.DataFrame({\n        'temp': [20.1, 21.3, 19.8, 22.5, 23.1],\n        'humidity': [45, 47, 44, 50, 52],\n        'pressure': [1012, 1010, 1013, 1015, 1014]\n    }))\n    features = signal(['temp', 'humidity'])  # which features to use\n    scaler_type = signal('standard')  # could be 'standard', 'minmax', etc.\n    \n    # Computed values automatically track dependencies\n    selected_features = computed(lambda: df()[features()])\n    \n    # Data preprocessing that updates when data OR preprocessing params change\n    def preprocess_data():\n        data = selected_features()\n        scaling = scaler_type()\n        \n        if scaling == 'standard':\n            # Using numpy for calculations\n            return (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n        elif scaling == 'minmax':\n            return (data - np.min(data, axis=0)) / (np.max(data, axis=0) - np.min(data, axis=0))\n        else:\n            return data\n    \n    normalized_data = computed(preprocess_data)\n    \n    # Summary statistics recalculated only when data changes\n    stats = computed(lambda: {\n        'mean': pd.Series(np.mean(normalized_data(), axis=0), index=normalized_data().columns).to_dict(),\n        'median': pd.Series(np.median(normalized_data(), axis=0), index=normalized_data().columns).to_dict(),\n        'std': pd.Series(np.std(normalized_data(), axis=0), index=normalized_data().columns).to_dict(),\n        'shape': normalized_data().shape\n    })\n    \n    # Effect to update visualization or logging when data changes\n    def update_viz_or_log():\n        current_stats = stats()\n        print(f\"Data shape: {current_stats['shape']}\")\n        print(f\"Normalized using: {scaler_type()}\")\n        print(f\"Features: {features()}\")\n        print(f\"Mean values: {current_stats['mean']}\")\n    \n    viz_updater = effect(update_viz_or_log)  # Runs initially\n    \n    # When we add new data, only affected computations run\n    print(\"\\nAdding new data row:\")\n    df.update(lambda d: pd.concat([d, pd.DataFrame({\n        'temp': [24.5], \n        'humidity': [55], \n        'pressure': [1011]\n    })]))\n    # Stats and visualization automatically update\n    \n    # Change preprocessing method - again, only affected parts update\n    print(\"\\nChanging normalization method:\")\n    scaler_type.set('minmax')\n    # Only preprocessing and downstream operations run\n    \n    # Change which features we're interested in\n    print(\"\\nChanging selected features:\")\n    features.set(['temp', 'pressure'])\n    # Selected features, normalization, stats and viz all update\n\nI think this approach might be particularly valuable for data science workflows - especially for:\n\n* Building exploratory data pipelines that efficiently update on changes\n* Creating reactive dashboards or monitoring systems that respond to new data\n* Managing complex transformation chains with changing parameters\n* Feature selection and hyperparameter experimentation\n* Handling streaming data processing with automatic propagation\n\nAs data scientists, would this solve any pain points you experience? Do you see applications I'm missing? What features would make this more useful for your specific workflows?\n\nI'd really appreciate your thoughts on whether this approach fits data science needs and how I might better position this for data-oriented Python developers.\n\nThanks in advance!",
    "created_utc": 1745790562.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1k9fhm8/d_a_reactive_computation_library_for_python_that/",
    "score": 2,
    "num_comments": 4
  },
  {
    "subreddit": "machinelearning",
    "title": "[P] Tips for hackathon",
    "text": "Hi guys! I hope that you are doing well. I am willing to participate in a hackathon event where I (+2 others) have been given the topic:\n\nRapid and accurate decision-making in the Emergency Room for acute abdominal pain.\n\nWe have to use anonymised real world medical dataset related to abdominal pain to make decisions on whether patient requires immediate surgery or not. Metadata includes the symptoms, vital signs, biochemical tests, medical history, etc (which we may have to normalize).\n\nI have a month to prepare for it. I am a fresher and I have just been introduced to ML although I am trying my best to learn as fast as I can. I have a decent experience in sqlalchemy and I think it might help me in this hackathon. All suggesstions on the different ML and Data Science techniques that would help us are welcome. If you have any github repositories in mind, please leave a link below. Thank you for reading and have a great day!",
    "created_utc": 1745783994.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1k9cz2s/p_tips_for_hackathon/",
    "score": 0,
    "num_comments": 3
  },
  {
    "subreddit": "machinelearning",
    "title": "[R] Seeking arXiv Endorsement",
    "text": "Hey everyone,  \nI'm an undergrad working on a multi-agent reinforcement learning paper for months, and I've finally got some results worth publishing. My university doesn't have auto-endorsement, and I'm looking for someone who might be willing to endorse my work in cs.LG(Machine Learning) or related fields.  \nI'd be happy to share the paper and abstract. Any help would be greatly appreciated.",
    "created_utc": 1745770219.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1k97klt/r_seeking_arxiv_endorsement/",
    "score": 0,
    "num_comments": 2
  },
  {
    "subreddit": "machinelearning",
    "title": "[P] I made a bug-finding agent that knows your codebase",
    "text": "",
    "created_utc": 1745765928.0,
    "url": "https://i.redd.it/uchcb9jmpbxe1.gif",
    "score": 130,
    "num_comments": 24
  },
  {
    "subreddit": "machinelearning",
    "title": "[R] 62.3% Validation Accuracy on Sequential CIFAR-10 (3072 length) With Custom RNN Architecture \u2013 Is it Worth Attention?",
    "text": "I'm currently working on my own RNN architecture and testing it on various tasks. One of them involved CIFAR-10, which was flattened into a sequence of 3072 steps, where each channel of each pixel was passed as input at every step.\n\nMy architecture achieved a validation accuracy of 62.3% on the 9th epoch with approximately 400k parameters. I should emphasize that this is a pure RNN with only a few gates and no attention mechanisms.\n\nI should clarify that the main goal of this specific task is not to get as high accuracy as you can, but to demonstrate that model can process long-range dependencies. Mine does it with very simple techniques and I'm trying to compare it to other RNNs to understand if \"memory\" of my network is good in a long term.\n\nAre these results achievable with other RNNs? I tried training a GRU on this task, but it got stuck around 35% accuracy and didn't improve further.\n\nHere are some sequential CIFAR-10 accuracy measurements for RNNs that I found:\n\n\\- [https://arxiv.org/pdf/1910.09890](https://arxiv.org/pdf/1910.09890) (page 7, Table 2)  \n\\- [https://arxiv.org/pdf/2006.12070](https://arxiv.org/pdf/2006.12070) (page 19, Table 5)  \n\\- [https://arxiv.org/pdf/1803.00144](https://arxiv.org/pdf/1803.00144) (page 5, Table 2)\n\nBut in these papers, CIFAR-10 was flattened by pixels, not channels, so the sequences had a shape of \\[1024, 3\\], not \\[3072, 1\\].\n\nHowever, [https://arxiv.org/pdf/2111.00396](https://arxiv.org/pdf/2111.00396) (page 29, Table 12) mentions that HiPPO-RNN achieves 61.1% accuracy, but I couldn't find any additional information about it \u2013 so it's unclear whether it was tested with a sequence length of 3072 or 1024.\n\nSo, is this something worth further attention?\n\nI recently published a basic version of my architecture on GitHub, so feel free to take a look or test it yourself:  \n[https://github.com/vladefined/cxmy](https://github.com/vladefined/cxmy)\n\n**Note:** It works *quite slow* due to internal PyTorch loops. You can try compiling it with torch.compile, but for long sequences it takes a lot of time and a lot of RAM to compile. Any help or suggestions on how to make it work faster would be greatly appreciated.",
    "created_utc": 1745750321.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1k910g9/r_623_validation_accuracy_on_sequential_cifar10/",
    "score": 15,
    "num_comments": 34
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] [P] Research Paper and Presentation about Multi-Agent Reinforcement Learning",
    "text": "Hey everyone!\n\nI am a current Master's student, and I am working on a presentation (and later research paper) about MARL. Specifically focusing on MARL for competitive Game AI. This presentation will be 20-25 minutes long, and it is for my machine learning class, where we have to present a topic not covered in the course. In my course, we went over and did an in-depth project about single-agent RL, particularly looking at algorithms such as Q-learning, DQN, and Policy Gradient methods. So my class is pretty well-versed in this area. I would very much appreciate any help and tips on what to go over in this presentation. I am feeling a little overwhelmed by how large and broad this area of RL is, and I need to capture the essence of it in this presentation.\n\nHere is what I am thinking for the general outline. **Please share your thoughts on these particular topics, if they are necessary to include, what are must cover topics, and maybe which ones can be omitted or briefly mentioned?**\n\n*My current MARL Presentation outline:*\n\n**Introduction**\n\n* What is MARL (brief)\n* Motivation and Applications of MARL\n\n**Theoretical Foundations**\n\n* Go over game models (spend most time on 3 and 4):\n   1. Normal-Form Games\n   2. Repeated Normal-Form Games\n   3. Stochastic Games\n   4. Partial Observable Stochastic Games (POSG)\n      * Observation function\n      * Belief States\n      * Modelling Communication (touch on implicit vs. explicit communication)\n\n**Solution Concepts**\n\n* Joint Policy and Expected Return\n   * History-Based and Recursive-Based\n* Equilibrium Solution Concepts\n   * Go over what is best response\n      1. Minimax\n      2. Nash equilibrium\n      3. Epsilon Nash equilibrium\n      4. Correlated equilibrium\n* Additional Solution Criteria\n   1. Pareto Optimality\n   2. Social Welfare and Fairness\n   3. No Regret\n\n**Learning Framework for MARL**\n\n* Go over MARL learning process (central and independent learning)\n* Convergence\n\n**MARL Challenges**\n\n* Non-stationarity\n* Equilibrium selection\n* multi-agent credit assignment\n* scaling to many agents\n\n**Algorithms**\n\n1. Go over a cooperative algorithm (not sure which one to choose? QMIX, VDN, etc.)\n2. Go over a competitive algorithm (MADDPG, LOLA?)\n\n**Case Study**\n\nGo over real-life examples of MARL being used in video games (maybe I should merge this with the algorithms section?)\n\n* AlphaStar for StarCraft2 - competitive\n* OpenAI Five for Dota2 - cooperative\n\n**Recent Advances**\n\nEnd with going over some new research being done in the field.\n\nThanks! I would love to know what you guys think. This might be a bit ambitious to go over in 20 minutes. I am thinking of maybe adding a section on Dec-POMPDs, but I am not sure.",
    "created_utc": 1745696414.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1k8lbro/d_p_research_paper_and_presentation_about/",
    "score": 4,
    "num_comments": 1
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] discussion period in the EMNLP 2025 call",
    "text": "Hi everyone,  \nI don't have prior experience with an EMNLP submission. In the call, I can't see when the discussion period starts.\n\n[https://2025.emnlp.org/calls/main\\_conference\\_papers/](https://2025.emnlp.org/calls/main_conference_papers/)\n\nIs it something that is usually announced beforehand, or is it decided on the fly during the review process? If yes, is it announced before the submission deadline? Usually, how long after the submission deadline are reviews released?\n\nthanks!",
    "created_utc": 1745689683.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1k8irsr/d_discussion_period_in_the_emnlp_2025_call/",
    "score": 1,
    "num_comments": 6
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] Preparing for a DeepMind Gemini Team Interview \u2014 Any Resources, Tips, or Experience to Share?",
    "text": "Hi everyone,\n\nI'm currently preparing for interviews with the Gemini team at Google DeepMind, specifically for a role that involves system design for LLMs and working with state-of-the-art machine learning models.\n\nI've built a focused 1-week training plan covering:\n\n* Core system design fundamentals\n* LLM-specific system architectures (training, serving, inference optimization)\n* Designing scalable ML/LLM systems (e.g., retrieval-augmented generation, fine-tuning pipelines, mobile LLM inference)\n* DeepMind/Gemini culture fit and behavioral interviews\n\nI'm reaching out because I'd love to hear from anyone who:\n\n* Has gone through a DeepMind, Gemini, or similar AI/ML research team interview\n* Has tips for LLM-related system design interviews\n* Can recommend specific papers, blog posts, podcasts, videos, or practice problems that helped you\n* Has advice on team culture, communication, or mindset during the interview process\n\nI'm particularly interested in how they evaluate \"system design for ML\" compared to traditional SWE system design, and what to expect culture-wise from Gemini's team dynamics.\n\nIf you have any insights, resources, or even just encouragement, I\u2019d really appreciate it! \ud83d\ude4f  \nThanks so much in advance.",
    "created_utc": 1745684942.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1k8gy12/d_preparing_for_a_deepmind_gemini_team_interview/",
    "score": 220,
    "num_comments": 38
  },
  {
    "subreddit": "machinelearning",
    "title": "[D] Intuition behind Load-Balancing Loss in the paper OUTRAGEOUSLY LARGE NEURAL NETWORKS: THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER",
    "text": "I'm trying to implement the paper \"OUTRAGEOUSLY LARGE NEURAL NETWORKS: THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER\"\n\npaper link: [https://arxiv.org/abs/1701.06538](https://arxiv.org/abs/1701.06538)\n\nBut got stuck while implementing the Load-Balancing Loss. Could someone please explain this with some INTUITION about what's going on here? In detail intuition and explanation of the math.\n\nhttps://preview.redd.it/t592d5o0jaxe1.png?width=718&format=png&auto=webp&s=201101c4745a53ac4bb26dac69b17f252506ae5b\n\nI tried reading some code, but failed to understand:\n\n\\* [https://github.com/davidmrau/mixture-of-experts/blob/master/moe.py](https://github.com/davidmrau/mixture-of-experts/blob/master/moe.py)\n\n\\* [https://github.com/lucidrains/mixture-of-experts/blob/master/mixture\\_of\\_experts/mixture\\_of\\_experts.py](https://github.com/lucidrains/mixture-of-experts/blob/master/mixture_of_experts/mixture_of_experts.py)\n\nAlso, what's the difference between the load-balancing loss and importance loss? How are they different from each other? I find both a bit similar, plz explain the difference.\n\nThanks!",
    "created_utc": 1745684540.0,
    "url": "https://www.reddit.com/r/MachineLearning/comments/1k8gsfe/d_intuition_behind_loadbalancing_loss_in_the/",
    "score": 16,
    "num_comments": 14
  },
  {
    "subreddit": "computerscience",
    "title": "Computer Networking Resources",
    "text": "Hello buddies,\n\nIs there a computer networks resource that isn't actually garbage?\n\nLet me explain. I am about to graduate in Math and CS and my uni kind of failed me on the systems side. I took your typical Computer Systems - Networks - Operating Systems classes but, by luck or otherwise, these 3 were taught on a lecturer-reading-slides way. \n\nNow, about to get my diploma, I'm clueless about networks. Is there a nice book, youtube lecture series, or something, that actually teaches you networks in the same way that other courses would teach you something hands-on? Even if theoretical? Here are some examples of what I mean. \n\nAlgorithms is hands on: problem sets that asks you to proof correctness of algorithms, computing complexity, coming up with variations of algos to solve a problem. \n\nData Structures is hands on: code the structures from scratch on c++.\n\nML is hands on: get a dataset and build a model that classifies well\n\nSWE is hands on: Read an architecture pattern and code something with it\n\nMath is hands on: literally just do problem sets\n\nWhat resources is hands-ons in networking? I don't want to memorize that the TCP header is 8 bytes (or whatever size it is) without ever looking at it beyond the silly graph in your usual textbook. I want to solve some problems, code something up, do something. Kurose's book problem, skimming through them, feel more like High School trivia, though I might be wrong. Any help is most welcomed.",
    "created_utc": 1746399206.0,
    "url": "https://www.reddit.com/r/computerscience/comments/1kewsdw/computer_networking_resources/",
    "score": 2,
    "num_comments": 2
  },
  {
    "subreddit": "computerscience",
    "title": "Flow network - residual graphs",
    "text": "I\u2019m sorry if this isn\u2019t the correct place to ask such a question but I didn\u2019t this exactly breaking the rules.  I\u2019m currently studying for my algorithms final tomorrow and I\u2019ve been conceptually struggling to understand the role of the residual graph and residual paths in finding the max-flow. \n\nIn the graph attached, when using the Ford Fulkerson algorithm with DFS, in the worst case a flow of 1 is pushed through the augmenting path repeatedly in an oscillating manner. What I\u2019m struggling to understand is why, after the very first time that the augmenting path is found and a flow of 1 is pushed through it, causing the flow to equal capacity through the middle edge, we are still able to find the same augmenting path again and again and pass flow through it.  \n\nI\u2019d really appreciate any help! Thanks a lot. ",
    "created_utc": 1746302961.0,
    "url": "https://i.redd.it/5afaynaajmye1.jpeg",
    "score": 4,
    "num_comments": 2
  },
  {
    "subreddit": "computerscience",
    "title": "How to count without the side effect caused by float precision of decimal numbers ?",
    "text": "Given two arbitrary vectors, which represent a bounding box in 3D space . They represent the leftbottom and the righttop corners of a box geometry . My question is , I want to voxelize this bounding box, but I can't get a correct number of total number of boxes .\n\nTo elaborate : I want to represent this bounding volume with several little cubes of constant size . And they will be placed along each axis with different amounts per axis. This technically would be easy but soon I encountered the problem of float precision . As decimal numbers are represented with negative powers, you have to fit the numerical value . Binary representation cannot represent it easily . It's like binary tree that you divide the whole tree into \"less than 0.5\" and \"greater than 0.5\" . After that , you divide each parts into 0.25 and 0.75. You repeat this process and finally get an approximate value .\n\nThe problem is : ***ceil((righttop.x-leftbottom.x)/cubesize)*** outputs 82 while ***ceil(righttop.x/cubesize)-ceil(leftbottom.x/cubesize)*** outputs 81 because ***(righttop.x-leftbottom.x)/cubesize*** equals to 81.000001 which is ceiled to 82, while I was expecting it to be ***ceil(81.000001)==81*** .\n\nHow should you calculate it in this case ?",
    "created_utc": 1746104331.0,
    "url": "https://www.reddit.com/r/computerscience/comments/1kc83d1/how_to_count_without_the_side_effect_caused_by/",
    "score": 9,
    "num_comments": 11
  },
  {
    "subreddit": "computerscience",
    "title": "I built a toy to help learn about arrays and pointers",
    "text": "Sometimes, I get sad that most of what I build are just metaphors for electrons occupying different spaces--so I start picturing tactile representations.  Here is one I designed in Fusion for Arrays and pointers. \n\nIt helped with explaining the concept to my 10 year old--although it didn't much help with the \"but why?\" question.",
    "created_utc": 1746038512.0,
    "url": "https://www.reddit.com/gallery/1kbo001",
    "score": 165,
    "num_comments": 23
  },
  {
    "subreddit": "computerscience",
    "title": "About how many bits can all the registers in a typical x86 CPU hold?",
    "text": "I know you can't necessarily actually access each one, but I was curious how many registers there are in a typical x86 processor (let's say a 4 core i7 6820 hq, simply cause it's what I have). I've only found some really rough guestimates of how many registers there are from Google, and nothing trying to actually find out how big they are (I don't know if they're all the same size or if some are smaller). Also, I was just curious which has more space, the registers in my CPU or a zx spectrums ram, because just by taking the number this thread ( https://www.reddit.com/r/programming/comments/k3wckj/how_many_registers_does_an_x8664_cpu_have/ )suggests and multiplying it by 64 then 4 you actually get a fairly similar value to the 16kb a spectrum has",
    "created_utc": 1745961260.0,
    "url": "https://www.reddit.com/r/computerscience/comments/1kaz67b/about_how_many_bits_can_all_the_registers_in_a/",
    "score": 25,
    "num_comments": 22
  },
  {
    "subreddit": "computerscience",
    "title": "CS Education Research",
    "text": "What's your view on CS Ed research? After working in CS Ed, what are the chances of getting hired as a teaching professor? Do you think the demand for CS will keep growing? Or it's a risky gamble? Cause if the demand shrinks, the need for CS Ed professors may shrink too. I enjoy the work, but future employability is becoming a bigger issue. ",
    "created_utc": 1745932133.0,
    "url": "https://www.reddit.com/r/computerscience/comments/1kanizq/cs_education_research/",
    "score": 4,
    "num_comments": 2
  },
  {
    "subreddit": "computerscience",
    "title": "What are the Implications of P=NP?",
    "text": "I am trying to write a sci-fi thriller where in 2027, there are anomalies in the world which is starting to appear because someone proves P=NP in specific conditions and circumstances and this should have massive consequences, like a ripple effect in the world. \nI just want to grasp the concept better and understand implications to write this setting better. \nI was thinking maybe one of the characters \"solves\" the Hodge conjecture in their dream and claims they could just \"see\" it ( which btw because a scenario where P=NP is developing) and this causes a domino effect of events. \n\nI want to understand how to \"show\" Or depict it in fiction, for which I need a better grasp\n\n thanks in advance for helping me out. ",
    "created_utc": 1745913003.0,
    "url": "https://www.reddit.com/r/computerscience/comments/1kaigyx/what_are_the_implications_of_pnp/",
    "score": 27,
    "num_comments": 71
  },
  {
    "subreddit": "computerscience",
    "title": "Computer Science book that will lead to insights into various Computer Systems?",
    "text": "Is there a book out there that would provide an overview of all CS that would come in handy when trying to understand things like containers, network architecture, python scripts, database replication, devops, etc? I was thinking about going through Nand2Tetris but that seems like it might be more low-level than I'd need to get the information I'm looking for. Unless you think a computer architecture and systems programming book like that would prove to be useful. Thank you for your help.",
    "created_utc": 1745758844.0,
    "url": "https://www.reddit.com/r/computerscience/comments/1k93ewk/computer_science_book_that_will_lead_to_insights/",
    "score": 15,
    "num_comments": 10
  },
  {
    "subreddit": "computerscience",
    "title": "Research paper help",
    "text": "Hello guys , I recently co wrote a research paper on Genetic algorithms and was searching for conferences to publish in India which will take place before Sept 2025 as am leaving for my masters . So if you have any leads about any good conferences about computer science during that time kindly please do share , its urgent .  \n",
    "created_utc": 1745565056.0,
    "url": "https://www.reddit.com/r/computerscience/comments/1k7euco/research_paper_help/",
    "score": 0,
    "num_comments": 1
  },
  {
    "subreddit": "computerscience",
    "title": "What is oflag in Unix system calls?",
    "text": "Hi, i'm trying to search information about this but Is very hard. So what is oflag? For example the system call open requires a string of char for the directory, and an int oflag. But the flags are like: O_RDONLY, O_WRONLY... so how it can be an integer? I have seen that the file permissions are represented by a string with 3 3-bit triplets (the first for user permission)but i don't have any clear study material on these topics. Thanks for the help\n",
    "created_utc": 1745493936.0,
    "url": "https://www.reddit.com/r/computerscience/comments/1k6pshs/what_is_oflag_in_unix_system_calls/",
    "score": 0,
    "num_comments": 12
  },
  {
    "subreddit": "computerscience",
    "title": "Computer science theory wins you\u2019ve actually used for prep",
    "text": "We all learned heaps of algorithm / automata theory, but how often do you really deploy it?\n\nMy recent win: turned a gnarly string\u2011search bug into a clean Aho\u2011Corasick automaton cut runtime from 45\u202fs \u279c 900\u202fms.  \n\nA teammate used max\u2011flow / min\u2011cut to optimize a supply\u2011chain model, saving the client \\~$40\u202fk/mo.\n\n\n\nDrop your stories (and what course prepped you). Bonus points if the professor swore \u201cyou\u2019ll use this someday\u201d\u2026 and they were right.  \n\n",
    "created_utc": 1745428198.0,
    "url": "https://www.reddit.com/r/computerscience/comments/1k64jxe/computer_science_theory_wins_youve_actually_used/",
    "score": 195,
    "num_comments": 36
  },
  {
    "subreddit": "computerscience",
    "title": "ELI5: What is OAuth?",
    "text": "So I was reading about OAuth to learn it and have created this explanation. It's basically a few of the best I have found merged together and rewritten in big parts. I have also added a super short summary and a code example. Maybe it helps one of you :-) This is the [repo][ref2].\n\n# OAuth Explained\n\n## The Basic Idea\n\nLet\u2019s say LinkedIn wants to let users import their Google contacts.\n\nOne obvious (but terrible) option would be to just ask users to enter their Gmail email and password directly into LinkedIn. But giving away your actual login credentials to another app is a huge security risk.\n\nOAuth was designed to solve exactly this kind of problem.\n\nNote: So OAuth solves an authorization problem! Not an authentication problem. See [here][ref1] for the difference.\n\n## Super Short Summary\n\n- User clicks \u201cImport Google Contacts\u201d on LinkedIn\n- LinkedIn redirects user to Google\u2019s OAuth consent page\n- User logs in and approves access\n- Google redirects back to LinkedIn with a one-time code\n- LinkedIn uses that code to get an access token from Google\n- LinkedIn uses the access token to call Google\u2019s API and fetch contacts\n\n## More Detailed Summary\n\nSuppose LinkedIn wants to import a user\u2019s contacts from their Google account.\n\n1. LinkedIn sets up a Google API account and receives a client_id and a client_secret\n   - So Google knows this client id is LinkedIn\n2. A user visits LinkedIn and clicks \"Import Google Contacts\"\n3. LinkedIn redirects the user to Google\u2019s authorization endpoint:\n   https://accounts.google.com/o/oauth2/auth?client_id=12345&redirect_uri=https://linkedin.com/oauth/callback&scope=contacts\n\n- client_id is the before mentioned client id, so Google knows it's LinkedIn\n- redirect_uri is very important. It's used in step 6\n- in scope LinkedIn tells Google how much it wants to have access to, in this case the contacts of the user\n\n4. The user will have to log in at Google\n5. Google displays a consent screen: \"LinkedIn wants to access your Google contacts. Allow?\" The user clicks \"Allow\"\n6. Google generates a one-time authorization code and redirects to the URI we specified: redirect_uri. **It appends the one-time code as a URL parameter**.\n   - So the URL could be https://linkedin.com/oauth/callback?code=one_time_code_xyz\n7. Now, LinkedIn makes a server-to-server request (not a redirect) to Google\u2019s token endpoint and receive an access token (and ideally a refresh token)\n8. **Finished**. Now LinkedIn can use this access token to access the user\u2019s Google contacts via Google\u2019s API\n\n---\n\n**Question:**\n_Why not just send the access token in step 6?_\n\n**Answer:** To make sure that the requester is actually LinkedIn. So far, all requests to Google have come from the user\u2019s browser, with only the client_id identifying LinkedIn. Since the client_id isn\u2019t secret and could be guessed by an attacker, Google can\u2019t know for sure that it's actually LinkedIn behind this. In the next step, LinkedIn proves its identity by including the client_secret in a server-to-server request.\n\n## Security Note: Encryption\n\nOAuth 2.0 does **not** handle encryption itself. It relies on HTTPS (SSL/TLS) to secure sensitive data like the client_secret and access tokens during transmission.\n\n## Security Addendum: The state Parameter\n\nThe state parameter is critical to prevent cross-site request forgery (CSRF) attacks. It\u2019s a unique, random value generated by the third-party app (e.g., LinkedIn) and included in the authorization request. Google returns it unchanged in the callback. LinkedIn verifies the state matches the original to ensure the request came from the user, not an attacker.\n\n## OAuth 1.0 vs OAuth 2.0 Addendum:\n\nOAuth 1.0 required clients to cryptographically sign every request, which was more secure but also much more complicated. OAuth 2.0 made things simpler by relying on HTTPS to protect data in transit, and using bearer tokens instead of signed requests.\n\n## Code Example: OAuth 2.0 Login Implementation\n\nBelow is a standalone Node.js example using Express to handle OAuth 2.0 login with Google, storing user data in a SQLite database.\n\n```javascript\nconst express = require(\"express\");\nconst axios = require(\"axios\");\nconst sqlite3 = require(\"sqlite3\").verbose();\nconst crypto = require(\"crypto\");\nconst jwt = require(\"jsonwebtoken\");\nconst jwksClient = require(\"jwks-rsa\");\n\nconst app = express();\nconst db = new sqlite3.Database(\":memory:\");\n\n// Initialize database\ndb.serialize(() => {\n  db.run(\n    \"CREATE TABLE users (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, email TEXT)\"\n  );\n  db.run(\n    \"CREATE TABLE federated_credentials (user_id INTEGER, provider TEXT, subject TEXT, PRIMARY KEY (provider, subject))\"\n  );\n});\n\n// Configuration\nconst CLIENT_ID = process.env.GOOGLE_CLIENT_ID;\nconst CLIENT_SECRET = process.env.GOOGLE_CLIENT_SECRET;\nconst REDIRECT_URI = \"https://example.com/oauth2/callback\";\nconst SCOPE = \"openid profile email\";\n\n// JWKS client to fetch Google's public keys\nconst jwks = jwksClient({\n  jwksUri: \"https://www.googleapis.com/oauth2/v3/certs\",\n});\n\n// Function to verify JWT\nasync function verifyIdToken(idToken) {\n  return new Promise((resolve, reject) => {\n    jwt.verify(\n      idToken,\n      (header, callback) => {\n        jwks.getSigningKey(header.kid, (err, key) => {\n          callback(null, key.getPublicKey());\n        });\n      },\n      {\n        audience: CLIENT_ID,\n        issuer: \"https://accounts.google.com\",\n      },\n      (err, decoded) => {\n        if (err) return reject(err);\n        resolve(decoded);\n      }\n    );\n  });\n}\n\n// Generate a random state for CSRF protection\napp.get(\"/login\", (req, res) => {\n  const state = crypto.randomBytes(16).toString(\"hex\");\n  req.session.state = state; // Store state in session\n  const authUrl = `https://accounts.google.com/o/oauth2/auth?client_id=${CLIENT_ID}&redirect_uri=${REDIRECT_URI}&scope=${SCOPE}&response_type=code&state=${state}`;\n  res.redirect(authUrl);\n});\n\n// OAuth callback\napp.get(\"/oauth2/callback\", async (req, res) => {\n  const { code, state } = req.query;\n\n  // Verify state to prevent CSRF\n  if (state !== req.session.state) {\n    return res.status(403).send(\"Invalid state parameter\");\n  }\n\n  try {\n    // Exchange code for tokens\n    const tokenResponse = await axios.post(\n      \"https://oauth2.googleapis.com/token\",\n      {\n        code,\n        client_id: CLIENT_ID,\n        client_secret: CLIENT_SECRET,\n        redirect_uri: REDIRECT_URI,\n        grant_type: \"authorization_code\",\n      }\n    );\n\n    const { id_token } = tokenResponse.data;\n\n    // Verify ID token (JWT)\n    const decoded = await verifyIdToken(id_token);\n    const { sub: subject, name, email } = decoded;\n\n    // Check if user exists in federated_credentials\n    db.get(\n      \"SELECT * FROM federated_credentials WHERE provider = ? AND subject = ?\",\n      [\"https://accounts.google.com\", subject],\n      (err, cred) => {\n        if (err) return res.status(500).send(\"Database error\");\n\n        if (!cred) {\n          // New user: create account\n          db.run(\n            \"INSERT INTO users (name, email) VALUES (?, ?)\",\n            [name, email],\n            function (err) {\n              if (err) return res.status(500).send(\"Database error\");\n\n              const userId = this.lastID;\n              db.run(\n                \"INSERT INTO federated_credentials (user_id, provider, subject) VALUES (?, ?, ?)\",\n                [userId, \"https://accounts.google.com\", subject],\n                (err) => {\n                  if (err) return res.status(500).send(\"Database error\");\n                  res.send(`Logged in as ${name} (${email})`);\n                }\n              );\n            }\n          );\n        } else {\n          // Existing user: fetch and log in\n          db.get(\n            \"SELECT * FROM users WHERE id = ?\",\n            [cred.user_id],\n            (err, user) => {\n              if (err || !user) return res.status(500).send(\"Database error\");\n              res.send(`Logged in as ${user.name} (${user.email})`);\n            }\n          );\n        }\n      }\n    );\n  } catch (error) {\n    res.status(500).send(\"OAuth or JWT verification error\");\n  }\n});\n\napp.listen(3000, () => console.log(\"Server running on port 3000\"));\n```\n\n[ref1]: https://stackoverflow.com/questions/6556522/authentication-versus-authorization\n[ref2]: https://github.com/LukasNiessen/oauth-explained",
    "created_utc": 1745266844.0,
    "url": "https://www.reddit.com/r/computerscience/comments/1k4njwn/eli5_what_is_oauth/",
    "score": 23,
    "num_comments": 2
  },
  {
    "subreddit": "computerscience",
    "title": "fully understanding computers and internet",
    "text": "hi, all. I would like to fully understand computers and internet and how it all functions and not just on a surface level like what each part does, or something like that. I want to be able to break it down until I can't anymore, only because there isnt really anything left, not because of limited knowledge; and I don't really know where to start, hence my post here: so I'm looking for directions.\nIt would be great if anyone could give me a list of materials and whatever other word of advice, thanks :D",
    "created_utc": 1744978231.0,
    "url": "https://www.reddit.com/r/computerscience/comments/1k23e4m/fully_understanding_computers_and_internet/",
    "score": 56,
    "num_comments": 75
  },
  {
    "subreddit": "computerscience",
    "title": "Cannot grasp some concepts from Charles Petzold\u2019s Code",
    "text": "Hey everybody, I've been reading Charles Petzold's book \"Code: The Hidden Language of Computer Hardware and Software\" 2nd edition and seemingly understood everything more or less. I'm now reading the chapter about memory and I can't seem to figure out some things:\n\n1. There's this overview of how to build a 16x8 memory array efficiently. I can understand everything up to the second screenshot. It might be the wording or I stopped following Charles' train of thought at some point. My current understanding is this: the 4 to 16 decoder is used to generate a write signal for a concrete byte. Once generated, all data in values are stored within flip-flops (1st screenshot). Further, however, the author says that those end gates from the decoder are inputs to another set of end gates with another write signal. This is where I'm lost. What is that second write signal? Where does it come from? What's the point of it if the signal generated from the 4 to 16 decoder is seemingly enough to do that 0-1 clock transition and save the value in the flip-flop:\n\n*Processing img wunmckic5gte1...*\n\n*Processing img hlgdjr4k5gte1...*\n\n2. Going further into the chapter, the author shows how we can read the value of a memory cell (the bits at a specific position in each byte are connected in columns). Then he says something I cannot understand, quote: \"At any time, only one of the 16 outputs of the 4-to-16 decoder will have an output of 1, which in reality is a voltage. **The rest will have an output of 0, indicating ground**\". I understand why 1 is voltage but why on earth does he refer to 0 as the ground? From what I understood having read this book for a long time is that the ground is basically a physical connection to the ground (earth) so that the circuit is closed without being visibly closed. Now he refers to the output of 0 as the ground and I'm completely confused. We cannot connect anything there to close the circuit, can we?\n\n*Processing img i8efa2nd6gte1...*\n\n3. And the last but not least, a little further the author says this: \"We could get rid of the giant OR gate if we could just connect all the outputs of the AND gates together. **But in general, directly connecting outputs of logic gates is not allowed because voltages might be connected directly to grounds, and that\u2019s a short circuit.** But there is a way to do this using a transistor, like this:\"\n\n*Processing img hb36678i7gte1...*\n\nAnd again I can't figure out where the ground is in that case and how connecting outputs of logic gates can cause short circuiting. Moreover, he also says this \"If the signal from the 4-to-16 decoder is 1, then the Data Out signal from the transistor emitter will be the same as the DO (Data Out) signal from the memory cell\u2014either a voltage or a ground. **But if the signal from the 4-to-16 decoder is 0, then the transistor doesn\u2019t let anything pass through, and the Data Out signal from the transistor emitter will be nothing\u2014neither a voltage nor a ground.**\". What does this mean? How is nothing different from 0 if, from what I understood, 0 means no voltage and nothing basically also means no voltage?",
    "created_utc": 1744238318.0,
    "url": "https://www.reddit.com/r/computerscience/comments/1jviwhx/cannot_grasp_some_concepts_from_charles_petzolds/",
    "score": 7,
    "num_comments": 7
  },
  {
    "subreddit": "computerscience",
    "title": "How (or do) game physics engines account for accumulated error?",
    "text": "I've been playing around with making my own simple physics simulation (mainly to implement a force-directed graph drawing algorithm, so that I can create nicely placed tikz graphs. Also because it's fun). One thing that I've noticed is that accumulated error grows rather quickly. I was wondering if this ever comes up in non-scientific physics engines? Or is this ignored? ",
    "created_utc": 1744123168.0,
    "url": "https://www.reddit.com/r/computerscience/comments/1juf5zj/how_or_do_game_physics_engines_account_for/",
    "score": 127,
    "num_comments": 48
  },
  {
    "subreddit": "devops",
    "title": "Got ghosted after 3rd round",
    "text": "Hey everyone,\n\nJust wanted to share my recent experience and see if others are going through the same thing.\n\nI\u2019ve been applying for DevOps roles for the past few months, and finally landed an interview. It started with a quick HR screen, followed by a technical round, which went well and I was immediately moved to the next stage.\n\nThe third round was a DevOps challenge, which I completed over my weekend. I presented it, answered all their technical questions, and felt the interview went smoothly.\n\nI followed up with HR the next day \u2014 no response. I waited a week and followed up again \u2014 still nothing. Then I sent a message on LinkedIn just in case, and even followed up with the second HR contact mentioned in the original email \u2014 still complete silence.\n\nAt this point, I\u2019m feeling pretty frustrated. It\u2019s disappointing to invest so much time and effort, only to be met with no closure. Is this kind of ghosting becoming normal now?\n\nWould appreciate hearing if others have gone through something similar, or any advice on how to deal with it.",
    "created_utc": 1746500783.0,
    "url": "https://www.reddit.com/r/devops/comments/1kfuk0z/got_ghosted_after_3rd_round/",
    "score": 38,
    "num_comments": 12
  },
  {
    "subreddit": "devops",
    "title": "Anyone facing issue with Cloudflare recently of suddenly not honoring \"Access-Control-Allow-Headers\" set by origin?",
    "text": "Is anyone facing this recent issue lately where all the sudden, you're getting thrown Access-Control-Allow-Headers error across all proxied domains. Cloudflare proxy, out-of-the-blue, decided not to honor the Access-Control-Allow-Headers set by origin, and decided to block most headers, including \"Authorization\". This caused temporary downtime across all our services, totally unacceptable.\n\nWe had to remove proxy across multiple of our domains temporary and we can't find any changelogs, issues, etc. regarding any changes or reported issues to Cloudflare proxy anywhere (which is strange).",
    "created_utc": 1746500276.0,
    "url": "https://www.reddit.com/r/devops/comments/1kfue56/anyone_facing_issue_with_cloudflare_recently_of/",
    "score": 1,
    "num_comments": 1
  },
  {
    "subreddit": "devops",
    "title": "Grafana Dashboard + Metrics For MCP Servers",
    "text": "I put together a Grafana Dashboard and metrics implementation for MCP servers. I thought some of you, might find it helpful. full post and code source [here](https://huggingface.co/blog/mclenhard/mcp-monitoring) ",
    "created_utc": 1746480383.0,
    "url": "https://www.reddit.com/r/devops/comments/1kfnh0t/grafana_dashboard_metrics_for_mcp_servers/",
    "score": 0,
    "num_comments": 0
  },
  {
    "subreddit": "devops",
    "title": "How do you inspect what actually changed in container images? (My Git-based approach)",
    "text": "Hey everyone,\n\nWhen working with CI images or debugging build issues, I often need to understand *exactly* what changed in a container layer - not just which files were added or removed, but what was inside them.\n\n[**Dive**](https://github.com/wagoodman/dive) is a great tool for exploring layers, but it mainly shows file names and status changes - not full file diffs. I wanted something more powerful and familiar.\n\nSo I built [**oci2git**](https://github.com/Virviil/oci2git), a tool that converts any OCI-compatible container image into a Git repo. Each image layer becomes a commit.\n\nWith it, you can:\n\n* Run `git diff` between layers and see actual content changes, even better - use VSCode for ex, or [**lazygit**](https://github.com/jesseduffield/lazygit)\n* Use `git blame` to find which layer added or modified a file\n* Explore the entire filesystem history with regular Git commands\n\nIt\u2019s been helpful for auditing, debugging, and understanding image composition more deeply. Would love feedback, and I\u2019m curious how others inspect images: Dive? manual tarballing? something else?",
    "created_utc": 1746472797.0,
    "url": "https://www.reddit.com/r/devops/comments/1kfkb6c/how_do_you_inspect_what_actually_changed_in/",
    "score": 33,
    "num_comments": 6
  },
  {
    "subreddit": "devops",
    "title": "Best CI/CD tool",
    "text": "I love TeamCity, it looks great, it's easy to setup and it's easy to work with. The issue at hand tho, it is written in Java and requires over of 4GB free RAM which is just insane.\n\nIs there a product that is as easy to deploy via Docker Compose, is as quality of a product and is more optimized?",
    "created_utc": 1746467424.0,
    "url": "https://www.reddit.com/r/devops/comments/1kfi1d7/best_cicd_tool/",
    "score": 8,
    "num_comments": 42
  },
  {
    "subreddit": "devops",
    "title": "Voice-to-text recs for sales professionals",
    "text": "Happy Monday killers! Hope everyone's crushing their quota this quarter.\n\nSo, I've been in sales for about 5 years now, mostly SDR roles, and I'm starting to feel it. My wrists are *screaming*. All that emailing, updating CRM, crafting personalized LinkedIn messages... it's taking its toll.\n\nI've tried the ergonomic keyboards, wrist rests, the whole nine yards. It helps a little, but honestly, by the end of the day, I'm still feeling the burn.\n\nBeen thinking about voice-to-text solutions. I know it's not perfect, but I'm desperate. Has anyone had good experiences with dictation software? I remember trying Dragon NaturallySpeaking years ago and it was kinda clunky. I've seen some newer stuff advertised, like... uh... WillowVoice? Claimed to use to write what you say, but I'm always skeptical of ads.\n\nMostly curious if anyone else has gone down this route and found something that actually works well in a sales context especially voice to text that can do writing for me. Stuff like accurately transcribing industry jargon and playing nice with Salesforce would be huge.\n\nAlternatively, has anyone found any other good solutions for preventing wrist pain/RSI? I'm all ears! Maybe I just need a better stretching routine lol.\n\nThanks in advance for any advice!",
    "created_utc": 1746467356.0,
    "url": "https://www.reddit.com/r/devops/comments/1kfi0bz/voicetotext_recs_for_sales_professionals/",
    "score": 0,
    "num_comments": 2
  },
  {
    "subreddit": "devops",
    "title": "Got a 3hr interview coming up. Tips/advice appreciated.",
    "text": "I got through the recruiter screening, a meeting with their main DevOps guy and CTO. I got notified that I'll be moving forward to the next round which is a 3 hour interview with other members of the team. I doubt it's going to be 3 straight hours and it'll probably be more like 3 1 hour blocks. \n\nAnyways,\nAny tips, advice, or suggestions? The interviews I already did were pretty chill and I think this might be the last round. The company is pretty cool and in a space where I have some expertise which I think gave me a leg up, I really want the job so help me get through the final push. A little background, I got about 10 years of full stack engineering experience and about the last 5ish years I've been exclusively doing DevOps\n\nOh edit to add: this is all completely remote ",
    "created_utc": 1746461679.0,
    "url": "https://www.reddit.com/r/devops/comments/1kffm0m/got_a_3hr_interview_coming_up_tipsadvice/",
    "score": 15,
    "num_comments": 8
  },
  {
    "subreddit": "devops",
    "title": "Any experience monitoring Redshift",
    "text": "Does anyone have experience monitoring Redshift? We've been having a series of data incidents and we're lacking visibility for what's happening with various jobs. The team usually resorts to tracking various sys\\_xxx tables to investigate failures. We're also using dbt, which writes some state to tables in Redshift as well. We're using Datadog and pulling in metrics for both Glue and Redshift, but none of those seem to be particularly helpful. I'm looking for any tips anyone has. ",
    "created_utc": 1746453856.0,
    "url": "https://www.reddit.com/r/devops/comments/1kfcfcy/any_experience_monitoring_redshift/",
    "score": 3,
    "num_comments": 1
  },
  {
    "subreddit": "devops",
    "title": "Devops not using Docker (or Podman), what does your stack look like?",
    "text": "Edit: I have nothing against containers, I'm looking for another containerization solution / ecosystem.\n\nI hate docker with all my soul. While writing it, I'm 100% aware that \"hate\" is a feeling and not rooted in logic. I'm not interested in comments explaining to me why I should feel differently, I have this discussion every day at work. I have to use this technology every day since years and feel miserable every minute of it.\n\nWhat interest me are the stories of those of you managing to avoid it (docker, and I'm including Podman because as much as I know it's a drop-in replacement so I expect it to have the same issues), while managing large systems (especially micro-services infrasctructures).\n\nFor what I know, docker is used for two different purposes: \n\n* people using docker images as a packaging system => for this the recommanded solution seems to be nix(os), \n* to deploy services => here, I'm not so sure. I have 2 lxc containers running on a private server but lxc seems more or less abandonned? And lxd seems to be vendor-locked to Canonical? I've heard about systemd-nspawn but never played with it...\n\nI don't want to list everything I dislike with docker that would take the whole day, I'm just really interested by the available alternatives.\n\nA last thing that I always says about programming languages but which works for every piece of technology: If I say that I find Tech-X horrible, the corollary is that I have to admire the people who thrive while using said tech. They are better than me.",
    "created_utc": 1746453435.0,
    "url": "https://www.reddit.com/r/devops/comments/1kfc9fo/devops_not_using_docker_or_podman_what_does_your/",
    "score": 0,
    "num_comments": 24
  },
  {
    "subreddit": "devops",
    "title": "Ibm Event notification question",
    "text": "Hello everyone, \n\nI am having difficulties to configure my alerts with different templates.   \nMaybe can someone help me? \n\nIn Event-notifications i have created a Source.   \nIn this sources i have 2 Topics.   \nI have 2 subscriptions and 2 templates. \n\nBut only one of the template is used to send the alerts to slack. \n\nHow can i change that? \n\nIdeally would be to write the Template query to call the alert description on slack.   \nIs this possible?",
    "created_utc": 1746443223.0,
    "url": "https://www.reddit.com/r/devops/comments/1kf8w1x/ibm_event_notification_question/",
    "score": 0,
    "num_comments": 0
  },
  {
    "subreddit": "devops",
    "title": "What\u2019s one cloud concept that took you way longer to understand than expected?",
    "text": "For me, it was IAM on AWS. At first, it seemed simple\u2014just give users permissions, right? But once I got into roles, policies, trust relationships, and least privilege... it felt like falling down a rabbit hole.\n\nI kept second-guessing myself every time I tried to troubleshoot access issues. Even now, I still double-check every policy I write like three times \ud83d\ude05\n\nCurious\u2014what was your \u201cwait, why is this so complicated?\u201d moment when learning cloud?",
    "created_utc": 1746418496.0,
    "url": "https://www.reddit.com/r/devops/comments/1kf2vqj/whats_one_cloud_concept_that_took_you_way_longer/",
    "score": 178,
    "num_comments": 91
  },
  {
    "subreddit": "devops",
    "title": "EKS custom ENIConfig issue",
    "text": "",
    "created_utc": 1746410876.0,
    "url": "/r/kubernetes/comments/1kez96r/eks_custom_eniconfig_issue/",
    "score": 2,
    "num_comments": 0
  },
  {
    "subreddit": "devops",
    "title": "Resource recs for cloud engineer that eventually needs to help developers",
    "text": "Hi everyone!\n\nI know this is a horrible title btw. And excuse me if I got some terms wrong. And I meant \"occasionally\".\n\nHere's the issue: I work as a cloud support engineer for a very small cloud shop and our clients are mainly startups so keep that in mind lol. We are supposed to support our client's infrastructure only, but a lot of times receive tickets asking for help in things that lean into the DevOps and software development fields. I have a very superficial background in backend development so sometimes with a bit of reading the docs and researching I can be of help, but a lot of times I feel like my \"help\" is lacking and not substantial enough. The other day for example we got a client asking how he could reduce downtime in his app during (schema, I assume) migrations. My colleague helped him, but then this weekend I researched the topic and I'm not sure the advice he provided was great.\n\nOn top of that, I'm pretty new to technology in general, still in college and I have A TON of things to learn and study on my to-do list that are related to cloud, networking, IaC, etc, but I feel like it would be incredibly useful to pick up some things in other related fields that would help me in my job.\n\nI'm not assuming in any way that I can pick up a book and suddenly become a genius, but what are the resources - courses, videos, books that in your experience could be helpful to someone in a position like the one I'm in?",
    "created_utc": 1746397736.0,
    "url": "https://www.reddit.com/r/devops/comments/1kew9rd/resource_recs_for_cloud_engineer_that_eventually/",
    "score": 3,
    "num_comments": 1
  },
  {
    "subreddit": "devops",
    "title": "Why did it take OpenAI 24 hours to roll back a faulty model?",
    "text": "Hi everyone,\n\nI read through [an article by OpenAI](https://openai.com/index/expanding-on-sycophancy/) and stumbled upon the following segment:\n\n>With the recent GPT\u20114o update, we started the rollout on Thursday, April 24th and completed it on Friday, April 25th. We spent the next two days monitoring early usage and internal signals, including user feedback. By Sunday, it was clear the model\u2019s behavior wasn\u2019t meeting our expectations.\n\n>We took immediate action by pushing updates to the system prompt late Sunday night to mitigate much of the negative impact quickly, and initiated a full rollback to the previous GPT\u20114o version on Monday. **The full rollback took around 24 hours to manage stability and avoid introducing new issues across the deployment.**\n\n>Today, GPT\u20114o traffic is now using this previous version. Since the rollback, we've been working to fully understand what went wrong and make longer-term improvements.\n\nI am just a developer who is using services like Vercel for deployment (or in a more professional context I used Azure WebApps). Of course, I do understand that for a larger user base, more servers have to be migrated and that this can take a longer time. However, 24hrs feels like a long time to me and I would like to understand, what exactly takes that long in the process. Has anyone insights or information on this?\n\nThank you :)",
    "created_utc": 1746342405.0,
    "url": "https://www.reddit.com/r/devops/comments/1kedugg/why_did_it_take_openai_24_hours_to_roll_back_a/",
    "score": 27,
    "num_comments": 16
  },
  {
    "subreddit": "devops",
    "title": "Where to get started",
    "text": "Hello, I\u2019m a long time admirer of this form. I\u2019m a \u201cjunior devops engineer\u201d in the financial field that was a previous mid-level, sulfur engineer, I\u2019ve been doing so-called devops work for about a year now where I\u2019m assigned to a team where I\u2019m managed their pipelining, but I feel like I\u2019m not doingreal devops. I\u2019ve been so studying outside of work just to get more exposure to the field, but I just want to know if there are any seniors in here that can point me in the right directionwhere I can start to get more exposure to more Devos technology. At my job, we don\u2019t utilize a lot of the all the devops technologies. I am starting a new project at work Monday so hopefully I will get more exposure to more technologies. But any pointers would be helpful \n",
    "created_utc": 1746321978.0,
    "url": "https://www.reddit.com/r/devops/comments/1ke8cl1/where_to_get_started/",
    "score": 0,
    "num_comments": 13
  },
  {
    "subreddit": "devops",
    "title": "Need Guidance for Amazon Systems/DevOps Engineer Interview (Cloud Support Background)",
    "text": "\nHope you're all doing well.\n\nI'm currently working as a Cloud Support Engineer and have managed to land an interview with Amazon for a Systems/DevOps Engineer role. While I\u2019m excited, I\u2019m also feeling a bit stressed\u2014mainly because I haven\u2019t officially worked as a Systems or DevOps Engineer before.\n\nThe interview email was pretty detailed (and a little overwhelming). As most of you know, the world of DevOps is huge\u2014tons of tools, technologies, and concepts\u2014and it\u2019s tough to gain hands-on experience with all of them. To top it off, the interview includes live coding sessions, which has me even more anxious.\n\nThe below qualifications are mentioned in the job description:\n\nProficient executing standard operating procedures and following operational best practices\n\u2022 Knowledge of scripting processes in a language such as Bash, Python, or Ruby or coding software applications in a modern language such as Java, TypeScript, or similar\n\u2022 Experience working cross-organizationally and leading strategic team efforts requiring work from multiple team members\n\u2022 Experience performance tuning software applications and optimizing fleet utilization\n\u2022 Experience with Infrastructure as Code, (such as CDK, CloudFormation, Puppet, Chef, Ansible, or similar)\n\nI\u2019m using the prep material Amazon provided, but I\u2019d love any advice on what to focus on\u2014specific tools, topics, or concepts that are likely to come up. Also, if anyone has insight into the kind of coding questions typically asked, that would be super helpful.\n\nAny resources, tips, or just general encouragement would be massively appreciated!\n\nThanks in advance, and apologies if this isn\u2019t the right place to post.",
    "created_utc": 1746302774.0,
    "url": "https://www.reddit.com/r/devops/comments/1ke1vlz/need_guidance_for_amazon_systemsdevops_engineer/",
    "score": 5,
    "num_comments": 6
  },
  {
    "subreddit": "devops",
    "title": "From Rejection to Redemption: How I Broke Into DevOps",
    "text": "Guys, I'm here sitting on my back yard on a beautiful Saturday and I am about to sign an offer letter with a Fortune 500 company \u2014 with a 25% salary increase.\n\nBut just a few months ago, I was getting rejected from interviews that didn\u2019t even last 10 minutes. I was so embarrassed on how bad I did on the interviews. With over a decade in IT \u2014 supporting Windows and Linux systems, solving tough problems, and holding a high-level security clearance \u2014 I thought I had a solid foundation. But in the world of DevOps, I kept hearing the same message:\n\n\u201cYou don\u2019t have enough experience.\u201d\n\n\u201cYou\u2019re not worth senior-level DevOps pay.\u201d\n\nAnd ironically, being a high earner already seemed to work \\*against\\* me.\n\nI was turned down from at least eight interviews. Some didn\u2019t even give me a chance to speak. I started doubting myself \u2014 hard.\n\nSo when another recruiter reached out, I told her:\n\n\"I don\u2019t want to waste your team\u2019s time. My background might not align.\"\n\nShe said:\n\n\"Actually, we really like what we see. Let\u2019s get you in front of the hiring manager.\"\\_\n\nAfter the first interview with the \\*\\*hiring manager\\*\\*, I asked for \\*\\*two weeks\\*\\* to prepare for the technical round \u2014 not to delay, but because I was \\*determined\\* not to fail again.\n\nAt that point, I didn\u2019t even have a home lab. But I went all in.\n\nIn those two weeks:\n\n\\- Built a full homelab from scratch\n\n\\- Deployed the Sock Shop app using ArgoCD\n\n\\- Provisioned infrastructure with Terraform\n\n\\- Set up monitoring with \\*\\*Prometheus, Grafana, and Kuberhealthy\\*\\*\n\n\\- Studied nonstop for a HackerRank I had never heard of\n\n\\- \\*\\*Watched DevOps interview Q&A videos on YouTube while driving \u2014 even while taking my dog to the vet\\*\\*\n\n\\- \\*\\*Skipped volleyball \u2014 something I love \u2014 and turned down social invites from friends just to stay locked in\\*\\*\n\nThe \\*\\*technical interview was round 2 of 4\\*\\*, but after one hour of walking through my setup, architecture, and decisions \u2014 they said:\n\n\"We\u2019re skipping the rest. We're making you an offer.\"\\_\n\nThat moment changed everything.\n\n\\*\\*My clearance didn\u2019t get me here. My title didn\u2019t. My past salary didn\u2019t.\\*\\*\n\nBut \\*grit, sacrifice, and proof of ability\\* did.\n\nAnd the cherry on top? I\u2019ll get to \\*\\*work from home eventually\\*\\* \u2014 a goal I\u2019ve had for years.\n\nTo anyone trying to break into DevOps:\n\nDon\u2019t wait until you\u2019re \u201cready.\u201d\n\n\\*\\*Start building, start learning, and never stop showing up.\\*\\*\n\nYour breakthrough might be closer than you think.\n\nSorry English isn't my first language and I use ChatGPT to help me with this but it's truly my experience.  So good luck out there, if I can make it, you can!!!! Cheers!!! ",
    "created_utc": 1746301558.0,
    "url": "https://www.reddit.com/r/devops/comments/1ke1fjq/from_rejection_to_redemption_how_i_broke_into/",
    "score": 309,
    "num_comments": 64
  },
  {
    "subreddit": "devops",
    "title": "AWS network automation",
    "text": "I find myself in a funny position to redo part of the network in AWS. We have two parts: one is newer and uses transit gateways that are centralized in a single account, the other is older and vpc peering is used between many accounts/vpcs. We try to use terraform for everything. That said, how the $%\\^&\\* do you automate transit gateways?  \n  \nIn terraform, i have taken the following steps in the past\n\n1) Got into the product's terraform repo, run the attachment module we have and it outputs the gateway attachment id.  \n  \n2) Get into the centralized network account repo, add the cidr/attachment id under a region in a large json file and run it. It adds the attachment id to a route table (non-prod vs prod) and a static route to the cidr is added in other regions as needed. The terraform module I wrote is \"clever\" and Kerighan's law makes it difficult for me to debug problems with the sub 100 vpcs we have now. \n\nHow do people handle this with hundreds of vpcs in a way that keeps state? I can see this working with a bunch of cloudwatch event rules and lambdas, but that seems very push and pray to me whereas I know what I'm getting with terraform before applying it.",
    "created_utc": 1746221696.0,
    "url": "https://www.reddit.com/r/devops/comments/1kdcirx/aws_network_automation/",
    "score": 6,
    "num_comments": 4
  },
  {
    "subreddit": "devops",
    "title": "MacOs HomeBrew and Open Source tooling",
    "text": "Hey guys!\n\nQuick question for ya, I've been at a job for awhile now but we just got transitioned over to macOS. We were on windows machines before. Software was always distributed through self service software centers or pushed via org policy.   \nNow however Im running into issues getting up and running with my dev tooling (mostly cli tools, and local cluster dev). Currently homebrew isnt an approved technology, but its so common to get tools installed that way im not familiar with any other common patterns. Ive been tasked with trying to make an argument to allow it for devs from my team.  \nIm anticipating security folks and others having a high skepticism because they cannot \"own\" the software that gets installed there as far as Im aware. The current pattern would have me contact the helpdesk to install software via .pkg or be distributed.   \n  \nCurrently other package managers are allowed - like conda, npm, yarn, etc. But I know its not quite an apples to apples comparison.  \n  \nWhat arguments would you make to allow homebrew into the ecosystem? Are any of your jobs able to track whats installed accurately? Im assuming the MDR/AV software locally would pick up something. ",
    "created_utc": 1746221386.0,
    "url": "https://www.reddit.com/r/devops/comments/1kdcehg/macos_homebrew_and_open_source_tooling/",
    "score": 2,
    "num_comments": 1
  },
  {
    "subreddit": "devops",
    "title": "We open-sourced internet\u2019s largest incident response glossary with over 500+ terms",
    "text": "We just published a public glossary with **500+ terms** related to incident response, on-call, alerting, SLOs, postmortems, and more. I think this is perhaps the internet's largest glossary for incident response. \n\n  \n\ud83d\udc49 [https://spike.sh/glossary](https://spike.sh/glossary)\n\nThere's no signups, no fluff. Just a clean, searchable list of terms \u2014 each one explained in plain English.\n\n\\----\n\n**Why we built this:**\n\nWriting about incident response, I would alaways get stuck on terms like *alert correlation*  and wondered if should explain it again? Should I link to something?\n\nThere wasn't a single place to encompass all the IR terms. This is when we decided to build on our own.\n\n  \nI really thought we could keep it small and we did in teh initial pass. But then later on we brought in **700+ terms** (thanks, AI \ud83d\ude05).\n\n  \nThere were lots of back-and-forth but we did endup narrowing it down to 525 terms that actually matter (*I know it's still absurdly large..*)\n\nEvery term answers:\n\n* What it means\n* Why it\u2019s relevant in incident response\n* (Sometimes) examples, best practices, or how teams use it\n\nngl, AI was super helpful in many ways, and we did edit *tons* by hand to make sure it wasn\u2019t just noise. Many terms didn\u2019t need extras so we cut it out. \n\nI didn't expect it be as big but it just happened.\n\n\\----\n\nFull disclosure - there are still terms we are working to improve upon but hey, its a start and I am happy we got some ting out there for everyone. \n\n  \nPRs are welcome - [https://github.com/spikehq/glossary](https://github.com/spikehq/glossary)\n\n  \nps: hosted on cloudflare pages which we love. Special shoutout to [11ty.dev](http://11ty.dev) and Claude code ",
    "created_utc": 1746217744.0,
    "url": "https://www.reddit.com/r/devops/comments/1kdazr7/we_opensourced_internets_largest_incident/",
    "score": 15,
    "num_comments": 4
  },
  {
    "subreddit": "devops",
    "title": "Interview for associate devops role, not sure how it went, need opinions",
    "text": "I had a technical discussion with with a smaller company(around 100-200 employees) and they are filling out a new devops team. I have 7 YOE at large tech companies as a software engineer, but my duties have closer aligned with sys admin, infrastructure, Linux admin, developer, kinda devops, or just whatever is needed. I always wanted to do devops but haven't had the opportunity to pivot. I got an interview at this place who has had this listing up for over a month for an associate devops engineer for the same salary. The recruiter seemed very excited to meet me and I was excited for this job\n\nI had the technical interview yesterday and the first half was asking me my technical experience with CI/CD tools and cloud environments. I tired to answer what I could but told them I was lacking in this area and have always wanted to learn it which is why I am so excited for this associate position. I understand the concepts of the tools and have interacted with them so I could explain them, but I don\u2019t have deep hands on. When they asked me more in depth scripting questions I may have been a little shaky, but eventually came to the correct answer they were looking for.\n\nThen it was the linux infrastructure guys turn who works on infrastructure within the team and he started shotgunning me system level questions that I was able to answer immediately and knew were right. The back and forth continued about 5-7 minutes before he said \"okay I think im good\" and went back to the main guy who asked me how id troubleshoot an issue. I talked out my thought process and isolated every point of failure and explained the testing for each point, and mentioned system level linux commands that could be used to troubleshoot this and went deeper into checking firewalls and such. After a bit he asked if I couldn\u2019t find anything there what would I do, and I said Id reach out to teams I know who may interact with this application and ask if any major changes have been pushed out recently that may have caused it, and as well asked for any logs on their side to be sent to me for further troubleshooting. Then I would escalate internally. He seemed to like this and started smiling and nodding.\n\nHe asked my strength and I noted how in every performance review I have ever received, my managers have noted that my attitude, positivity, communication, and mentorship is invaluable and is why I am always assigned to work with new college hires, interns, and junior devs. And this is also why I am usually the point of contact within my team to interface with other teams as I am usually the easiest to talk to and why I am also in charge of screening L2 defects for customers and usually am the one to assist customers on calls. He also seemed to like this. I made sure to re-iterate how I really want to do devops and how I am really excited about this opportunity. I asked next steps and they said it would be an interview with the head of engineering and that would be the final interview. I was very polite and positive and made them smile and laugh a lot on the call. I followed up the next morning to everyone on the panel with a sincere thank you email.\n\nI have never done a devops interview and not sure at all how this went. I feel like my natural personality showed through with them and they really liked it, but I wished the linux guy asked me more, I really crushed that section. I really hope I get this job but I have no idea how this type of hiring works",
    "created_utc": 1746214274.0,
    "url": "https://www.reddit.com/r/devops/comments/1kd9msw/interview_for_associate_devops_role_not_sure_how/",
    "score": 1,
    "num_comments": 4
  },
  {
    "subreddit": "devops",
    "title": "Devops resources",
    "text": "Hello everyone,  my name is Sal i been in IT for over 15 years.  Mostly web development and recently ML/AI. I'm familiar with Docker and CI/CD pipelines with github actions. Looking for recommendations on resources that helped you level up your devOps skills?",
    "created_utc": 1746204425.0,
    "url": "https://www.reddit.com/r/devops/comments/1kd5pis/devops_resources/",
    "score": 0,
    "num_comments": 20
  },
  {
    "subreddit": "devops",
    "title": "Project ideas",
    "text": "I am currently working as tester using blueprism. Want to transition my career in to devops . So can you please share some project ideas that can land me a job.\nOr any advise that can help.",
    "created_utc": 1746202802.0,
    "url": "https://www.reddit.com/r/devops/comments/1kd52ba/project_ideas/",
    "score": 0,
    "num_comments": 2
  },
  {
    "subreddit": "devops",
    "title": "Which DevOps repositories need contributions?",
    "text": "I don't think I am the only one that has a little bit of a spare time in their life and would love to help out on a DevOps project in need. \n \nWhat are your favorite ones? Which repositories need just a little bit more love, whether writing documentation, improving runtime or adding features?",
    "created_utc": 1746200303.0,
    "url": "https://www.reddit.com/r/devops/comments/1kd41pq/which_devops_repositories_need_contributions/",
    "score": 89,
    "num_comments": 33
  },
  {
    "subreddit": "devops",
    "title": "Help creating a whatsapp bot",
    "text": "Hi, im trying to create a bot for my company that grabs files from a sharepoint folder and sends them through whatsapp when asked. i have 0 experience, whats the easiest way to do it? my job kind of depends on this\n\nedit\\* i can use only copilot IA, for privacy policies",
    "created_utc": 1746197301.0,
    "url": "https://www.reddit.com/r/devops/comments/1kd2t6z/help_creating_a_whatsapp_bot/",
    "score": 0,
    "num_comments": 8
  },
  {
    "subreddit": "devops",
    "title": "AWS SAA-C03 Exam Traps That Almost Failed Me (And How to Dodge Them)",
    "text": "Hello comrades!\n\nI cleared my AWS SAA exam recently and made an article about my journey and what common pitfalls to avoid :)\nI hope this helps anyone who's planning to take up the examination soon :)\nPlease feel to add anything I might have missed :)\n\nhttps://medium.com/@nageshrajcodes/aws-saa-c03-exam-traps-that-almost-failed-me-and-how-to-dodge-them-08c41ed73e2a?sk=cea7f9606ce910a723b4064b2a48c8d9\n\nI wish you all the very best :')\n\nThank you :)\n",
    "created_utc": 1746191106.0,
    "url": "https://www.reddit.com/r/devops/comments/1kd0ghv/aws_saac03_exam_traps_that_almost_failed_me_and/",
    "score": 0,
    "num_comments": 0
  },
  {
    "subreddit": "devops",
    "title": "Business scaling up - what cloud provider should we use?",
    "text": "Our business is scaling rapidly \u2014 we\u2019re currently handling millions of unique requests per week, and this number continues to grow. At the moment, we\u2019re hosted on DigitalOcean, paying approximately \u20ac400 per month for the following infrastructure:\n\n* One small Redis server for caching\n* Four medium ARM nodes in two data centers\n* One MySQL database with two replicas\n\nHowever, we\u2019re now facing significant performance issues due to unoptimized application code. Our stack includes Symfony (backend), MySQL (database), and a partially VueJS-powered frontend.\n\n# Key Problems\n\n1. **Blocking Requests:** When User A and User B make simultaneous requests, User B is delayed until User A's request completes. If our code executes a long-running operation (e.g., 20 seconds), the server is locked during that time, triggering Cloudflare\u2019s load balancer to mark it as unhealthy. I initially suspected this was related to MySQL\u2019s transaction isolation level (TIL), but DigitalOcean doesn\u2019t allow us to change this setting. Regardless, with our current code inefficiencies, this issue is likely to worsen.\n2. **Lack of Scalable Architecture:** We're not using Kubernetes or any dynamic scaling solution. Our infrastructure consists of a fixed number of servers behind Cloudflare\u2019s load balancer. This will likely become a bottleneck as we grow.\n\n# What We Need to Do\n\n1. **Optimize the Application Code:** We need to refactor our backend to avoid inefficient loops and rely more on optimized database queries.**Question:** Does Symfony block concurrent requests by design? Is there a way to configure Symfony or PHP-FPM to handle multiple requests more efficiently? Or is it more likely that MySQL's transaction behavior is the real bottleneck? Would it be hard to migrate to PostgreSQL and is it really that much faster?\n2. **Improve Infrastructure & Scalability:** We need a more robust and flexible server architecture with proper failover and autoscaling capabilities.**Question:** Which cloud providers would you recommend for scalable and reliable database hosting? Our primary concern is database performance and availability. Thanks to Cloudflare\u2019s load balancer, we\u2019re flexible with server location and even open to transitioning to Kubernetes.\n\nWe\u2019re aiming to stay ahead of any major issues that could impact our platform\u2019s stability. Any advice or insights would be greatly appreciated.",
    "created_utc": 1746179406.0,
    "url": "https://www.reddit.com/r/devops/comments/1kcx1iw/business_scaling_up_what_cloud_provider_should_we/",
    "score": 11,
    "num_comments": 20
  },
  {
    "subreddit": "devops",
    "title": "Tech Support to DevOps?",
    "text": "I'm currently working for a Software-Development company which owns their products/solutions as a Tech-Fuctional support engineer for one of those. This was my first real job and it's been around 3 years.\n\nRight now, I'm looking to jump onto a more technical role, I'm very interested in Networking (CCNA in progress), programming, scripting, server management, and automation. I'm just wondering how hard it is to land a DevOps job, I've applied to some vaccants but HR simply say that despite having some of the requirements of the role, the managers wouldn't consider me due to the lack of experience in a DevOps role. \n\nI'd love to some day land a job as a DevOps Engineer, I don't mind working for it and having that as a medium/long-term objective. I was actually looking for advise or suggestions from people knowing the field. What role or job would you say will help me at this point? What could be a good next-step to start pointing my career to DevOps? Also, in your experience, how feasible it's to make this jump I'm trying to do?",
    "created_utc": 1746160270.0,
    "url": "https://www.reddit.com/r/devops/comments/1kcshr5/tech_support_to_devops/",
    "score": 0,
    "num_comments": 4
  },
  {
    "subreddit": "devops",
    "title": "Asking for help in implementing a monitoring application?",
    "text": "I'm a junior sofware dev and I want to create a semi-real time monitoring for my application (minor delays are allowed <15min). My application produces a bunch of events with the following states: `queued`, `error`, `processed`, `to_be_requeued`. I want to track if the state goes to the `error` state. At the same time, I want to track if an order got `queued` but didn't get to the processed state (maybe due to an application bug). This will be flagged as an error if the `timestamp` exceeds some threshold.\n\nI'm stumped on how to approach this problem. My initial poc implementation dumps raw events to a timescale database, and then a web api polls and processes it according to some set interval. The implementation is not performant as I expected, and I want to improve it.\n\nAfter browsing the internet, I've read up that the ELK stack is commonly used for alert/ monitoring stuff. But I was wondering if this could be applied to my situation. Afaik elastic is just a key value store and kibana is just a visualization tool/ dashboard for said data.\n\n\nCan this be done with ELK? If not, what are other better approaches/ architectures that I can consider using.\n\nLinks to resources would be helpful and I would also appreciate some input from someone that did a similar task before . Thank you!\n\n\n\n\n```\n{\n  \"user\": \"mel\",\n  \"order_id\": \"0001\",\n  \"event-type\":  \"queued\",\n  \"message\": {\n\u00a0\u00a0\u00a0\u00a0\"timestamp\": <unix_time>\"\n  }\n},\n\n\n{\n  \"user\": \"mel\",\n  \"order_id\": \"0002\",\n  \"event-type\":  \"queued\",\n  \"message\": {\n\u00a0\u00a0\u00a0\u00a0\"timestamp\": <unix_time>\"\n  }\n},\n\n\n{\n  \"user\": \"mel\",\n  \"order_id\": \"0003\",\n  \"event-type\":  \"queued\",\n  \"message\": {\n\u00a0\u00a0\u00a0\u00a0\"timestamp\": <unix_time>\"\n  }\n},\n\n\n{\n  \"user\": \"mel\",\n  \"order_id\": \"0001\",\n  \"event-type\":  \"error\",\n  \"message\": {\n\u00a0\u00a0\u00a0\u00a0\"timestamp\": <unix_time>\"\n  }\n},\n\n{\n  \"user\": \"mel\",\n  \"order_id\": \"0002\",\n  \"event-type\":  \"processed\",\n  \"message\": {\n\u00a0\u00a0\u00a0\u00a0\"timestamp\": <unix_time>\"\n  }\n},\n\n\n\n{\n  \"user\": \"mel\",\n  \"order_id\": \"0003\",\n  \"event-type\":  \"to_be_requeued\",\n  \"message\": {\n\u00a0\u00a0\u00a0\u00a0\"timestamp\": <unix_time>\"\n  }\n},\n\n\n\n{\n  \"user\": \"mel\",\n  \"order_id\": \"0003\",\n  \"event-type\":  \"queued\",\n  \"message\": {\n\u00a0\u00a0\u00a0\u00a0\"timestamp\": <unix_time>\"\n  }\n},\n\n{\n  \"user\": \"mel\",\n  \"order_id\": \"0003\",\n  \"event-type\":  \"processed\",\n  \"message\": {\n\u00a0\u00a0\u00a0\u00a0\"timestamp\": <unix_time>\"\n  }\n},\n\n\n```",
    "created_utc": 1746157914.0,
    "url": "https://www.reddit.com/r/devops/comments/1kcru5c/asking_for_help_in_implementing_a_monitoring/",
    "score": 0,
    "num_comments": 8
  },
  {
    "subreddit": "devops",
    "title": "A simple, self-hosted Sentry alternative you can install in 5 minutes (with just one command!)",
    "text": "Hey folks \ud83d\udc4b\n\nI got fed up with monthly bills and SaaS lock-in, and I needed a better way to track errors in my apps, so I built Telebugs. It\u2019s an error tracker you pay for once, host yourself, and actually own. It took me 3.5 months of solo Rails work, and I\u2019m really happy with the results.\n\nIt\u2019s compatible with Sentry SDKs, so it probably supports your language or framework of choice.\n\nIt\u2019s built for people who just want something that works without the headache. Setup is dead simple: one command and you\u2019re rolling in 5 minutes. It automatically sets up your server with an SSL certificate. All you need to do is specify the domain you want it to run on.  \n  \nIt catches your errors, keeps everything on your machine, and doesn\u2019t bug you with upsells or surprise fees.\n\n**Tech stack:**\n\n* Rails 8 + Hotwire + TailwindCSS\n* SQLite (yep)\n* Runs in a single Docker container\n* Compatible with Sentry SDKs\n* Push + email alerts (needs to be enabled explicitly)\n* Rule-based data cleanup\n* No analytics, no third-party calls\n\nHappy to answer any questions here, or over email. Cheers!\n\n[https://telebugs.com/](https://telebugs.com/)",
    "created_utc": 1746115042.0,
    "url": "https://www.reddit.com/r/devops/comments/1kcc8qg/a_simple_selfhosted_sentry_alternative_you_can/",
    "score": 2,
    "num_comments": 12
  },
  {
    "subreddit": "devops",
    "title": "Should you whitelist known cookies in the WAF?",
    "text": "So recently we had an outage due to a cookie value for a third party monitoring system falling foul of a WAF Rule.\n\nThis was tested in QA environment and it didn't trigger the WAF (cookie value was different in qa) so it never was raised as an issue.\n\nThis got me thinking that maybe we should whitelist all known cookies but obviously that opens the door to attack via the whitelisted cookie.\n\nOn the one hand it's unlikely that a random attacker would stumble upon the right cookie but what about the users? and also, it's not like we use obscure tech, so somebody might try some sort of drive by attack with known cookies.\n\nIt seems like a bad idea to whitelist, to say nothing that we were actually not aware of the change, so we wouldn't have been able to whitelist it (though we could put a process in place for to be notified)\n\nSo, do you whitelist known cookies in your WAF? \n\nwhy? \n\nwhy not?\n\nHow do you ensure that cookies do not trigger WAF rules in production?",
    "created_utc": 1746106462.0,
    "url": "https://www.reddit.com/r/devops/comments/1kc8v1c/should_you_whitelist_known_cookies_in_the_waf/",
    "score": 0,
    "num_comments": 1
  },
  {
    "subreddit": "devops",
    "title": "I built a PagerDuty docs AI, LMK what you think!",
    "text": "Hi everyone, \n\nI gave a custom LLM access to all PagerDuty dev center docs([https://developer.pagerduty.com/docs/introduction](https://developer.pagerduty.com/docs/introduction)) to answer technical questions for people using PagerDuty:\u00a0[https://demo.kapa.ai/widget/pagerduty](https://demo.kapa.ai/widget/pagerduty)  \n\n\nAny other technical info you think would be helpful to add to the knowledge base?\n\nWould love to hear your thoughts on it!",
    "created_utc": 1746105932.0,
    "url": "https://www.reddit.com/r/devops/comments/1kc8o6c/i_built_a_pagerduty_docs_ai_lmk_what_you_think/",
    "score": 0,
    "num_comments": 2
  },
  {
    "subreddit": "devops",
    "title": "server error 500 after depolying on railway",
    "text": "",
    "created_utc": 1746082144.0,
    "url": "/r/djangolearning/comments/1kaojmd/server_error_500_after_depolying_on_railway/",
    "score": 0,
    "num_comments": 0
  },
  {
    "subreddit": "devops",
    "title": "Saw lots of comments that Jenkins is not worth it. Why and if not then what??",
    "text": "I looking to enter devops and just completed jenkins. But iam worried looking at all those comments. And also what other helpful tip you would give. Thank you \ud83d\ude4f",
    "created_utc": 1746075992.0,
    "url": "https://www.reddit.com/r/devops/comments/1kc0vvk/saw_lots_of_comments_that_jenkins_is_not_worth_it/",
    "score": 75,
    "num_comments": 105
  },
  {
    "subreddit": "devops",
    "title": "Calling all founders - Help validate an early stage idea - helping AI developers go from fine tuned AI model to product in minutes",
    "text": "We\u2019re working on a platform thats kind of like\u00a0**Stripe for AI APIs**. You\u2019ve fine-tuned a model. Maybe deployed it on Hugging Face or RunPod. \n\nBut turning it into a\u00a0**usable, secure, and paid API**? That\u2019s the real struggle.\n\n* Wrap your model with a secure endpoint\n* Add metering, auth, rate limits\n* Set your pricing\n* We handle usage tracking, billing, and payouts\n\nIt takes weeks to go from fine-tuned model to monetization. We are trying to solve this.\n\nWe\u2019re validating interest right now. Would love your input:\u00a0[**https://forms.gle/GaSDYUh5p6C8QvXcA**](https://forms.gle/GaSDYUh5p6C8QvXcA)\n\nTakes 60 seconds \u2014 early access if you want in.\n\nWe will not use the survey for commercial purposes. We are just trying to validate an idea. Thanks!",
    "created_utc": 1746044312.0,
    "url": "https://www.reddit.com/r/devops/comments/1kbqa5b/calling_all_founders_help_validate_an_early_stage/",
    "score": 0,
    "num_comments": 5
  },
  {
    "subreddit": "devops",
    "title": "What networking questions should a fresher DevOps engineer expect in interviews?",
    "text": "\nHey folks,\nI'm preparing for DevOps engineer interviews as a fresher and want to get a solid grasp on the networking side of things. I understand that networking is a key skill for DevOps, but I\u2019m not sure what kind of questions are commonly asked at the entry level.\n\nCould anyone share the typical networking topics or specific questions that I should prepare for? Things like DNS, HTTP, ports, firewalls, etc.?\nAny tips, resources, or personal interview experiences would be super helpful!\n\n",
    "created_utc": 1746028790.0,
    "url": "https://www.reddit.com/r/devops/comments/1kbk2a2/what_networking_questions_should_a_fresher_devops/",
    "score": 0,
    "num_comments": 2
  },
  {
    "subreddit": "devops",
    "title": "Security Tool (hardening) with Ansible remediation",
    "text": "Hello guys! \n\nI work on\u00a0[Squirrel Servers Manager](https://squirrelserversmanager.io/), the open-source monitoring & configuration management platform some of you might know from here or Github.\n\nI am starting starting to build a\u00a0**lightweight security feature**\u00a0for self-hosted / on-prem Linux boxes.\n\nThe idea:\u00a0**scan your servers over SSH**, spot common config issues or weak points (CIS-style stuff), and\u00a0**suggest ready-to-run Ansible playbooks**\u00a0to fix them. No agents, no magic \u2014 just faster, cleaner hardening. *Think about it like a lightweight \"Ansible Lockdown\" with an UI.*\n\nBefore I go too far and spend too many weekends on it :-), I\u2019d love your input:\n\n* Biggest security frustrations/needs right now?\n* How do you handle server hardening today?\n* On hardening - what\u2019s the most annoying part? Keeping track of benchmark? Writing fixes? Testing safely?\n* Would a workflow like this save you time or just add noise?`ssh-key`\u00a0\u279c\u00a0**scan**\u00a0(CIS-ish checks + top CVEs) \u279c\u00a0**get a ranked list & matching Ansible/YAML snippets**\u00a0\u279c approve / tweak / run \u279c success/fail ping after 30 min\n\nIf you\u2019re curious to try it early or have opinions, I\u2019d love to hear from you\u00a0**here or by DM**.\n\nThanks, and fire away with critique, war stories, or \u201cthis already exists, go look at X\u201d!\u00a0\u2014 Manu",
    "created_utc": 1746028422.0,
    "url": "https://www.reddit.com/r/devops/comments/1kbjx53/security_tool_hardening_with_ansible_remediation/",
    "score": 1,
    "num_comments": 0
  },
  {
    "subreddit": "devops",
    "title": "Un(der)documented thing about importing datasets in GCP Vertex AI",
    "text": "Just saw a post wishing that we talked about more DevOps things in this sub so I thought I would post this in case someone else is running into this problem.\n\nYesterday we spent a bit of time beating our heads against permissions issues trying to import images into a dataset using an import file. \n\nTurns out the service account doing the work needed both Storage Object Viewer and Legacy Bucket Reader. Only Storage Object Viewer was listed in any documentation we could find.\n\nThe actual perms needed are definitely a more tailored list than the broad swath of those role assignments, but starting with those roles should get you over the hump, with tuning coming later.\n\nJust thought I'd share this in case someone else was struggling with the Y U NO WORK of this function.",
    "created_utc": 1746024343.0,
    "url": "https://www.reddit.com/r/devops/comments/1kbiac9/underdocumented_thing_about_importing_datasets_in/",
    "score": 1,
    "num_comments": 1
  },
  {
    "subreddit": "Frontend",
    "title": "Hi I need help for my web design",
    "text": "I am a college student and I want someone to help me with my website design for my college assignment. I have made the design in figma but I don't have any html/front end knowledge. I need to submit this project in two days it's only 5-6 pages with barely any interaction. Just need it enough to show my design and little bit of interactions I added.\nCan someone help me make it?\n \nI am ready to pay if necessary/ my budget is $10\n \nI have no resort but this... :')",
    "created_utc": 1746504864.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1kfvr50/hi_i_need_help_for_my_web_design/",
    "score": 0,
    "num_comments": 3
  },
  {
    "subreddit": "Frontend",
    "title": "Google frontend interview",
    "text": "Hi all, I have frontend domain round for google L4 position in India coming up in few days and wanted to know if anyone has already given this round before. If so, what is the format of the interview and what kind of questions can we expect? If it has live ui development, Is it still going to be on Google doc or will we have access to some code editor? I am confused on what resources to focus in the remaining days of preparation. I am familiar with frontend development and have given multiple interviews earlier but not really what Google expects. Any guidance will be of huge help. \n\nJust an FYI, I had 2 rounds of DSA before this as part of onsite rounds. 3rd onsite round will be frontend domain specific",
    "created_utc": 1746502675.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1kfv4ic/google_frontend_interview/",
    "score": 21,
    "num_comments": 7
  },
  {
    "subreddit": "Frontend",
    "title": "New to Web Development \u2013 Eager to Join a Project!",
    "text": "Hi! I\u2019ve been studying HTML, CSS, and JavaScript, and I\u2019m looking to contribute to a project to gain more experience. I\u2019d love to collaborate and learn\u2014let me know if there\u2019s anything I can help with!",
    "created_utc": 1746475271.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1kflcgr/new_to_web_development_eager_to_join_a_project/",
    "score": 4,
    "num_comments": 3
  },
  {
    "subreddit": "Frontend",
    "title": "Just got laid off \u2014 Fullstack/Creative Developer",
    "text": "In order to help pay my bills and maintain stability after my recent layoff, I\u2019m currently looking for freelance work or even a full-time remote position.\n\nI have six years of experience as a full-stack and creative developer. Over the years, I\u2019ve built SaaS platforms, worked closely with startups, designed beautiful user interfaces, and shipped production-ready code across the stack.\n\n**Skills and tech stack:**\n\nFrontend: Framer Motion, GSAP, Tailwind CSS, Next.js, React\n\nBackend: Firebase, Prisma, PostgreSQL, Express, Node.js\n\nDevOps / Tools: GitHub, Vercel, Docker (basic usage)\n\nDesign-oriented: As a UX/UI-aware developer, I care deeply about clean interfaces and polished micro interactions.\n\n**Bonus:** I\u2019ve previously run an agency, so I understand both technical and business perspectives when collaborating with teams or stakeholders.\n\nI\u2019m ready to jump in and help you scale your existing product, improve your landing page, or ship a new MVP.\n\nFeel free to DM me or drop a comment. I\u2019d be happy to share my work samples or chat about how I can help.\n\nThanks in advance. Any leads, referrals, or opportunities are greatly appreciated.",
    "created_utc": 1746228232.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1kdex8t/just_got_laid_off_fullstackcreative_developer/",
    "score": 274,
    "num_comments": 79
  },
  {
    "subreddit": "Frontend",
    "title": "AI-first IDE changed how I build frontend apps \u2014 here\u2019s how",
    "text": "I\u2019ve been using an AI-native IDE for the past few months (Cursor)\n\nHere\u2019s what\u2019s been most helpful in my day to day as a Frontend Engineer:\n\n# \ud83e\udde0 Agent Mode for UI-heavy features\n\nThis is probably the biggest time saver. Some things I regularly use it for:\n\n* Rewriting code\n* Writing tests\n* Generating component + test boilerplate from a short prompt\n* Implementing small UI features directly from a Figma description\n\nSometimes, I paste in a problem description or test error, and the agent gives me code suggestions. I still review everything, but it saves hours.\n\n# \ud83d\udcd0 Figma + Cursor\n\nUsing the Figma MCP, I can pull design info directly into my coding context. Instead of flipping between tabs, I paste in a link or screenshot and ask Cursor to scaffold a layout or match styles.\n\nIt\u2019s not pixel-perfect, but it's great for:\n\n* Skeleton code generation\n* Storybook story setup\n* Getting breakpoints or color tokens applied quickly\n\n# \ud83d\udcc2 Team Rules = Consistent Frontend Code\n\nTo avoid AI generating inconsistent styles, we added rule files to enforce conventions. Some examples in `.cursor/rules/`:\n\n* `style.mdc` \u2192 Use CSS vars + BEM, no inline styles\n* `react.mdc` \u2192 Enforce component folder structure and prop naming\n* `typescript.mdc` \u2192 Require strict typing, no `any`\n* `test.mdc` \u2192 Follow Playwright + RTL patterns, avoid flaky selectors\n\nIt\u2019s made the output way more aligned with our standards.\n\n# \ud83d\udd0c Tooling MCPs that help frontend\n\nBesides Figma, I\u2019ve also connected Cursor to:\n\n* **Jira** \u2192 to fetch ticket context while building\n* **GitHub** \u2192 to scaffold PRs\n* **Slack** \u2192 to notify the team when features are done\n* **Postgres (read-only)** \u2192 when we need sample data for frontend dev\n\nI also use Puppeteer + Cursor Agent together to reproduce UI bugs and write E2E tests that fail first, then iterate until they pass.\n\nHappy to answer any questions, share example rule files, or hear how others are integrating AI tools into frontend workflows.\n\nFull writeup: [https://neciudan.dev/cursor-ai-the-future-of-coding](https://neciudan.dev/cursor-ai-the-future-of-coding)  \nMy Cursor Rules: [https://github.com/Cst2989/cursor-rules](https://github.com/Cst2989/cursor-rules)  \nA list of curated MCPs: [https://github.com/wong2/awesome-mcp-servers](https://github.com/wong2/awesome-mcp-servers)",
    "created_utc": 1746096820.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1kc5t9h/aifirst_ide_changed_how_i_build_frontend_apps/",
    "score": 0,
    "num_comments": 8
  },
  {
    "subreddit": "Frontend",
    "title": "Interview with fintech/e trade company frontend position",
    "text": "I have a interview with a e trade company and it is specifically a frontend/UI engineering position - from the 2 glassdoor reviews I found seems that this company doesn't ask traditional leetcode questions and both people had negative experiences/interviewers. I guess my question is how would you approach preparing for a interview this style that is more trivia or fixing errors in code blocks and not traditional leetcode? And how do you deal/have y dealt with a negative interviewer?",
    "created_utc": 1746026769.0,
    "url": "https://www.reddit.com/gallery/1kbj9cg",
    "score": 111,
    "num_comments": 27
  },
  {
    "subreddit": "Frontend",
    "title": "Looking for mentor",
    "text": "Hello there! I'm a frontend dev with a year of React experience, and I'm looking for a mentor to help me level up.",
    "created_utc": 1745854552.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1k9yiph/looking_for_mentor/",
    "score": 2,
    "num_comments": 22
  },
  {
    "subreddit": "Frontend",
    "title": "A StackOverflow-like platform for CSS/UI issues with live code previews \u2014 should I pursue it?",
    "text": "Hey everyone,  \nI just had an idea pop into my head and I\u2019m wondering if it\u2019s worth exploring.\n\nThe concept is:  \nA platform like StackOverflow, but specifically for **simple UI/UX problems** \u2014 things like **CSS issues, small animations, layout bugs**, etc.  \nThe difference is, instead of just posting a text question and code snippets like StackOverflow, you would:\n\n* Write your code in an online editor inside the platform.\n* Show a **live visual preview** of your problem.\n* Add a short description explaining what\u2019s wrong.\n* The community can directly **see** your issue and offer solutions by looking at the live preview.\n\nBecause for frontend problems, **seeing** the actual issue often makes it way easier to understand and solve, right?\n\nExamples of questions could be:\n\n* \"My hover animation is glitchy \u2014 what\u2019s wrong?\"\n* \"Why won\u2019t my flexbox center properly on mobile?\"\n* \"How can I make this loader smoother?\"\n\nIt\u2019s like combining CodePen\u2019s live preview with StackOverflow\u2019s Q&A format, but purely for frontend design and animation fixes.\n\n**Do you think this is a good idea to pursue?**  \nWould love to hear your thoughts \ud83d\ude4f",
    "created_utc": 1745814108.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1k9n1bn/a_stackoverflowlike_platform_for_cssui_issues/",
    "score": 0,
    "num_comments": 26
  },
  {
    "subreddit": "Frontend",
    "title": "Frontend/workflow efficiency",
    "text": "Hi all! I have been working as a junior software developer (mainly frontend focused with some backend) for 8 months now. During this time I have been working on a webshop for the company I work at. \n\nNow that I have settled and have gotten used to the processes, I am looking for ways to improve my efficiency during the frontend work. Whilst building the webshop I had several moments where I thought things could have gone faster/better, but there was nobody to ask for tips regarding this. At my company there are no senior, or even medior, frontend developers. It's just me and a friend of mine that I know from college. \n\nThe software development part of the company is still in the beginning phase (about a 1.5 years) and so I thought it would be a good moment to think of and implement efficiency tricks or other workflow improvements in our workflow. I feel like this is quite a unique situation I am in, since I can really give input on how things should be done and I am trying to make the most of it.\n\nFor this I have the following questions:\n\n1. How can I counter building the same things over and over again? I am using components with Tailwind as the styling solution but I am looking for something I can have as a base for each project I start. Do you have your own component library? \n\n2. We have no designer at the company and since I did both frontend and design at college, I do both on my own. Would setting up a design system help and could this be made in a general way so I can use it for each project?\n\nI feel like it is even hard for me to come up with questions on improving efficiency since I don't have someone to learn from. \n\nIf there are any other tips I can use to improve as a frontend dev, even non-efficiency related advice, please make sure to let me know aswell!\n\nThanks in advance!",
    "created_utc": 1745794698.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1k9gyr1/frontendworkflow_efficiency/",
    "score": 2,
    "num_comments": 5
  },
  {
    "subreddit": "Frontend",
    "title": "I want vscode to show prettier errors on warnings but I don't want eslint to fix them",
    "text": "\nI am maintaining a very old ts project wherein I am setting up prettier and linter. Long story short, prettier flagged 2500 files. So, we decided not to run prettier --write in order to preserve history. \n\nWe have also setup eslint, for implementing other rules within the codebase including identifying import order issues. Now 2 situations: \n\n1. If I turn off the plugin, prettier errors stop showing on the IDE (vscode)\n2. If I turn it to either 'warn' or 'error', it shows up in vscode as an issue but it gets auto corrected by eslint --fix or when I save after setting the flag in .vscode/settings.json\n\nIs there a middle ground where the errors will show in vscode but will not get overwritten by eslint --fix or during save? \n\n\n[Solved]: https://www.reddit.com/r/Frontend/s/5Fxt62fbsJ",
    "created_utc": 1745762038.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1k94hiv/i_want_vscode_to_show_prettier_errors_on_warnings/",
    "score": 2,
    "num_comments": 5
  },
  {
    "subreddit": "Frontend",
    "title": "Want to get some feedbacks, are you guys up for it ??",
    "text": "hii, I have a project and I want to make it more user friendly for students using it. Can you guys suggest some improvements in the UI. I am not UI/UX guy, I am a full stack dev and have minimum understanding of what looks good, I dont know dos and donts, or anything about Design, please help me out.\n\nAlso wanted to know how much should I expect for someone to do figma design for me, Currently I cant afford a lot, but maybe in few months I can pay up.\n\nHere is the website [https://brogrammers.in](https://brogrammers.in/)",
    "created_utc": 1745732162.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1k8wpkq/want_to_get_some_feedbacks_are_you_guys_up_for_it/",
    "score": 2,
    "num_comments": 14
  },
  {
    "subreddit": "Frontend",
    "title": "Collection of useful CSS classes? (i.e. circular profile pictures)",
    "text": "Hello!\n\nI am visually impaired, so my best bet to make UIs is to \"cheat\" a little ;) It took me a while, but I have decided to go forward with customizing [Matcha CSS](https://matcha.mizu.sh/) to my liking (`styles/@root/mod.css`). And with some ChatGPT help, I got me a nice color palette going too for both light and dark.\n\nBut, Matcha is indeed very minimal; no badges or other useful stuff.\n\nDo you know of a collection/library of pure CSS components that might play nice here? I have my own colors - I just need it to do the shapes and stuff.\n\nGrand goal is to work this into a Go/Templ/HTMX stack. So I am just looking for useful CSS to use here. The CSS will be built with PostCSS for the time being, there does not seem to be a better tool for stripping unused classes yet...\n\nThanks and kind regards,\nIngwie",
    "created_utc": 1745700885.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1k8myoq/collection_of_useful_css_classes_ie_circular/",
    "score": 0,
    "num_comments": 4
  },
  {
    "subreddit": "Frontend",
    "title": "Need Help Preparing for SDE I - Frontend Developer Interview at LivSYT : What Should I Focus On? What could be the Possible Max interview questions? Any Tips or Advice?",
    "text": "Can anyone please guide me on:\n\nWhat concepts/technologies I should focus on more?\n\nWhich frontend areas are usually important for this kind of role? (ex: HTML, CSS, JS, React, etc.)\n\nIf possible, could you share a list of common or expected interview questions (from start to end) so I can practice properly?\n\nAny tips or experiences would really help!",
    "created_utc": 1745674526.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1k8d3i1/need_help_preparing_for_sde_i_frontend_developer/",
    "score": 0,
    "num_comments": 6
  },
  {
    "subreddit": "Frontend",
    "title": "Winded - alternative to Tailwind",
    "text": "I've put together a project that's allows you to add CSS in HTML, like Tailwind does, while also solving some of the biggest issues Tailwind has.\n\nProject webpage: [https://thescottyjam.github.io/winded/](https://thescottyjam.github.io/winded/)\n\nGithub repo: [https://github.com/theScottyJam/winded](https://github.com/theScottyJam/winded)\n\nIt's pretty simple really - I'm just making it so you can add *any* CSS to your HTML, like this:\n\n    <p data-css=\"color: purple; &:hover { font-weight: bold }\">\n      Hey, that's neat\n    </p>\n    \n    <p data-css=\"\n      color: green;\n      &:hover {\n        font-weight: bolder;\n      }\n    \">\n      Did you know you can go multi-line too?\n    </p>\n\nRun a build tool over your HTML files to produce a `.css` file, import that CSS file, and that's it, you've got CSS-in-HTML.\n\nWhat does this solve?\n\n* A much lighter learning curve. You can take your existing CSS knowledge and use it straight away, instead of having to memorize a parallel CSS class for each HTML rule.\n* You get the full expressivity of CSS available to you. You can create CSS variables, write arbitrary selectors, etc, just as you normally would.\n* `px` aren't second class anymore. Proper accessability requires you to mix both `px` and `rem`.\n* Better dev-tools experience. All of your CSS rules for an element will be together, instead of being spread out among many different utility classes. You can also toggle a single rule on and off in dev tools, and assuming you don't have multiple elements with the exact same `data-css=\"...\"` attribute, toggling the rule will only effect the individual element. (If you do have multiple elements with the same `data-css=\"...\"`, it will be optimized so only one CSS ruleset is produced for both elements).\n* You can use the `all: unset` to remove styles from an element, followed by whatever CSS rules you'd like. This isn't possible in tailwind, as you don't get as much control over the order in which rules apply, and the `all: unset` often gets applied after your other rules instead of before.\n\nThis tool isn't for everyone, but I thought I'd share it.",
    "created_utc": 1745598145.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1k7p2ku/winded_alternative_to_tailwind/",
    "score": 0,
    "num_comments": 21
  },
  {
    "subreddit": "Frontend",
    "title": "Seeking Front-End Guidance for My New Startup",
    "text": "I\u2019m a back-end developer, and I\u2019m about to launch a startup in the coming days. I\u2019ve been working on the back end for a while, and I plan to hire front-end students to help me. Since I\u2019m not familiar with the front-end world, I\u2019d like to hear your opinion on the decisions I need to make \u2014 such as which framework to use. I\u2019ve done some research, but most opinions tend to focus on popularity or usage. That doesn't matter much to me, because I\u2019m building my own company and want to choose whatever works best.",
    "created_utc": 1745462582.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1k6hmiy/seeking_frontend_guidance_for_my_new_startup/",
    "score": 0,
    "num_comments": 25
  },
  {
    "subreddit": "Frontend",
    "title": "First ever Upwork client broke my confidence calling my non-paid work \u201cunprofessional\u201d",
    "text": "Hi everyone,\n\nI am a 32 F (provided so other women in tech can relate). I\u2019m currently a Software Engineering student at WGU, expecting to graduate in Dec 2025. I\u2019ve applied to over 200 internships, and unfortunately, most replies are for unpaid roles. I believe even as students, our time and skills matter \u2014 especially when the company is generating revenue. I was even ready to take as low as $20/hour just to gain experience, but decided to try freelancing on Upwork in the meantime.\n\nA client from Nepal reached out after viewing my profile. He wanted a UI redesign of an old layout, so I followed all of his requirements, added extra touches like footer links (which weren\u2019t requested), and made it responsive, simple, and clean.\n\nThen I received this feedback:\n\n\u201cI\u2019m sorry to say this, but the design seems unprofessional and resembles work done by beginners in web design. This was unexpected, and I apologize for my candid feedback.\u201d\n\nThe \u201cunprofessional part\u201d really stung. He didn\u2019t even tell me what about my design was unprofessional. I knew I was still learning, but this made me question everything. I genuinely didn\u2019t feel my work was that bad, especially when compared to his original version. He didn\u2019t give any clear pointers (e.g., on layout, typography, color, or spacing), nor did he provide a color palette, persona, or any design references.\nHe didn\u2019t even specify what was unprofessional, so I decided to post here, to re-gain my confidence. \nI\u2019m now wondering:\n\t\u2022\tShould I stop referring to myself as a UI/UX designer and just say frontend dev for now?\n\t\u2022\tAm I approaching freelance gigs wrong, or was I wrong doing pre-assessment project? \n\t\u2022\tWhat could I have done better, and how can I keep improving?\n\t\u2022\tWould anyone here be open to giving feedback if I share before/after images and my GitHub link?\n\nI\u2019ve never received this type of blunt feedback before, even in my corporate roles. I expected more constructive direction, not something that made me doubt my entire path.\n\nIf wanyone\u2019s been here, or can help me see this clearly, I\u2019d really appreciate your insight. Thank you.\n",
    "created_utc": 1745425280.0,
    "url": "https://www.reddit.com/gallery/1k63cdq",
    "score": 252,
    "num_comments": 202
  },
  {
    "subreddit": "Frontend",
    "title": "How to remove artifact when closing dropdown menu?",
    "text": "I'm trying to create a dropdown menu for my mobile-responsive website template and I'm facing one annoying issue. I would appreciate help on how to solve this problem!\n\nI'm trying to animate the opening and closing of the menu to make it smooth, which is a work in progress (I'm playing around with opacity) but I think this has caused a side effect to appear. When the menu closes, there is a cutout section of the menu that appears for a moment before continuing the rest of the animation.\n\nIts hard to explain so I recorded a video: [https://imgur.com/a/1wfvptQ](https://imgur.com/a/1wfvptQ)\n\nMaybe animating the opacity is the issue? Would be grateful for your insight!\n\nMy stack is Astro + Tailwind + DaisyUI.\n\nHere is my mobile navigation component:\n\n    ---\n    interface Item {\n      href: string;\n      label: string;\n    }\n    \n    interface Props {\n      navItems: Item[];\n      ctaItems: Item[];\n      headerID: string;\n    }\n    \n    const { navItems, ctaItems, headerID } = Astro.props;\n    \n    const menuToggleID = \"menu-toggle\";\n    const toggleContainerID = \"toggle-container\";\n    const dropdownMenuID = \"dropdown-menu\";\n    ---\n    \n    <button\n      id={menuToggleID}\n      class=\"w-12 h-12 ml-auto border-none rounded relative z-10 flex justify-center items-center transition-transform duration-600 md:hidden\"\n      aria-label=\"mobile menu toggle\"\n    >\n      <div\n        id={toggleContainerID}\n        class=\"w-[clamp(1.5rem,2vw,1.75rem)] h-4 relative\"\n        aria-hidden=\"true\"\n      >\n        <span\n          class=\"w-full h-[2px] bg-primary rounded absolute left-1/2 -translate-x-1/2 top-0 origin-center transition-all duration-500 ease-in-out\"\n          aria-hidden=\"true\"></span>\n        <span\n          class=\"w-full h-[2px] bg-primary rounded absolute left-1/2 top-1/2 -translate-x-1/2 -translate-y-1/2 transition-all duration-500 ease-in-out\"\n          aria-hidden=\"true\"></span>\n        <span\n          class=\"w-full h-[2px] bg-primary rounded absolute left-1/2 -translate-x-1/2 bottom-0 transition-all duration-300 ease-in-out\"\n          aria-hidden=\"true\"></span>\n      </div>\n    </button>\n    <menu\n      id={dropdownMenuID}\n      class=\"menu opacity-0 max-h-0 pointer-events-none absolute left-0 w-full h-auto items-center bg-base-100 z-50 shadow-lg rounded-lg overflow-hidden transition-opacity duration-300 ease-in-out\"\n    >\n      {\n        navItems.map(({ href, label }) => (\n          <li>\n            <a href={href}> {label} </a>\n          </li>\n        ))\n      }\n      {\n        ctaItems.map(({ href, label }) => (\n          <li>\n            <a class=\"btn btn-primary\" href={href}>\n              {\" \"}\n              {label}\n            </a>\n          </li>\n        ))\n      }\n    </menu>\n    \n    <script\n      define:vars={{ menuToggleID, toggleContainerID, dropdownMenuID, headerID }}\n    >\n      document.addEventListener(\"DOMContentLoaded\", () => {\n        const menuToggle = document.getElementById(menuToggleID);\n        const toggleContainer = document.getElementById(toggleContainerID);\n        const menu = document.getElementById(dropdownMenuID);\n        const header = document.getElementById(headerID);\n    \n        // TODO: add rotating animation to the toggle button when clicked. Lines should rotate to make an X\n        // TODO: hide the menu when the button is clicked again or when clicking outside the menu\n        function toggleMenu() {\n          const isOpen = menu?.classList.contains(\"opacity-100\");\n    \n          if (isOpen) {\n            menu.classList.remove(\n              \"opacity-100\",\n              \"max-h-1/2\",\n              \"pointer-events-auto\"\n            );\n            menu.classList.add(\"opacity-0\", \"max-h-0\", \"pointer-events-none\");\n          } else {\n            const headerHeight = header?.offsetHeight;\n            menu.style.top = `${headerHeight + 8}px`;\n    \n            menu.classList.remove(\"opacity-0\", \"max-h-0\", \"pointer-events-none\");\n            menu.classList.add(\"opacity-100\", \"max-h-1/2\", \"pointer-events-auto\");\n          }\n        }\n    \n        menuToggle?.addEventListener(\"click\", toggleMenu);\n      });\n    </script>\n    \n    ---\n    interface Item {\n      href: string;\n      label: string;\n    }\n    \n    \n    interface Props {\n      navItems: Item[];\n      ctaItems: Item[];\n      headerID: string;\n    }\n    \n    \n    const { navItems, ctaItems, headerID } = Astro.props;\n    \n    \n    const menuToggleID = \"menu-toggle\";\n    const toggleContainerID = \"toggle-container\";\n    const dropdownMenuID = \"dropdown-menu\";\n    ---\n    \n    \n    <button\n      id={menuToggleID}\n      class=\"w-12 h-12 ml-auto border-none rounded relative z-10 flex justify-center items-center transition-transform duration-600 md:hidden\"\n      aria-label=\"mobile menu toggle\"\n    >\n      <div\n        id={toggleContainerID}\n        class=\"w-[clamp(1.5rem,2vw,1.75rem)] h-4 relative\"\n        aria-hidden=\"true\"\n      >\n        <span\n          class=\"w-full h-[2px] bg-primary rounded absolute left-1/2 -translate-x-1/2 top-0 origin-center transition-all duration-500 ease-in-out\"\n          aria-hidden=\"true\"></span>\n        <span\n          class=\"w-full h-[2px] bg-primary rounded absolute left-1/2 top-1/2 -translate-x-1/2 -translate-y-1/2 transition-all duration-500 ease-in-out\"\n          aria-hidden=\"true\"></span>\n        <span\n          class=\"w-full h-[2px] bg-primary rounded absolute left-1/2 -translate-x-1/2 bottom-0 transition-all duration-300 ease-in-out\"\n          aria-hidden=\"true\"></span>\n      </div>\n    </button>\n    <menu\n      id={dropdownMenuID}\n      class=\"menu opacity-0 max-h-0 pointer-events-none absolute left-0 w-full h-auto items-center bg-base-100 z-50 shadow-lg rounded-lg overflow-hidden transition-opacity duration-300 ease-in-out\"\n    >\n      {\n        navItems.map(({ href, label }) => (\n          <li>\n            <a href={href}> {label} </a>\n          </li>\n        ))\n      }\n      {\n        ctaItems.map(({ href, label }) => (\n          <li>\n            <a class=\"btn btn-primary\" href={href}>\n              {\" \"}\n              {label}\n            </a>\n          </li>\n        ))\n      }\n    </menu>\n    \n    \n    <script\n      define:vars={{ menuToggleID, toggleContainerID, dropdownMenuID, headerID }}\n    >\n      document.addEventListener(\"DOMContentLoaded\", () => {\n        const menuToggle = document.getElementById(menuToggleID);\n        const toggleContainer = document.getElementById(toggleContainerID);\n        const menu = document.getElementById(dropdownMenuID);\n        const header = document.getElementById(headerID);\n    \n    \n        // TODO: add rotating animation to the toggle button when clicked. Lines should rotate to make an X\n        // TODO: hide the menu when the button is clicked again or when clicking outside the menu\n        function toggleMenu() {\n          const isOpen = menu?.classList.contains(\"opacity-100\");\n    \n    \n          if (isOpen) {\n            menu.classList.remove(\n              \"opacity-100\",\n              \"max-h-1/2\",\n              \"pointer-events-auto\"\n            );\n            menu.classList.add(\"opacity-0\", \"max-h-0\", \"pointer-events-none\");\n          } else {\n            const headerHeight = header?.offsetHeight;\n            menu.style.top = `${headerHeight + 8}px`;\n    \n    \n            menu.classList.remove(\"opacity-0\", \"max-h-0\", \"pointer-events-none\");\n            menu.classList.add(\"opacity-100\", \"max-h-1/2\", \"pointer-events-auto\");\n          }\n        }\n    \n    \n        menuToggle?.addEventListener(\"click\", toggleMenu);\n      });\n    </script>\n\n  \n",
    "created_utc": 1745418320.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1k60hey/how_to_remove_artifact_when_closing_dropdown_menu/",
    "score": 0,
    "num_comments": 5
  },
  {
    "subreddit": "Frontend",
    "title": "Vercal 404! Error",
    "text": "Hii everyone, i encountered this issue when i try to refresh any /children page of my app it crashes. i added the vercal.json file which stopped the root page from crashing but children pages crash when i refresh the tab. i have pasted screenshots of vercal.json file, my app.jsx which contains all the routes, vercal build settings. Please help me figure out what i am doing wrong",
    "created_utc": 1745405719.0,
    "url": "https://www.reddit.com/gallery/1k5w7sm",
    "score": 0,
    "num_comments": 8
  },
  {
    "subreddit": "Frontend",
    "title": "Is there a way to get an iOS device to display a web page in full screen mode reliably?",
    "text": "The scenario: \n\nI've built a web site that is going to be used on a touch-screen device in a facility. A fixed-size screen. Pretty easy to build as we just built a web site with a very specific aspect ratio, and via javascript open the web site up into full-screen mode. Works great. \n\nWe're now being asked if we could make this work well on mobile devices and that's where things get tricky. By default, the site 'works' just fine, but we run into the full screen issue. \n\nFrom what I've been investigating: \n\n*  at least on iOS, Safari has never supported full-screen mode (weird!)\n*  via a manifest.json file, you can instruct the iphone to do certain things if a user 'adds this page to my home screen'\n* via some viewport meta tags, you can restrict some of the behavior\n\nSo this is where I'm at:\n\n* I set up the manifest file and instructed it to 'display: standalone'\n* added a viewport tag that sets the height OR width (depending on aspect ratio) to 100%, and turns off 'user-scalable'\n\nThe results are...mixed. \n\nOn my actual iphone. It sometimes open without the browser chrome like you want it to. This is good and what I want. But sometimes it shows the chrome in landscape mode, even if it doesn't in portrait. But not always. It seems...random. \n\nI can still drag the page and it will move (though snap back). Not sure if this can be prevented. \n\nIt gets really weird when I test on the iOS simulator on my macbook. I can make the brower chrome pop on and off seemingly randomly by just dragging around the screen. And at times, the page zooms by itself, even though I have told it to not allow pinch zooming. \n\nTL/DR the whole experience is finicky and a bit erratic. \n\nI guess I have a few questions:\n\n1. Is there anything else I can do with my setup to make this less erratic?\n2. Are there other browsers on iOS I should look into that can handle a full-screen web site better? \n3. Or is this just how iOS is? ",
    "created_utc": 1745368645.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1k5m86i/is_there_a_way_to_get_an_ios_device_to_display_a/",
    "score": 3,
    "num_comments": 18
  },
  {
    "subreddit": "Frontend",
    "title": "I'm going slightly mad with space between! help!",
    "text": "hello,\n\nI am doing my first bigger self project and combining grid and flex.\n\ni essentially have 3 main columns and 2 rows under those3 columns.\n\nI have buttons in my main center column...and i'd like to have them fill the space.\n\ni did align-content: space -between and although it moves it up...it does not fill the whole column with an even space between buttons?\n\nspace evenly does put even space between the buttons, but also centers them in the column which looks odd.\n\nSo the parent to where i am applying it is setting the grid, then i am applying the space between to the main area which is what i have called the middle column\n\nI feel like as a noob i'm missing something obvious.\n\nDo i make another div as a container within the grid area and make that flex, then do space between? Do i make another grid inside of this grid, 6 rows, 1 for each button. \n\nI've tried applying flex to the existing 'main area' with is the child of 'grid container'.\n\nEssentially i want the middle to be evenly spread, like a button panel.\n\nSo essentially i've got area1 main main area3...it's the buttons in the main (orange rounded rectangles below) that i want to fill the whole main area with the thick border.\n\nSorry for rudimentary screenshot, i've just literally been working on my layout, proper styling to come later lol. \n\nBelow is what happens with space-between.\n\n    align-content: space-between;\n    \n\nhttps://preview.redd.it/vnfbibv1t4we1.jpg?width=1081&format=pjpg&auto=webp&s=89b67db1192f50ad2b3862c470b91da4bf0cafde\n\n",
    "created_utc": 1745216892.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1k46v4z/im_going_slightly_mad_with_space_between_help/",
    "score": 0,
    "num_comments": 15
  },
  {
    "subreddit": "Frontend",
    "title": "Putting an absolute positioned element above/below based on viewport",
    "text": "I'm building an autocomplete (enter text into an input, do a API call, show matching content in a drop down div). I've got it mostly working (I'm sure there are issues, but not too important for this question). In the context of the page I'm making, on a mobile view, there could potentially be enough rows containing these inputs where the drop down could be at the bottom of the screen, which if I'm correct, as an absolute object, could go below the viewport? Even if not, it would extend the view port, but you couldn't scroll down without closing the drop down if I set it to close when clicked outside (which I obviously would).\n\nI know in the future, we'll have anchor name to help with this problem, but how could I have the drop down appear above the element if it goes below the viewport? I feel like there's probably some math-y thing I could do in JS, but what that is isn't coming to me.",
    "created_utc": 1745176321.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1k3u3id/putting_an_absolute_positioned_element_abovebelow/",
    "score": 0,
    "num_comments": 4
  },
  {
    "subreddit": "Frontend",
    "title": "Struggling to find a colour for my Navbar due to text colouration.",
    "text": "Hi all, I've got a logo which has sort of just... bold text, in these hexcodes:  \n\\#AEA37D (gold)  \n\\#343433 (dark grey)\n\nAn then under that more gold text, in a finer font.\n\nWhen I pick a lightbackground, it makes the gold / finer bit almost invisible. When I go for something darker, it blends the dark too much. I can't win.\n\nIt's in the navbar, and I've tried transparent / partially transparent but it's not really clicking. Any ideas would be appreciated.\n\nhttps://preview.redd.it/nmiikbkg8hve1.png?width=1146&format=png&auto=webp&s=f22bb8b4755f250d7b199f29189b1cfcf8b71c8c\n\n  \n",
    "created_utc": 1744930590.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1k1q65a/struggling_to_find_a_colour_for_my_navbar_due_to/",
    "score": 1,
    "num_comments": 9
  },
  {
    "subreddit": "Frontend",
    "title": "Problem with date filter in Tabulator and time zone in Angular",
    "text": "Hello everyone!\n\nI'm working with Tabulator version 5.4.4 and have encountered an issue related to date handling and filtering. I'm consuming data from my backend, but the dates are arriving with time zone issues. I've formatted the dates before displaying them in the table using the appropriate format (I've had no issues with that, and the date is formatted with a custom setting that hasn't given me any issues), but when I try to apply the date filter in Tabulator, the filter doesn't recognize the formatted date. My goal is to customize the filter to handle dates in the correct time zone (UTC-4, for example), but I've had difficulty getting Tabulator to recognize and apply the formatting correctly in the filter.\n\nI've tried customizing the filter to take UTC dates into account and automatically convert them, but I haven't had any luck. The date filter seems to still use the original dates (in UTC) and doesn't respond to the adjusted format.\n\nHas anyone had a similar issue with date filtering in Tabulator? How can I get Tabulator to handle dates and their filters correctly when they're in a different time zone?\n\nAny advice or solutions would be greatly appreciated. Thanks in advance!",
    "created_utc": 1744816097.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1k0mqkv/problem_with_date_filter_in_tabulator_and_time/",
    "score": 2,
    "num_comments": 0
  },
  {
    "subreddit": "Frontend",
    "title": "React Markdown Editor messes up text position when zoomed in",
    "text": "Left(Normal Scaling) Right (Browser scaling at 110%)\n\nI was working on a Markdown Editor ([https://github.com/RishiSpace/osfm-md](https://github.com/RishiSpace/osfm-md)) and I was using react-md-editor when I noticed this issue\n\nAs you can see when highlighting the text, the text appears to be slightly above where it's being shown and same applies when you're typing on it\n\nIs there a way to fix this ? What could be causing this problem ?",
    "created_utc": 1744811048.0,
    "url": "https://www.reddit.com/gallery/1k0krts",
    "score": 4,
    "num_comments": 5
  },
  {
    "subreddit": "Frontend",
    "title": "Need Help with JS Animation: Swapping Points on Circle Edge (Like Video)",
    "text": "I'm trying to create a specific animation using JavaScript (and potentially SVG/GSAP) based on a video reference.  \n\nI tried just to use this video and add over it like triggers and than played specific parts of video but the problem is video isn't suit for being looped as first frame is quite different from last one. I tried to implement logic when after video ended I started it from spefic time, where frame is kinda similar to last one in video, but still they ain't same and it caused some side effects like captions changing it's position. I also tried to hide it behind some fade-in and fade-out effect but still not impressed with result.   \n  \nSo I decided to ask maybe it is better to try implement logic of animation using some JavaScript, and it would be nice if you share some tools or ideas I can use.   \n  \n[https://drive.google.com/file/d/1yxp9VUw1ZF4GRLXMmUxh8hJn31NA3IDx/view?usp=sharing](https://drive.google.com/file/d/1yxp9VUw1ZF4GRLXMmUxh8hJn31NA3IDx/view?usp=sharing) ",
    "created_utc": 1744720712.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1jzqu16/need_help_with_js_animation_swapping_points_on/",
    "score": 2,
    "num_comments": 8
  },
  {
    "subreddit": "Frontend",
    "title": "Bugsink (Self-hosted Error Tracking) just became Frontend Friendlier (sourcemaps support)",
    "text": "I get it... I have to [post the repo too](https://github.com/bugsink/bugsink/). ",
    "created_utc": 1744660514.0,
    "url": "https://www.bugsink.com/blog/bugsink-1.5-introducing-sourcemaps/",
    "score": 2,
    "num_comments": 1
  },
  {
    "subreddit": "Frontend",
    "title": "I need help from frontend people regarding bootstrap modules, css. I am willing to pay for the services. DM if interested. please its urgent.",
    "text": "",
    "created_utc": 1744630312.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1jywlrr/i_need_help_from_frontend_people_regarding/",
    "score": 0,
    "num_comments": 6
  },
  {
    "subreddit": "Frontend",
    "title": "CMS Tool suggestions for a healthcare mobile app (e-commerce + services)",
    "text": "Hey Folks!\n\nI\u2019m a product manager working on a healthcare mobile application that combines e-commerce (like pharmacy, lab test bookings, etc.) with other service modules (appointments, online consults, homecare, etc.).\n\nI\u2019m looking for a CMS tool that allows us to:\n\n\\- Dynamically update content across the app (banners, service info, etc.)\n\n\\- Easily push and manage offers/promotions\n\n\\- Potentially support personalization in the future\n\n\\- Be mobile-friendly (ideally with good SDK support or APIs)\n\nWould love to hear from anyone who has built something similar or evaluated CMS options for mobile-first health or commerce apps. Any advice or tool recommendations would be super helpful!\n\nThanks in advance \ud83d\ude4f",
    "created_utc": 1744620597.0,
    "url": "https://www.reddit.com/r/Frontend/comments/1jyu6l8/cms_tool_suggestions_for_a_healthcare_mobile_app/",
    "score": 2,
    "num_comments": 7
  },
  {
    "subreddit": "backend",
    "title": "help i really need your input",
    "text": "hello, a little about myself, i have 2 years, fullstack experience mostly frontend. but lately, i  got into backend with nodejs. currently, i am taking a django introductory course. now here lies my problem, i am in a country, where majority of our unicorns,and, i am saying 5 out of 6 are fintechs\nso i am trying to build a lean fintech backend project . my more experienced dev friend says, i should go the .NET route for the project, but i know c# has a steep learning curve. my question is do you suggest building a fintech backend in nodejs or django or .NET if you had the option which would you choose and why?",
    "created_utc": 1746501700.0,
    "url": "https://www.reddit.com/r/Backend/comments/1kfuu15/help_i_really_need_your_input/",
    "score": 1,
    "num_comments": 0
  },
  {
    "subreddit": "backend",
    "title": "What's the \"best\" backend architecture as your application grows?",
    "text": "We've all seen the typical progression \u2013 start with MVC, move to something more structured (DDD, modular monoliths, or even microservices) when things get messy.\n\nBut what has actually worked for you?\n\n* How does DDD help to build a rich domain model?\n* Was the modular monolith a clean middle ground?\n* If you went all in on microservices, was it worth the ops overhead?\n\nWe\u2019re not saying there's one \"right\" answer, but what helped your team scale and what do you regret? Share your thoughts and cases. And [here](https://dev.family/blog/article/the-evolution-of-architectural-patterns-in-back-end-development-from-mvc-to-microservices?utm_source=reddit&utm_medium=post&utm_campaign=dev-family&utm_content=the-evolution-of-architectural-patterns-in-back-end-development-from-mvc-to-microservices) are our case studies and insights into this topic based on migrations we've seen or worked on directly.",
    "created_utc": 1746444355.0,
    "url": "https://www.reddit.com/r/Backend/comments/1kf97pz/whats_the_best_backend_architecture_as_your/",
    "score": 10,
    "num_comments": 3
  },
  {
    "subreddit": "backend",
    "title": "I\u2019m a 2-year experienced NestJS backend developer from India. I want to grow but I feel stuck.",
    "text": "Hello seniors,\n\nI\u2019ve been working as a NestJS backend developer for 2 years. I\u2019m based in India and looking to switch jobs, but I don\u2019t see many backend-only openings in Node.js. Most job posts are for Java or C#, and startups usually want full-stack developers. I have solid experience with API integration, but I don\u2019t enjoy frontend \u2014 CSS and UI just don\u2019t excite me.\n\nI\u2019ve been applying through cold DMs. My LinkedIn has 5k+ connections. I follow HRs, tech leads, companies, and keep an eye on openings. I even cracked a few interviews but was rejected because the companies wanted backend + data engineering or backend + frontend. Some wanted MQTT, video streaming, .NET, or AWS-heavy backend roles.\n\nMy current challenge:\n\nI feel like an average backend developer. Not great, not terrible.\n\nI want to work on large-scale systems and build meaningful backend architectures.\n\nNode.js isn\u2019t used at a massive scale in serious backend infra, especially in India.\n\nSome say I should stick to Node.js + MongoDB, others say Node.js devs barely earn INR 20\u201325k.\n\nI don\u2019t want to switch to full-stack \u2014 I don\u2019t enjoy frontend.\n\nReact devs are getting jobs, but Node.js devs are struggling.\n\nEven if I want to switch to Go, Rust, or Python (like FastAPI), my current company doesn\u2019t use them, and I don\u2019t have time for major personal projects due to work + freelancing + teaching.\n\nI\u2019m the only backend dev in my current company, working on all projects in the MERN stack.\n\n\nMy goals:\n\nEarn 1 lakh per month\n\nWork on large-scale systems\n\nGet a chance to work abroad someday\n\n\nMy questions to this community:\n\nHow can I stand out as a backend developer if I\u2019m sticking to Node.js?\n\nWhat skills or areas should I focus on within backend?\n\nHow can I bridge the gap between being a \u201cjust Node.js dev\u201d and someone working on scalable, impactful systems?\n\nShould I focus on DevOps, AI, Data engineering,  architecture, testing, message queues, or something else?\n\nIf switching language/framework isn\u2019t an option right now, how do I still grow?\n\n\nPlease help me with direction or share your stories if you\u2019ve faced something similar.",
    "created_utc": 1746283302.0,
    "url": "https://www.reddit.com/r/Backend/comments/1kdujc1/im_a_2year_experienced_nestjs_backend_developer/",
    "score": 6,
    "num_comments": 5
  },
  {
    "subreddit": "backend",
    "title": "Spring Boot + Next.js OAuth session issue on Render (cross-domain cookies problem) \u2014 Need advice",
    "text": "Hi all,\n\nI\u2019m running into an authentication/session issue with my deployed app and could really use some advice. Here\u2019s the setup and the problem:\n\n\n---\n\nStack:\n\u2014 Backend: Spring Boot (deployed on Render)\n\u2014 Frontend: Next.js (also deployed on Render)\n\n\n---\n\nWhat works locally:\nOn localhost:\n\n1. User clicks Google Sign-In on the frontend login page.\n\n\n2. OAuth flow completes (via the backend).\n\n\n3. Backend creates a session (JSESSIONID).\n\n\n4. Redirects to frontend homepage \u2192 user is logged in, session persists.\n\n\n\nNo problems locally \u2014 everything works as expected.\n\n\n---\n\nWhat happens on Render (deployment):\n\n1. User clicks Google Sign-In on the frontend (Render deployed app).\n\n\n2. OAuth flow completes and backend does create a JSESSIONID (I can see it).\n\n\n3. Redirect happens to the frontend homepage...\n\n\n4. But the JSESSIONID is not present anymore in the request headers. So the backend sees no session, and user ends up unauthenticated.\n\nMy understanding (based on research):\nSince the backend and frontend are on different domains/subdomains (Render gives different URLs for each service), cookies like JSESSIONID are not shared across origins. So after OAuth redirect, backend treats frontend as a \"new\" origin \u2192 session doesn\u2019t persist.\n\n\n\nConstraints:\n\u2014 I don\u2019t want to purchase a custom domain (limited budget \u2014 personal project).\n\u2014 I\u2019m fine with changing auth/session strategies if it stays free and simple.\n\n\nMy questions:\n\n1. Should I just move to a JWT-based auth system (store JWT in localStorage / cookie and skip server sessions)?\n\n\n2. Are there other practical options to make cross-origin session management work without buying a domain?\n\n\n3. If you\u2019ve solved similar issues (especially on Render), how did you do it?",
    "created_utc": 1746139402.0,
    "url": "https://www.reddit.com/r/Backend/comments/1kcluzr/spring_boot_nextjs_oauth_session_issue_on_render/",
    "score": 2,
    "num_comments": 2
  },
  {
    "subreddit": "backend",
    "title": "Best practices (or tools) for validating SAML authentication flows in backend services?",
    "text": "While working on SAML SSO integrations for a B2B SaaS platform recently, I ran into a bunch of frustrating backend issues:\n\n* X.509 certificate parsing/formatting mismatches\n* XML signature validation failures in AuthNRequests/Responses\n* Metadata inconsistencies between identity providers and service providers\n* Problems decrypting SAML responses securely\n\nManually testing these flows during backend integration was painful and error-prone, especially when automating SSO onboarding for enterprise customers.\n\nI ended up building a small internal toolkit to help validate and debug the full SAML flow without spinning up complex environments \u2014 handling cert generation, request signing, metadata building, encryption/decryption, and validation.\n\nIt eventually became a free toolset.  \nNo login needed \u2014 just lightweight utilities for developers working on backend authentication workflows.\n\nCurious what best practices or tools you\u2019re using today to handle secure SAML validation for your APIs and services?  \nAlso happy to share the toolkit link if anyone\u2019s interested.",
    "created_utc": 1745838495.0,
    "url": "https://www.reddit.com/r/Backend/comments/1k9svhi/best_practices_or_tools_for_validating_saml/",
    "score": 1,
    "num_comments": 1
  },
  {
    "subreddit": "backend",
    "title": "Adding indexes would fix +1M slow queries ?",
    "text": "We had +1 million orders in our database.  \nCustomers were complaining search was painfully slow.  \nMy first thought was the classic backend voice in my head:  \n*\"Just add some indexes, it\u2019ll be fine.\"*\n\nSo I added indexes on `status` and `payment_method`, deployed...  \nand ?  \n**Still slow.**\n\nTurns out, indexes aren't a magic wand when you\u2019re dealing with huge datasets.  \nSome lessons I learned (the hard way):\n\n* **Always run EXPLAIN ANALYZE \u2014 just because I** ***added*** **an index doesn't mean your query** ***uses*** **it.(my case)**\n* Sometimes **partial indexes** (on the most frequent query filters) perform way better. **here is my case!**\n* If the dataset is mostly for search \u2192  probably need a **search engine** like Elasticsearch, not just SQL.(found upon trying to find a solution)\n* For extreme read pressure, **read replicas** can help.(found upon trying to find a solution)\n\nJust sharing in case someone else falls into the \"just add indexes\".  \nWould love to hear if anyone has other tips for scaling search at 1M+ rows!  \n\\- Another thing if you can help me find a twist way / alternative to apply partial indexes in Prisma (Not supported)",
    "created_utc": 1745778802.0,
    "url": "https://www.reddit.com/r/Backend/comments/1k9ayh5/adding_indexes_would_fix_1m_slow_queries/",
    "score": 9,
    "num_comments": 4
  },
  {
    "subreddit": "backend",
    "title": "I Collected 1,000+ backend engineer Jobs from AI Companies. Apply now!",
    "text": "I\u2019ve noticed that many AI companies\u2014especially startups\u2014are actively hiring backend engineer, likely because they help reduce costs.\n\nSo, I built EasyJob AI, a job board focused exclusively on the AI industry. It aggregates not only AI/ML and data science roles but also engineering positions like full-stack, backend, and frontend developers.\n\nUnlike other job platforms, EasyJob AI specializes in AI companies and uncovers many unlisted opportunities you won\u2019t find on LinkedIn or major job sites.\n\nYou can check it out here: [EasyJob AI](https://easyjobai.com/search/backend-engineer).",
    "created_utc": 1745759410.0,
    "url": "https://www.reddit.com/r/Backend/comments/1k93lm2/i_collected_1000_backend_engineer_jobs_from_ai/",
    "score": 11,
    "num_comments": 0
  },
  {
    "subreddit": "backend",
    "title": "Tools for design backends",
    "text": "Hi, what tools do you use to design your backends, more specifically microservices? Feel free to suggest any other tools that you think help you be productive.",
    "created_utc": 1745684180.0,
    "url": "https://www.reddit.com/r/Backend/comments/1k8gnd9/tools_for_design_backends/",
    "score": 6,
    "num_comments": 9
  },
  {
    "subreddit": "backend",
    "title": "System design for a Spring boot application",
    "text": "Sorry if it's not exactly the Java problem because I am not sure where to post and it might be related to how I use WebClient.\n\nI have two applications running as Docker containers within the same Docker network:\n\n1. **Spring Boot Backend**\n   * Stores classroom-related data in its own database.\n2. [**Thingsboard**](https://thingsboard.io/docs/user-guide/install/docker/)\n   * Stores device and telemetry data in a separate database.\n\n# Data Access Pattern\n\n* To access device telemetry, I use Thingsboard\u2019s telemetry API:\n\n&#8203;\n\n    /api/plugins/telemetry/{entityType}/{entityId}/values/timeseries{?keys,startTs,endTs,intervalType,interval,timeZone,limit,agg,orderBy,useStrictDataTypes} \n\n* My Spring Boot backend exposes an endpoint to fetch telemetry data for all devices in all classrooms within a specified time window. This endpoint fetches telemetry by making multiple REST API calls to Thingsboard using Spring Boot\u2019s WebClient:\n\n&#8203;\n\n     /api/classrooms/device-usages?startTs={startTs}&endTs={endTs} \n\n# Problem\n\n* The\u00a0`/api/classrooms/device-usages`\u00a0endpoint is slow (up to 15 seconds or more), especially as the number of devices increases.\n* The performance bottleneck is due to the large number of sequential/external API calls required to gather telemetry data for all devices.\n\n# Potential Solutions Considered\n\n1. **Caching:**\n   * Short-term caching doesn\u2019t help much because clients require up-to-date usage data (e.g., today\u2019s device usages).\n   * Long-term caching risks serving stale data.\n2. **Direct Database Access:**\n   * Connecting the Spring Boot backend directly to the Thingsboard database would allow more efficient SQL queries.\n   * However, this increases complexity and maintenance overhead, since I need to write custom queries instead of reusing the Restful Api logic.\n3. **Combining Databases:**\n   * Merging both databases into one could simplify queries but may introduce schema conflicts and is generally undesirable.\n\n# Questions\n\n1. Are there best practices or recommended patterns for efficiently aggregating telemetry data from Thingsboard for multiple devices, especially in a multi-container setup?\n2. Is direct database access (option 2) a viable approach, or are there significant risks or drawbacks I should be aware of?\n3. Are there alternative architectural approaches or optimizations (e.g., batching, async processing, data warehousing) that could improve the performance of this use case?\n4. Any feedback on the risks of combining databases (option 3), or is this strongly discouraged in practice?",
    "created_utc": 1745426681.0,
    "url": "https://www.reddit.com/r/Backend/comments/1k63x4d/system_design_for_a_spring_boot_application/",
    "score": 2,
    "num_comments": 1
  },
  {
    "subreddit": "backend",
    "title": "NGINX configuration needs SSL certificates to start but SSL certificates require NGINX to be running, how to break this loop when running inside docker?",
    "text": "* If you want a letsencrypt certificate, surely you have run into this issue\n* You have docker containers lets say with a node-server running on port 3000\n* You want to run nginx in another docker container that acts as reverse proxy to this 3000 one\n* Your nginx configuration requires you to mention SSL certificates so that you can forward HTTP to HTTPS, setup rules for port 443 etc\n* But letsencrypt requires your nginx server to be running in order for them to give you SSL certificates\n* How do you BREAK this loop in docker?",
    "created_utc": 1745309043.0,
    "url": "https://www.reddit.com/r/Backend/comments/1k50yze/nginx_configuration_needs_ssl_certificates_to/",
    "score": 2,
    "num_comments": 3
  },
  {
    "subreddit": "backend",
    "title": "backend and frontend question",
    "text": "**\"I started my Information Systems degree this year and plan to join the IT team in the junior company. The issue is that they use the MERN stack, and I\u2019ve already decided that I want to be a backend developer\u2014it\u2019s the area I identify with the most. I really want to become a software engineer (especially in big companies where back/front specialization is more valuable). For now, I\u2019m not interested in specializing in data engineering or data analysis.**\n\nI was planning to focus on Java, but my university is using C at the beginning to teach\u00a0*Introduction to Programming*\u00a0and later\u00a0*Algorithm Analysis*\u00a0in the second semester. Since I intend to work on the backend at the junior company, I\u2019ll have to learn Node.js and Express.js. But I\u2019m not sure if it\u2019s worth it if I also have to study HTML, CSS, React, and frontend in general. I feel like I\u2019d be wasting time that I could instead dedicate to backend studies (I\u2019m not too keen on learning JS\u2014I\u2019d really prefer to go straight to Java, but I think the experience of being part of the junior company is valuable for teamwork, agile methodologies, and networking).\n\n**Could I just study JS for the backend and ignore the frontend?**\u00a0Meanwhile, I\u2019d keep studying C (mostly for university, not because I want to) and start learning Java next year. I feel like trying to squeeze Java into everything right now would be too much, and I wouldn\u2019t be able to go deep into anything. Next year, I\u2019d stop studying C for university and focus 100% on specializing in Java\u2014probably for the rest of my degree.\n\nMaybe this frontend knowledge is important for my career, even if I\u2019m aiming for backend, and I\u2019m mistaken in my perspective? I\u2019d really appreciate any thoughts or experiences you could share!\"\n\n",
    "created_utc": 1745195748.0,
    "url": "https://www.reddit.com/r/Backend/comments/1k40t9i/backend_and_frontend_question/",
    "score": 3,
    "num_comments": 1
  },
  {
    "subreddit": "backend",
    "title": "How to backup and restore postgres? CSV + Connection URL",
    "text": "Basically the title, but here's some info for better context. \n\nI want to be able to:\n- make database backups, ideally into .csv files for better readability and integration with other tools\n- use these .csv files for restoration\n- both backup and restoration should only require a connection string\n\nI use Railway for hosting postgres and all my apps.\n\nI have tried to create a custom JS scripts for this, but there are so many details that I can't make it work perfectly:\n- relations\n- markdown strings\n- restoration order\n- etc\n\nI know there are tools like PgAdmin with pg_dump, but these tools don't allow automatically uploading these CSVs into S3 for backups.\n\n**Does anybody have a simple, working workflow for duplicating the entire postgres data?** Ideally, I want these tools to be free and open-source. \n\nOr maybe I am asking the wrong thing?",
    "created_utc": 1744979381.0,
    "url": "https://www.reddit.com/r/Backend/comments/1k23r3d/how_to_backup_and_restore_postgres_csv_connection/",
    "score": 2,
    "num_comments": 2
  },
  {
    "subreddit": "backend",
    "title": "How can I host my Frontend and Backend platform for free for now?",
    "text": "I really want to get this project up. I need help though. How can I host the frontend and backend for free for a limited time until I get the money needed? Thank you.",
    "created_utc": 1744906496.0,
    "url": "https://www.reddit.com/r/Backend/comments/1k1gqa0/how_can_i_host_my_frontend_and_backend_platform/",
    "score": 6,
    "num_comments": 12
  },
  {
    "subreddit": "backend",
    "title": "Is being able to write algorithms necessary to become a backend developer?",
    "text": "So I learned algorithms by myself, and in theory I know how BFS and DFS works. But I have some hard times in writing them in programming language. Maybe it's because of the lack of practice, or I'm just stupid idk.\n\nAnyway if there is working developers, did you need them in you real projects? Were tasks you solved in leetcode helpful?",
    "created_utc": 1744879137.0,
    "url": "https://www.reddit.com/r/Backend/comments/1k17ype/is_being_able_to_write_algorithms_necessary_to/",
    "score": 21,
    "num_comments": 30
  },
  {
    "subreddit": "backend",
    "title": "Looking to collaborate on open-source while job hunting any devs building something cool?",
    "text": "Hey folks! \ud83d\udc4b\n\nI\u2019m a full-stack developer with 4.5 YOE and currently job hunting in Canada and trying to stay sharp with my tech stack during the process.\n\nI'm looking to **collaborate on any open-source or side projects** you might be working on. Whether it\u2019s contributing features, fixing bugs, or handling backend stuff; I\u2019d love to help and grow alongside other devs.\n\nIf you\u2019ve got something going on or know of a good place to get involved, drop a comment or DM me. Let\u2019s build something cool together! \ud83d\ude80",
    "created_utc": 1744755299.0,
    "url": "https://www.reddit.com/r/Backend/comments/1k04oee/looking_to_collaborate_on_opensource_while_job/",
    "score": 11,
    "num_comments": 4
  },
  {
    "subreddit": "backend",
    "title": "How do you choose which backend framework for a take home test?",
    "text": "Got a take-home backend test (simple endpoints, simple auth for some endpoints, code review after).\n\n* **Option A:**\u00a0Use Python/FastAPI. It's faster for me, less boilerplate. 1 .py file easy\n* **Option B:**\u00a0Use Spring Boot (Java). Matches their stack, but I need a refresher via a 1 hours into to spring-boot (background: TS/.NET).\n\nWhich option makes a better impression, assuming the code quality is good either way? Using my preferred tool quickly, or showing willingness to use their stack even if it takes longer?\n\n\nUPDATE:\nI got the internship \ud83d\ude4f\nWent with option B\nThank you everyone for your help",
    "created_utc": 1744353827.0,
    "url": "https://www.reddit.com/r/Backend/comments/1jwjjud/how_do_you_choose_which_backend_framework_for_a/",
    "score": 6,
    "num_comments": 8
  },
  {
    "subreddit": "backend",
    "title": "Struggling to connect AWS ElastiCache Redis with my Serverless Node.js + Express app",
    "text": "Hey devs,  \nI'm building a serverless app (Node.js + Express) and trying to use ElastiCache Redis for caching (e.g., URL shortener redirects). I\u2019ve deployed my app with the Serverless Framework, but I\u2019m having issues connecting to Redis (timeouts, cluster config, VPC setup, etc.).\n\nIf anyone has a solid step-by-step or working example of how to:\n\n* Set up ElastiCache Redis properly with VPC access\n* Connect from a Lambda function\n* Use it in middleware (e.g., caching GET responses)\n\nI\u2019d seriously appreciate a walkthrough or repo link. \ud83d\ude4f  \nBonus if it uses `ioredis` ...",
    "created_utc": 1744214667.0,
    "url": "https://www.reddit.com/r/Backend/comments/1jv9g3g/struggling_to_connect_aws_elasticache_redis_with/",
    "score": 2,
    "num_comments": 4
  },
  {
    "subreddit": "backend",
    "title": "Node js Vs Java springboot",
    "text": "I'm currently working as a sde in optum and I want to switch after October(will have 1.5 year of experience by this time) considering this im looking forward to prepare for backend profile and I'm very confused which should I focus on as I want to get into good company adobe, facebook meta  Netfix and for that I know I have to strong my dsa and that is I'm doing in c++. Coming to the dev part I need your help. And please try to be brutally honest and kind with language \ud83d\ude2d\ud83d\ude4f\ud83c\udffb\n\n",
    "created_utc": 1744141621.0,
    "url": "https://www.reddit.com/r/Backend/comments/1jumomb/node_js_vs_java_springboot/",
    "score": 3,
    "num_comments": 3
  },
  {
    "subreddit": "backend",
    "title": "\ud83c\udf0d New free IP Geolocation API with a plugin system (weather, language, etc.) \u2013 Contributors welcome!",
    "text": "I\u2019ve been working on an open-source project called **Hoskes GeoAPI**, and I\u2019d love to get your feedback and maybe even some contributors!\n\n\ud83d\udd17 **Live Demo:**  \n[https://hoskes-geoapi.onrender.com/json.gp](https://hoskes-geoapi.onrender.com/json.gp)\n\n\ud83d\udcbe **GitHub Repo:**  \n[https://github.com/matheushoske/hoskes.geoapi](https://github.com/matheushoske/hoskes.geoapi)\n\n# \ud83d\ude80 What it does:\n\n* \ud83e\udde0 Detects IP-based geolocation using the MaxMind GeoLite2 database (self-hosted, no external API).\n* \ud83c\udf26\ufe0f Supports plugins (e.g., `?plugins=weather,language`) so the API response can be extended dynamically.\n* \ud83d\udcdc Fully documented, easy to contribute.\n* \ud83c\udf10 No API key or signup \u2013 just hit the URL and get a JSON response!\n\n# \ud83e\udde9 Current Plugins:\n\n* `weather`: Gets the current weather at the IP location.\n* `language`: Guesses the language based on the country.\n\n# \ud83d\ude4c Why I built it:\n\nI wanted a completely **free, open, self-hosted alternative** to things like IPAPI or GeoPlugin \u2013 but with the ability to add plugins and customize the API response. Something that could evolve into a community-driven, plugin-based API playground.\n\n# \ud83e\uddd1\u200d\ud83d\udcbb Looking for:\n\n* Feedback or bug reports (issues welcome!)\n* Contributors to build more plugins (currency converter, time-based data, VPN detection, etc.)\n* Anyone who loves building tools for devs \u2764\ufe0f\n\nThanks for reading \u2013 happy to answer any questions, and if you\u2019d like to contribute, feel free to open a PR!",
    "created_utc": 1744005446.0,
    "url": "https://www.reddit.com/r/Backend/comments/1jtebv0/new_free_ip_geolocation_api_with_a_plugin_system/",
    "score": 1,
    "num_comments": 0
  }
]